---
title: "Análisis de los Sets de Datos"
author: "Luciano Hernández"
date: "`r Sys.Date()`"
output:
  pdf_document:
    toc: true
    toc_depth: 3
    keep_tex: true
---

```{r setup, include=FALSE}
if (Sys.getenv("JAVA_HOME")=="") {
  Sys.setenv(JAVA_HOME="C:/Program Files/Java/jre1.8.0_361")
}
knitr::opts_chunk$set(echo = TRUE)
options(future.globals.maxSize = 8000 * 1024^2)
options(java.parameters = "-Xmx2048m")
library(cowplot)
library(dplyr)
library(ggmap)
library(ggplot2)
library(ggspatial)
library(googlesheets4)
library(grid)
library(gridExtra)
library(knitr)
library(leaflet)
library(lubridate)
library(maps)
library(OpenStreetMap)
library(openxlsx)
library(osmdata)
library(prettymapr)
library(purrr)
library(readr)
library(readxl)
library(rnaturalearth)
library(rnaturalearthdata)
library(sf)
library(stringr)
library(tidyr)
library(tidyverse)
library(tidyxl)
library(viridis)
```

```{r key.objects, include=FALSE}
key.objects <- c("interurban.bus.accidents", "gh026929", "police.accidents", "radio.accidents.df", "chiguayante.speed.df", "vega.speed.df", "gps.events", "biobio.inventary", "trafic.alerts", "accidents", "waze.data", "meters.per.degree.lat", "meters.per.degree.lng", "quantum.data", "tracking.gps.df")
```

```{r save, eval=FALSE, include=FALSE}
deleting.objects <- setdiff(ls(), key.objects)
rm(list = deleting.objects)
gc()
memory.limit()
memory.size()
save.image("~/GitHub/data-sets-analysis/.RData")
save.time.sys <- ls()
for(ko in key.objects) {
  start.sys <- Sys.time()
  file.name <- paste(ko, "rds", sep = ".")
  file.path. <- paste("~/GitHub/data-sets-analysis/rds-files", file.name, sep = "/")
  ko %>% get() %>% saveRDS(file = file.path.)
  end.sys <- Sys.time()
  dt.sys <- end.sys - start.sys
  print(ko)
  print(dt.sys)
  save.time.sys[[ko]] <- dt.sys
}
```


```{r load, include=FALSE}
load.time.sys <- ls()
for(ko in key.objects[key.objects != "tracking.gps.df"]) {
  start.sys <- Sys.time()
  file.name <- paste(ko, "rds", sep = ".")
  file.path. <- paste("~/GitHub/data-sets-analysis/rds-files", file.name, sep = "/")
  assign(ko, ko %>% readRDS(file = file.path.))
  end.sys <- Sys.time()
  dt.sys <- end.sys - start.sys
  print(ko)
  print(dt.sys)
  load.time.sys[[ko]] <- dt.sys
}
```

```{r load.tracking.gps.df, include=FALSE}
options(future.globals.maxSize = 2^6 * 1000 * 1024^2)
ko <- "tracking.gps.df"
start.sys <- Sys.time()
file.name <- paste(ko, "rds", sep = ".")
file.path. <- paste("~/GitHub/data-sets-analysis/rds-files", file.name, sep = "/")
assign(ko, ko %>% readRDS(file = file.path.))
end.sys <- Sys.time()
dt.sys <- end.sys - start.sys
print(ko)
print(dt.sys)
load.time.sys[[ko]] <- dt.sys
```

# Extracción de datos

## Siniestros buses interurbanos(1).xlsx

```{r getData0, eval=FALSE, include=FALSE}
# Siniestros buses interurbanos(1).xlsx
interurban.bus.accidents <- read_excel("data/Siniestros buses interurbanos(1).xlsx", 
    col_types = c("numeric", "numeric", "date", 
        "date", "numeric", "text", "text", 
        "text", "text", "text", "text", "text", 
        "text", "text", "text", "text", "numeric", 
        "text", "numeric", "numeric", "numeric", 
        "numeric", "numeric", "numeric", 
        "numeric", "numeric", "numeric"))
interurban.bus.accidents$Fecha <- paste(interurban.bus.accidents$Fecha, interurban.bus.accidents$Hora %>% format(format = "%H:%M:%S")) %>% as.POSIXct(format = "%Y-%m-%d %H:%M")
interurban.bus.accidents <- interurban.bus.accidents %>% select(-Hora)
interurban.bus.accidents$Región <- interurban.bus.accidents$Región %>% as.factor()
interurban.bus.accidents$Comuna <- interurban.bus.accidents$Comuna %>% as.factor()
interurban.bus.accidents$`Tipo Accidente` <- interurban.bus.accidents$`Tipo Accidente` %>% as.factor()
interurban.bus.accidents$`Tipo (CONASET)` <- interurban.bus.accidents$`Tipo (CONASET)` %>% as.factor()
interurban.bus.accidents$Zona <- interurban.bus.accidents$Zona %>% as.factor()
interurban.bus.accidents$`Ubicación Relativa` <- interurban.bus.accidents$`Ubicación Relativa` %>% as.factor()
interurban.bus.accidents$`Causa (CONASET)` <- interurban.bus.accidents$`Causa (CONASET)` %>% as.factor()
interurban.bus.accidents$`Causa Accidente` <- interurban.bus.accidents$`Causa Accidente` %>% as.factor()
interurban.bus.accidents %>% summary()
interurban.bus.accidents[interurban.bus.accidents$Zona == "RURAL",] %>% nrow() / interurban.bus.accidents %>% nrow() * 100
```

El análisis comprende 6268 registros de siniestros de buses interurbanos ocurridos entre el 1 de enero de 2014 y el 29 de diciembre de 2023.

### Distribución Geográfica

- **Regiones más afectadas**: Región Metropolitana (1285 casos), Región del Maule (835 casos) y Región del Biobío (767 casos)
- **Comunas con mayor incidencia**: Curicó (244 siniestros), Valdivia (227) y Estación Central (186)

### Características de los Siniestros

- **Tipos predominantes**: Colisión (3655 casos), choque (1464) y atropello (448)
- **Distribución por zona**: 4251 accidentes en zonas urbanas (67.82%) versus 2,017 en zonas rurales (32.18%)

### Factores Causales

- **Principales causas**: Imprudencia del conductor (3597 casos), otras causas (599) y causas no determinadas (540)
- *Nota*: La alta frecuencia de la categoría "otras causas" sugiere la necesidad de ampliar la clasificación causal existente

### Consecuencias y Severidad

- Fallecidos: 94.58% de los siniestros no registran víctimas mortales
- Lesiones graves: Ausentes en 89.69% de los casos
- Lesiones menos graves: No ocurren en 94.16% de los accidentes
- Lesiones leves: No se presentan en 63.10% de los incidentes

### Optimizaciones Realizadas

- **Unificación temporal**: Fusión de las columnas "Fecha" y "Hora" en un único campo datetime
- **Normalización de datos**: Conversión de 8 variables de texto a tipo factor para mejorar el procesamiento estadístico:
    - "Región" -"Comuna"
    - "Tipo Accidente"
    - "Tipo (CONASET)"
    - "Zona"
    - "Ubicación Relativa"
    - "Causa (CONASET)"
    - "Causa Accidente"

## GH026929.xlsx

```{r getData1, eval=FALSE, include=FALSE}
# GH026929.xlsx
gh026929 <- read_excel("data/GH026929.xlsx", 
    range = "A1:L1727", col_types = c("numeric", 
        "date", "text", "numeric", "numeric", 
        "numeric", "numeric", "skip", "skip", 
        "numeric", "numeric", "numeric"))

## ¿Qué es cts?
## Rangos altura
## ¿Qué es fix?
## U.M. precision

gh026929$date <- paste(gh026929$date, gh026929$hora) %>% as.POSIXct(format = "%Y-%m-%d %H:%M")
gh026929 <- gh026929 %>% select(-hora)
reduce.coords <- function(n) {
  n * 10 ^ (1 - (n %>% abs() %>% log10() %>% floor()))
}
reduce.2d.speed <- function(n, m) {
  N <- n * 10 ^ ((m %>% log10() + 1) %>% floor() - (n %>% log10() + 1) %>% floor())
  N[(N / m) %>% log10() > 0.7] <- N[(N / m) %>% log10() > 0.7] / 10
  N[(N / m) %>% log10() < -0.7] <- N[(N / m) %>% log10() < -0.7] * 10
  N
}
gh026929$`GPS (2D speed) [m/s]` <- reduce.2d.speed(gh026929$`GPS (2D speed) [m/s]`, gh026929$`GPS (3D speed) [m/s]`)
gh026929$`GPS (Lat.) [deg]` <- gh026929$`GPS (Lat.) [deg]` %>% reduce.coords()
gh026929$`GPS (Long.) [deg]` <- gh026929$`GPS (Long.) [deg]` %>% reduce.coords()
gh026929 %>% summary()
```

El dataset contiene 1726 registros de telemetría GPS capturados durante un período específico de operación vehicular.

### Características Temporales

- **Período de registro**: 29 de agosto de 2024, entre las 01:32 y 01:34 horas
- **Duración total**: Aproximadamente 2 minutos de monitoreo continuo

### Parámetros de Velocidad

- **Velocidad 3D**: Rango de 0.01 a 19.06 m/s (0.036 a 68.62 km/h)
- **Velocidad promedio**: 9.1 m/s (32.76 km/h)
- **Velocidad mediana**: 9.81 m/s (35.32 km/h), indicando una distribución sesgada hacia velocidades moderadas-altas

### Calidad de Señal GPS

- **Valor fix**: Constante en 3 para todos los registros, indicando que calculó su posición a partir de 3 satélites
- **Precisión**: Oscila entre 121 y 158 m (media: 125.9 m, mediana: 125 m)

### Aspectos Requieren Clarificación

**Variables por Definir**

- `cts`: Propósito y unidades no especificadas
- **Rango de alturas**: Valores de altitud GPS no reportados en el resumen

**Problemas de Formato Identificados**

- Coordenadas GPS (`Lat.` y `Long.`) sin formato decimal apropiado
- Velocidad 2D con inconsistencias en la ubicación del punto decimal
- Múltiples campos numéricos presentados sin separador decimal

### Procesamiento de Datos Realizado

**Normalización Temporal**

- Fusión de columnas `date` y `hora` en un campo datetime unificado

**Corrección de Coordenadas Geográficas**

Función aplicada:

$$\text{reduce.coords}(n)\equiv n\times10^{1-\lfloor\log_{10}|n|\rfloor}$$

*Objetivo*: Ajuste de coordenadas chilenas mediante reposicionamiento del punto decimal basado en el orden de magnitud

**Normalización de Velocidad 2D**

Función aplicada:

$$\text{reduce.2d.speed}(n,m)\equiv n\times10^{\lfloor\log_{10}m+1\rfloor-\lfloor\log_{10}n+1\rfloor}$$

*Objetivo*: Alineación de órdenes de magnitud entre velocidades 2D y 3D mediante escalado decimal dinámico

### Observaciones Técnicas

Los ajustes aplicados sugieren que el sistema de captura original podría presentar inconsistencias en el formato de salida numérico, requiriendo post-procesamiento para una interpretación correcta de las mediciones GPS.

## DTPR

```{r getData1.5, eval=FALSE, include=FALSE}
tracking.route <- "data/Tracking GPS"
tracking.cols <- c("EVT_REGISTRO_ID", "EVT_OP_TR_ID", "EVT_OP_TE_ID", "EVT_MES_INFORMACION", "EVT_SERVICIO_ID_ORACLE", "EVT_SERVICIO_ID", "EVT_SENTIDO", "EVT_IMEI", "EVT_PPU", "EVT_GPS_TIME_CHILE_STR", "EVT_GPS_TIME_UTC_0", "EVT_GPS_DIR_GEO", "Y_EVT_GPS_LAT", "X_EVT_GPS_LON", "EVT_GPS_VEL", "EVT_GPS_DOP", "EVT_DISTANCIA_RECORRIDA (Km)", "EVT_ESTADO_MOTOR_GPS", "EVT_TIPO_EVENTO", "EVT_TIPO_VIAJE", "EVT_DISTACIA_A_SERVICIO", "EVT_CARPETA")
folders <- tracking.route %>% list.dirs(recursive = F) %>% basename()
tracking.gps <- list()
tracking.read <- list()
for(folder in folders) {
  start.sys <- Sys.time()
  base.route <- paste(tracking.route, folder, "ArchivosTxt", sep = "/") %>% list.files(pattern = "^MNT_TRACKING", full.names = T)
  df <- base.route %>% read.table(header = F, sep = ";")
  df$EVT_CARPETA <- folder
  tracking.gps[[folder]] <- df
  end.sys <- Sys.time()
  dt.sys <- end.sys - start.sys
  tracking.read[[folder]] <- dt.sys
  print(folder)
  print(dt.sys)
}
# Reading time: 428.22 s = 7 m + 8.22 s
start.sys <- Sys.time()
tracking.gps.df <- tracking.gps %>% bind_rows()
colnames(tracking.gps.df) <- tracking.cols
end.sys <- Sys.time()
binding.time <- end.sys - start.sys
# Binding time: 300.63 s = 5 m + 0.63 s
start.sys <- Sys.time()
tracking.gps.df$EVT_SERVICIO_ID <- tracking.gps.df$EVT_SERVICIO_ID %>% as.factor()
tracking.gps.df$EVT_PPU <- tracking.gps.df$EVT_PPU %>% as.factor()
tracking.gps.df$EVT_GPS_TIME_CHILE_STR <- tracking.gps.df$EVT_GPS_TIME_CHILE_STR %>% as.POSIXct(format = "%d/%m/%Y %H:%M:%S", tz = "America/Santiago")
tracking.gps.df$EVT_GPS_TIME_UTC_0 <- tracking.gps.df$EVT_GPS_TIME_UTC_0 %>% as.POSIXct(format = "%d/%m/%Y %H:%M:%S")
tracking.gps.df$Y_EVT_GPS_LAT <- gsub(",", ".", tracking.gps.df$Y_EVT_GPS_LAT) %>% as.numeric()
tracking.gps.df$X_EVT_GPS_LON <- gsub(",", ".", tracking.gps.df$X_EVT_GPS_LON) %>% as.numeric()
tracking.gps.df$`EVT_DISTANCIA_RECORRIDA (Km)` <- gsub(",", ".", tracking.gps.df$`EVT_DISTANCIA_RECORRIDA (Km)`) %>% as.numeric()
tracking.gps.df$EVT_DISTACIA_A_SERVICIO <- gsub(",", ".", tracking.gps.df$EVT_DISTACIA_A_SERVICIO) %>% as.numeric()
tracking.gps.df$EVT_CARPETA <- tracking.gps.df$EVT_CARPETA %>% as.factor()
tracking.gps.df$EVT_SEÑAL <- NA
tracking.gps.df$EVT_SEÑAL[tracking.gps.df$EVT_GPS_DOP < 1] <- "Excelente"
tracking.gps.df$EVT_SEÑAL[tracking.gps.df$EVT_GPS_DOP >= 1 & tracking.gps.df$EVT_GPS_DOP < 2] <- "Muy Buena"
tracking.gps.df$EVT_SEÑAL[tracking.gps.df$EVT_GPS_DOP >= 2 & tracking.gps.df$EVT_GPS_DOP < 5] <- "Buena"
tracking.gps.df$EVT_SEÑAL[tracking.gps.df$EVT_GPS_DOP >= 5 & tracking.gps.df$EVT_GPS_DOP <= 10] <- "Regular"
tracking.gps.df$EVT_SEÑAL[tracking.gps.df$EVT_GPS_DOP >= 5 & tracking.gps.df$EVT_GPS_DOP > 10] <- "Mala"
tracking.gps.df$EVT_SEÑAL <- tracking.gps.df$EVT_SEÑAL %>% as.factor()
end.sys <- Sys.time()
modifying.time <- end.sys - start.sys
# Modifying time: 1807.08 s = 30 m + 7.08 s
```

```{r getData1.51, eval=FALSE, include=FALSE}
tracking.gps.df %>% summary()
```

El dataset consolidado comprende 21683856 registros de telemetría GPS provenientes del sistema de monitoreo de transporte público DTPR, capturados durante el mes de agosto de 2025 a través de 31 unidades operativas diferentes.

### Metadatos de Procesamiento

- **Tiempo total de lectura**: 7 minutos 8.22 segundos
- **Tiempo de consolidación**: 5 minutos 0.63 segundos
- **Tiempo de transformación**: 30 minutos 7.08 segundos
- **Total de procesamiento**: 42 minutos 15.93 segundos

### Período de Monitoreo

- **Fecha inicial**: 1 de agosto de 2025, 00:00:00 (hora Chile)
- **Fecha final**: 1 de septiembre de 2025, 00:05:27 (hora Chile)
- **Duración**: 31 días completos + 5 minutos
- **Cobertura temporal**: Mes completo de agosto 2025

### Características Operacionales del Sistema

**Flota y Rutas Monitoreadas**

- **Rutas más frecuentes**:
  - "13GS": 617591 registros
  - "43JT": 500230 registros
  - "14HT": 481486 registros
- **Vehículos más activos**:
  - "FSLC62": 27847 registros
  - "TTHL10": 25901 registros
  - "SZDZ86": 25483 registros

**Distribución Direccional**

- **Sentido ida (0)**: 10809559 registros
- **Sentido vuelta (1)**: 10671146 registros
- **Sentido indeterminado (-1)**: 203151 registros

**Métricas de Desempeño Técnico**

_Calidad de Señal GPS_

- Muy Buena: 17924666 registros
- Buena: 966491 registros
- Regular: 592320 registros
- Mala: 2200379 registros

_Velocidades Operacionales_

- Rango: 0 - 193 km/h
- Velocidad promedio: 21.69 km/h
- Velocidad mediana: 19 km/h

_Estados del Sistema_

- Motor encendido (1): 21619957 registros
- Motor apagado (0): 63899 registros

### Procesamiento y Normalización de Datos

**Estructuración Multi-carpeta**

- **Estrategia**: Procesamiento paralelo de 31 unidades operativas
- **Identificación**: Incorporación de metadatos de carpeta origen
- **Consolidación**: Unificación en dataset coherente

**Transformaciones Aplicadas**

_Normalización Temporal_

- **Timestamp Chile**: Conversión a formato POSIXct
- **Timestamp UTC**: Sincronización con estándar internacional
- **Zona horaria**: Conservación de huso local (America/Santiago)

_Clasificación de Calidad de Señal_
_Escala DOP (Dilution of Precision)_:

- `Excelente`: $DOP < 1$
- `Muy Buena`: $1 <= DOP < 2$
- `Buena`: $2 <= DOP < 5$
- `Regular`: $5 <= DOP <= 10$
- `Mala`: $DOP > 10$

_Optimización de Tipos de Datos_

- **Coordenadas**: Conversión a numérico con estandarización decimal
- **Identificadores**: Transformación a factores para análisis categórico
- **Distancias**: Normalización de formatos numéricos

**Variables Críticas Procesadas**

- `EVT_GPS_TIME_CHILE_STR`, `EVT_GPS_TIME_UTC_0` -> POSIXct
- `EVT_SERVICIO_ID`, `EVT_PPU` -> Factor
- `Y_EVT_GPS_LAT`, `X_EVT_GPS_LON` -> Numérico
- `EVT_DISTANCIA_RECORRIDA` -> Numérico
- `EVT_SEÑAL` -> Factor (derivado de DOP)

### Análisis por Unidad Operativa

**Patrones de Operación por Unidad**

_Frecuencia de Reporte_

- **Típico**: 1:00-1:03 minutos entre registros por vehículo
- **Variaciones**: UN52_265 muestra intervalos más irregulares (3.5s - 1min)
- **Consistencia**: Mayoría mantiene intervalos estables

_Distribución por Unidad_

- **Mayor volumen**: UN80_274 (1459884 registros)
- **Menor volumen**: UN52_265 (118026 registros)
- **Promedio por unidad**: ~699479 registros

_Características Específicas Destacables_

- **UN13_247**: Operación exclusiva de ruta "13GS"
- **UN18_254**: Frecuencia muy consistente (1:03-1:03.5 min)
- **UN22_257**: Mayor variabilidad en intervalos (59s - 22:31 min)
- **UNB0_277**: Única unidad con datos en septiembre

## Data accidentes de carabineros.xlsx

```{r getData2, eval=FALSE, include=FALSE}
# Data accidentes de carabineros.xlsx
police.accidents <- read_excel("data/Data accidentes de carabineros.xlsx", 
    col_types = c("numeric", "date", "skip", 
        "date", "text", "text", "text", "text", 
        "text", "numeric", "numeric", "numeric", 
        "numeric", "numeric", "text", "text", 
        "text", "text", "text"))
police.accidents$FECHA <- paste(police.accidents$FECHA, police.accidents$HORA %>% format(format = "%H:%M:%S")) %>% as.POSIXct(format = "%Y-%m-%d %H:%M")
police.accidents <- police.accidents %>% select(-HORA)
police.accidents$ZONA <- police.accidents$ZONA %>% as.factor()
police.accidents$COMUNA <- police.accidents$COMUNA %>% as.factor()
police.accidents$TIPO <- police.accidents$TIPO %>% as.factor()
police.accidents$CAUSA <- police.accidents$CAUSA %>% as.factor()
police.accidents$SECTOR <- police.accidents$SECTOR %>% as.factor()
police.accidents$KM <- police.accidents$KM %>% as.numeric()
police.accidents$PARTE <- police.accidents$PARTE %>% as.numeric()
police.accidents$TRIBUNAL <- police.accidents$TRIBUNAL %>% as.factor()
police.accidents$TIPO %>% summary()
police.accidents$`MACRO TIPO` <- police.accidents$TIPO %>% as.character()
police.accidents$`MACRO TIPO`[
  police.accidents$TIPO %in% c(
    "CHOQUE",
    "CHOQUE FRONTAL",
    "CHOQUE LATERAL",
    "CHOQUE POSTERIOR"
  )
] <- "CHOQUE"
police.accidents$`MACRO TIPO`[
  police.accidents$TIPO %in% c(
    "COLISION",
    "COLISION FRONTAL",
    "COLISION LATERAL",
    "COLISION PERPENDICULAR",
    "COLISION POR ALCANCE"
  )
] <- "COLISION"
police.accidents$`MACRO TIPO` <- police.accidents$`MACRO TIPO` %>% as.factor()
police.accidents %>% summary()
```

El dataset comprende 5739 registros de accidentes de tránsito documentados por Carabineros de Chile durante un período concentrado de 30 días.

### Período de Análisis

- **Cobertura temporal**: 1 al 30 de marzo de 2025 (30 días)
- **Registros diarios promedio**: aproximadamente 191 accidentes

### Distribución Geográfica

- **Regiones con mayor siniestralidad**:
    - Región Metropolitana (1513 casos)
    - Región del Biobío (699 casos)
    - Región del Maule (574 casos)
- **Comunas más afectadas**:
    - Concepción (193 accidentes)
    - Temuco (175 accidentes)
    - Arica (150 accidentes)

### Clasificación de Accidentes

- **Tipos predominantes**:
    - Colisión: 2,936 casos
    - Choque: 1,801 casos
    - Atropello: 461 casos
- **Distribución por sector**:
    - Urbano: 4,432 casos
    - Rural: 1,304 casos
    - Vía férrea: 3 casos

### Procesamiento y Normalización de Datos

**Optimizaciones Aplicadas**

- **Unificación temporal**: Fusión de campos "FECHA" y "HORA" en timestamp único
- **Normalización de tipos de datos**:
    - **Conversión a factor**: ZONA, COMUNA, TIPO, CAUSA, SECTOR, TRIBUNAL
    - **Conversión a numérico**: KM (donde aplicable) y PARTE

**Creación de Categorías Agrupadas**

- **Variable "MACRO TIPO"**:
    - **CHOQUE**: Agrupa "CHOQUE", "CHOQUE FRONTAL", "CHOQUE LATERAL", "CHOQUE POSTERIOR"
    - **COLISION**: Agrupa "COLISION", "COLISION FRONTAL", "COLISION LATERAL", "COLISION PERPENDICULAR", "COLISION POR ALCANCE"
    - **Conserva valores originales** para categorías no agrupables

### Observaciones Relevantes

La concentración temporal del dataset (solo 30 días) permite un análisis detallado de patrones de siniestralidad en un período específico, aunque limita la identificación de tendencias estacionales. La predominancia de accidentes en zonas urbanas refleja la distribución poblacional y de tráfico vehicular del país.

## Incidentes de tráfico radio.xlsx

```{r getData3, eval=FALSE, include=FALSE}
# Incidentes de tráfico radio.xlsx
file.path <- "data/Incidentes de tráfico radio.xlsx"
sheet.names <- file.path %>% excel_sheets()
date.sheets <- sheet.names[grepl("^\\d{1,2}-\\d{1,2}$", sheet.names)]
radio.accidents <- list()
cell.colors <- list()
get.cells.colors <- function(file.path, sheet.name, column.indices) {
  wb <- file.path %>% loadWorkbook()
  styles <- wb %>% getStyles()
  sheet <- wb[[sheet.name]]
  colors.list <- list()
  for(col.idx in column.indices) {
    col.letter <- col.idx %>% int2col()
    cell.refs <- paste0(col.letter, 1:(sheet$rows %>% length()))
    colors <- sapply(cell.refs, function(cell.ref) {
      cell.style <- sheet$styleObjects[[which(sapply(sheet$styleObjects, function(x) x$rows == as.numeric(gsub("\\D", "", cell.ref)) & x$cols == col.idx))]]
      if(!is.null(cell.style)) {
        cell.style$style$fill$fillFg
      } else {
        NA
      }
    })
    colors.list[[colnames(sheet)[col.idx]]] <- colors
  }
  colors.list
}
get.cell.colors.simple <- function(file.path, sheet.name) {
  wb <- file.path %>% loadWorkbook()
  all.styles <- wb %>% getStyles()
  sheet.styles <- wb$styleObjects[grepl(paste0("^", sheet.name, "\\."), wb$styleObjects %>% names())]
  sheet.data <- wb %>% read.xlsx(sheet = sheet.name)
  col.names <- sheet.data %>% names()
  tipo.cols <- (col.names %in% c("Tipo de incidente", "tipo de incidente")) %>% which()
  if(length(tipo.cols) == 0){
    list()
  } else {
    colors.df <- NA %>% matrix(nrow = sheet.data %>% nrow(), ncol = tipo.cols %>% length()) %>% data.frame()
    names(colors.df) <- col.names[tipo.cols]
    for(style.obj in wb$styleObjects) {
      if(style.obj$sheet == sheet.name && style.obj$cols %in% tipo.cols) {
        col.name <- col.names[style.obj$cols]
        for(row in style.obj$rows) {
          if(row <= colors.df %>% nrow()) {
            colors.df[row, col.name] <- style.obj$style$fill$fillFg
          }
        }
      }
    }
    colors.df
  }
}
get.cell.colors.tidyxl <- function(file.path, sheet.name) {
  cells <- file.path %>% xlsx_cells(sheets = sheet.name)
  formats <- file.path %>% xlsx_formats()
  target.cols <- c("Tipo de incidente", "tipo de incidente")
  col.indices <- cells %>%
    filter(!(character %>% is.na()) | !(numeric %>% is.na())) %>% 
    group_by(col) %>%
    summarise(
      header = character %>% first(na_rm = T),
      .groups = "drop"
    ) %>%
    filter(header %in% target.cols) %>%
    pull(col)
  if(col.indices %>% length() == 0){
    data.frame(
      row = integer(),
      col = integer(),
      color = character()
    )
  } else {
    colors.df <- cells %>%
      filter(col %in% col.indices) %>%
      select(row, col, address, character, numeric, local_format_id) %>%
      mutate(
        value = coalesce(character, numeric %>% as.character())
      ) %>%
      mutate(
        color = ifelse(
          !(local_format_id %>% is.na()),
          formats$local$fill$patternFill$fgColor$rgb[local_format_id],
          NA_character_
        )
      ) %>%
      select(row, col, value, color)
    colors.df
  }
}
for(sheet in date.sheets) {
  df <- file.path %>% read_excel(sheet = sheet)
  colors.info <- get.cell.colors.tidyxl(file.path, sheet)
  day.month <- (sheet %>% strsplit(., "-"))[[1]]
  day <- day.month[1] %>% as.numeric()
  month <- day.month[2] %>% as.numeric()
  ## ¿De qué año es?
  comp.date <- paste("2024", month, day, sep = "-") %>% as.Date()
  df$fecha <- comp.date
  df$`#ID` <- df$`#ID` %>% as.numeric()
  df$Hora <- df$Hora %>% as.numeric() %>% as.POSIXct() %>% format(format = "%H:%M")
  radio.accidents[[sheet]] <- df
  cell.colors[[sheet]] <- colors.info
}
radio.accidents.df <- radio.accidents %>% bind_rows()
all.colors.df <- cell.colors %>% bind_rows(.id = "sheet.name")
radio.accidents.df$sheet.name <- NA_character_
radio.accidents.df$original.row <- NA_integer_
row.counter <- 1
for(sheet in date.sheets) {
  n.rows <- radio.accidents[[sheet]] %>% nrow()
  if(n.rows > 0) {
    radio.accidents.df$sheet.name[row.counter:(row.counter + n.rows - 1)] <- sheet
    radio.accidents.df$original.row[row.counter:(row.counter + n.rows - 1)] <- 1:n.rows
  }
  row.counter <- row.counter + n.rows
}
radio.accidents.df <- radio.accidents.df %>%
  left_join(
    all.colors.df %>%
      select(sheet.name, row, color) %>%
      rename(original.row = row),
    by = c("sheet.name", "original.row")
  )
radio.accidents.df <- radio.accidents.df[!(radio.accidents.df$coord %>% is.na() | radio.accidents.df$`Reporte completo? (SI/NO)` %>% is.na()),]
radio.accidents.df$coord[!(radio.accidents.df$lat %>% is.na())] <- radio.accidents.df$lat[!(radio.accidents.df$lat %>% is.na())]
radio.accidents.df <- radio.accidents.df %>% select(-c(lat, `tipo de incidente`, ...7, ...13, sheet.name, original.row))
radio.accidents.df$dir[!(radio.accidents.df$...12 %>% is.na()) & (radio.accidents.df$dir %>% is.na())] <- radio.accidents.df$...12[!(radio.accidents.df$...12 %>% is.na()) & (radio.accidents.df$dir %>% is.na())]
radio.accidents.df <- radio.accidents.df %>% select(-...12)
radio.accidents.df$`Reporte completo? (SI/NO)`[(radio.accidents.df$`Reporte completo? (SI/NO)` %in% c("is", "si", "SI", "su")) %>% which()] = "SI"
radio.accidents.df$`Reporte completo? (SI/NO)`[(radio.accidents.df$`Reporte completo? (SI/NO)` %in% c("no", "NO")) %>% which()] = "NO"
radio.accidents.df$`Reporte completo? (SI/NO)`[(radio.accidents.df$`Reporte completo? (SI/NO)` == "-") %>% which()] = NA
radio.accidents.df$`es incidente de tráfico? (si/no)`[(radio.accidents.df$`es incidente de tráfico? (si/no)` %in% c("si", "SI")) %>% which()] <- "SI"
radio.accidents.df$`es incidente de tráfico? (si/no)`[(radio.accidents.df$`es incidente de tráfico? (si/no)` %in% c("no", "NO")) %>% which()] <- "NO"
radio.accidents.df$dir[radio.accidents.df$dir %in% c("-", "n/a", "n/A")] <- NA
radio.accidents.df$dir[radio.accidents.df$dir %in% c("e-o", "E-O")] <- "E-O"
radio.accidents.df$dir[radio.accidents.df$dir %in% c("o-e", "O-E")] <- "O-E"
radio.accidents.df$dir[radio.accidents.df$dir %in% c("n-s", "n.s", "N-S")] <- "N-S"
radio.accidents.df$dir[radio.accidents.df$dir %in% c("s-n", "S-N")] <- "S-N"
radio.accidents.df$dir[radio.accidents.df$dir %in% c("n-s. s-n", "n-s.s-n", "N-S, S-N")] <- "N-S, S-N"
radio.accidents.df$dir[radio.accidents.df$dir %in% c("s-n.n-s", "S-N, N-S")] <- "S-N, N-S"
radio.accidents.df$`Reporte completo? (SI/NO)` <- radio.accidents.df$`Reporte completo? (SI/NO)` %>% as.factor()
radio.accidents.df$`es incidente de tráfico? (si/no)` <- radio.accidents.df$`es incidente de tráfico? (si/no)` %>% as.factor()
radio.accidents.df$dir <- radio.accidents.df$dir %>% as.factor()
radio.accidents.df$color <- radio.accidents.df$color %>% as.factor()
color_mapping <- c(
  "FF00B0F0" = "Intervenciones de Emergencia", 
  "FF00FFFF" = "Congestión",
  "FFFF0000" = "Accidente de tránsito",
  "FFFF00FF" = "Obstrucciones en la vía",
  "FFFF6600" = "Problema Infraestructura de control de tránsito",
  "FFFFC000" = "Condición de tráfico",
  "FFFFFF00" = "Congestión",
  "FF00B050" = "Otros"
)
radio.accidents.df$`Tipo de incidente` <- ifelse(
  radio.accidents.df$color %>% is.na(),
  "Congestión",
  color_mapping[radio.accidents.df$color]
) %>% as.factor()
radio.accidents.df <- radio.accidents.df %>% select(-color)
radio.accidents.df <- radio.accidents.df %>% fill(Hora, .direction = "down")
radio.accidents.df <- radio.accidents.df %>% separate(coord, into = c("lat", "lng"), sep = ",\\s*") %>% mutate(lat = lat %>% as.numeric(), lng = lng %>% as.numeric())
radio.accidents.df <- radio.accidents.df[!(radio.accidents.df$lat %>% is.na()),]
radio.accidents.df$Hora <- paste(radio.accidents.df$fecha, radio.accidents.df$Hora) %>% as.POSIXct(format = "%Y-%m-%d %H:%M")
radio.accidents.df <- radio.accidents.df %>% select(-fecha)
radio.accidents.df %>% summary()
```

El dataset contiene 312 registros de incidentes de tráfico reportados a través de sistemas de radio durante un período de 37 días.

### Período de Registro

- **Duración**: 15 de julio al 20 de agosto (año no especificado)
- **Cobertura temporal**: 37 días de monitoreo continuo

### Clasificación de Incidentes

- **Naturaleza del incidente**:
    - **Incidentes de tráfico**: 263 casos
    - **No incidentes de tráfico**: 1 caso
    - **No especificado**: 48 casos
- **Completitud de reportes**:
    - **Reportes completos**: 257 casos
    - **Reportes incompletos**: 55 casos

### Tipología de Incidentes

*Distribución por categoría*:

- Congestión: 191 casos
- Obstrucciones en la vía: 38 casos
- Condición de tráfico: 26 casos
- Problema Infraestructura de control de tránsito: 25 casos
- Accidentes de tránsito: 20
- Intervenciones de emergencia: 7 casos
- Otros: 5 casos

### Direccionalidad del Tráfico Afectado

**Patrones de flujo vehicular impactado**:

- Sur a Norte (S-N): 53 casos
- Norte a Sur (N-S): 51 casos
- Bidireccional (N-S, S-N): 17 casos
- Este a Oeste (E-O): 15 casos
- Oeste a Este (O-E): 10 casos
- Ambos sentidos (a/s): 2 casos
- Bidireccional (S-N, N-S): 1 caso
- No especificado: 163 casos

### Aspectos Requieren Clarificación

**Información Crítica Faltante**

- **Año de referencia**: No especificado en los datos originales
- **Categorías direccionales**: Necesidad de confirmar si "N-S, S-N" y "S-N, N-S" representan categorías distintas o requieren unificación

### Procesamiento y Normalización de Datos

**Extracción y Estructuración**

- **Identificación de hojas relevantes**: Filtrado por nombres con formato fecha (dd-mm)
- **Consolidación temporal**: Unificación de 37 hojas diarias en dataset único
- **Construcción de timeline**: Asignación de fechas basada en nombres de hojas

**Limpieza y Estandarización**

*Normalización de Variables Categóricas*:

- **"Reporte completo? (SI/NO)"**:
    - *Valores estandarizados*: "SI" para ["is", "si", "SI", "su"], "NO" para ["no", "NO"]
    - *Valores excluidos*: "-" convertido a NA
- **"es incidente de tráfico? (si/no)"**:
    - *Valores estandarizados*: "SI" para ["si", "SI"], "NO" para ["no", "NO"]
- *Direccionalidad ("dir")*:
    - *Normalización de notaciones*: Unificación de variantes ("e-o" -> "E-O", "n-s" -> "N-S", etc.)
    - *Patrones bidireccionales*: Estandarización de formatos compuestos
    - *Valores inválidos*: ["-", "n/a", "n/A"] convertidos a NA

**Sistema de Clasificación por Color**

*Mapeo cromático de tipos de incidente*:

- `FF00B0F0` -> Intervenciones de Emergencia
- `FF00FFFF`, `FFFFFF00`, `NA` -> Congestión
- `FFFF0000` -> Accidente de tránsito
- `FFFF00FF` -> Obstrucciones en la vía
- `FFFF6600` -> Problema Infraestructura de control
- `FFFFC000` -> Condición de tráfico
- `FF00B050` -> Otros

**Optimizaciones Geográficas y Temporales**

- **Coordenadas**: Separación de campo "coord" en latitud/longitud numéricas
- **Timestamp**: Fusión de fecha y hora en campo datetime unificado
- **Completitud**: Rellenado de horas faltantes con valores anteriores
- **Estructura de datos**: Conversión de variables clave a tipo factor

## Med velo CHIGUAYANTE.xlsx

```{r getData4, eval=FALSE, include=FALSE}
# Med velo CHIGUAYANTE.xlsx
date <- "2024-06-25"
file.path <- "data/Med velo CHIGUAYANTE.xlsx"
directions <- file.path %>% excel_sheets()
chiguayante.speed <- list()
for(sheet in directions) {
  df <- file.path %>% read_excel(sheet = sheet)
  df$dirección <- sheet
  df$`Lugar (dirección)` <- df$`Lugar (dirección)`[!(df$`Lugar (dirección)` %>% is.na())] %>% paste(collapse = ", ")
  chiguayante.speed[[sheet]] <- df
}
chiguayante.speed.df <- chiguayante.speed %>% bind_rows()
chiguayante.speed.df <- chiguayante.speed.df %>% select(-c(...5, ...6, ...7, ...8, ...9, ...10, ...11, ...12, ...13))
chiguayante.speed.df <- chiguayante.speed.df[!(chiguayante.speed.df$`Velocidad [km/hr]` %>% is.na()),]
chiguayante.speed.df <- chiguayante.speed.df %>% fill(Hora, .direction = "down")
chiguayante.speed.df$Hora <- paste(date, chiguayante.speed.df$Hora %>% as.POSIXct() %>% format(., "%H:%M:%S")) %>% as.POSIXct(format = "%Y-%m-%d %H:%M:%S")
chiguayante.speed.df$Comentario[chiguayante.speed.df$Comentario %in% c(
  "auto, doblo a Lo Plaza",
  "Auto, doblo a Lo Plaza",
  "Auto, gira a Lo Plaza"
)] <- "Auto, dobló a Lo Plaza"
chiguayante.speed.df$Comentario[chiguayante.speed.df$Comentario %in% c(
  "camion",
  "Camion"
)] <- "Camión"
chiguayante.speed.df$Comentario[chiguayante.speed.df$Comentario %in% c(
  "micro",
  "Micro"
)] <- "Micro"
chiguayante.speed.df$Comentario <- chiguayante.speed.df$Comentario %>% as.factor()
chiguayante.speed.df$dirección <- chiguayante.speed.df$dirección %>% as.factor()
chiguayante.speed.df$`Lugar (dirección)` <- chiguayante.speed.df$`Lugar (dirección)` %>% as.factor()
chiguayante.speed.df$Vehículo <- "Auto"
chiguayante.speed.df$Vehículo[chiguayante.speed.df$Comentario %in% c("Camión", "Micro", "MOTO", "retroexcavadora")] <- chiguayante.speed.df$Comentario[chiguayante.speed.df$Comentario %in% c("Camión", "Micro", "MOTO", "retroexcavadora")] %>% as.character()
chiguayante.speed.df$Vehículo <- chiguayante.speed.df$Vehículo %>% as.factor()
chiguayante.speed.df %>% summary()
```

El dataset contiene 338 mediciones de velocidad vehicular capturadas en el paradero "Bdo O'Higgins - Arauco" de Chiguayante, monitoreando el flujo entre Concepción y Hualqui.

### Contexto Operacional

- **Ubicación**: Paradero "Bdo O'Higgins - Arauco", Chiguayante
- **Corredor vial**: Concepción - Hualqui
- **Período de medición**: 26 de junio de 2024 entre las 09:06 y las 17:58 horas
- **Duración**: Aproximadamente 9 horas de monitoreo continuo

### Análisis de Velocidades

- **Rango de velocidades**: 3 a 71 km/h
- **Velocidad promedio**: 44.27 km/h
- **Velocidad mediana**: 43 km/h
- **Distribución**: Relativamente simétrica alrededor de la mediana

### Composición Vehicular

**Tipos de vehículos identificados**:

- **Automóviles**: 273 registros
- **Microbuses**: 52 registros
- **Camiones**: 9 registros
- **Motos**: 3 registros
- **Retroexcavadora**: 1 registro

### Patrones de Movimiento

**Distribución direccional**:

- **Hacia Concepción**: 163 mediciones
- **Hacia Hualqui**: 175 mediciones
- **Balance**: Ligero predominio del flujo hacia Hualqui

### Comportamientos Específicos

**Maniobras documentadas**:

- "Auto, dobló a Lo Plaza": 8 casos
- "Auto, iba a doblar a Lo Plaza": 1 caso
- "auto, se percibe cola": 1 caso

### Aspectos que Requieren Clarificación

**Información Crítica Faltante**

- **Fecha de medición**: No especificada en los datos originales
- **Clasificación vehicular**: Necesidad de confirmar si vehículos sin comentario deben categorizarse automáticamente como "Auto"

### Procesamiento y Normalización de Datos

**Estructuración Multi-hoja**

- **Organización por dirección**: Cada hoja representa una dirección de flujo (Concepción->Hualqui / Hualqui->Concepción)
- **Consolidación**: Unificación de todas las hojas en dataset único
- **Metadatos direccionales**: Incorporación de columna "dirección" desde nombres de hojas

**Limpieza y Estandarización**

*Normalización de Localización*

- **Unificación geográfica**: Campo "Lugar (dirección)" consolidado por hoja
- **Eliminación de redundancias**: Remoción de 9 columnas vacías o duplicadas (...5 a ...13)

*Procesamiento Temporal*

- **Completitud horaria**: Rellenado de valores faltantes usando observaciones anteriores
- **Formato estandarizado**: Conversión a tipo hms para análisis temporal

*Estandarización de Categorías*

Comentarios vehiculares:

- *Maniobras*: Unificación de variantes ["auto, doblo a Lo Plaza", "Auto, doblo a Lo Plaza", "Auto, gira a Lo Plaza"] -> "Auto, dobló a Lo Plaza"
- *Tipos vehiculares*: Normalización de ["camion", "Camion"] -> "Camión" y ["micro", "Micro"] -> "Micro"

*Clasificación Vehicular Sistematizada*

Variable "Vehículo":

- *Valor por defecto*: "Auto" para registros sin comentario o con referencias a automóviles
- *Especificación*: Conservación de categorías explícitas ["Camión", "Micro", "MOTO", "retroexcavadora"]
- *Optimización*: Conversión a tipo factor para análisis categórico

**Optimizaciones Finales**

- **Estructuración**: Conversión de variables clave a tipo factor
- **Consistencia**: Validación de integridad de datos numéricos
- **Preparación analítica**: Dataset listo para análisis estadístico y temporal

## Med velo LA VEGA.xlsx

```{r getData5, eval=FALSE, include=FALSE}
#Med velo LA VEGA.xlsx
date <- "2024-06-25"
file.path <- "data/Med velo LA VEGA.xlsx"
sheets <- excel_sheets(file.path)
directions <- sheets[grepl("21", sheets) & grepl("mayo", sheets)]
vega.speed <- list()
for(sheet in directions) {
  df <- file.path %>% openxlsx::read.xlsx(sheet = sheet, colNames = T, fillMergedCells = T, detectDates = T, skipEmptyCols = F, skipEmptyRows = F)
  df <- df[, 2:5]
  df$Hora[!(df$Hora %>% is.na()) & df$Hora %>% as.numeric() > 1 & !((!(df$Hora %>% is.na()) & df$Hora %>% as.numeric() %>% is.numeric() & df$Hora %>% as.numeric() > 1) %>% is.na())] <- ((df$Hora[!(df$Hora %>% is.na()) & df$Hora %>% as.numeric() > 1 & !((!(df$Hora %>% is.na()) & df$Hora %>% as.numeric() %>% is.numeric() & df$Hora %>% as.numeric() > 1) %>% is.na())] %>% as.numeric() %>% round(digits = 2)) / 24) %>% as.character()
  df <- df %>% fill(Hora, .direction = "down")
  hour <- ((df$Hora %>% as.numeric()) * 24) %>% floor()
  minute <- (((df$Hora %>% as.numeric()) * 24 - hour) * 60) %>% floor()
  df$Hora <- sprintf("%02d:%02d:00", hour, minute)
  df$Hora <- paste(date, df$Hora) %>% as.POSIXct(format = "%Y-%m-%d %H:%M:%S")
  df$dirección <- sheet
  df$`Lugar.(dirección)` <- df$`Lugar.(dirección)`[!(df$`Lugar.(dirección)` %>% is.na())] %>% paste(collapse = ", ")
  vega.speed[[sheet]] <- df
}
vega.speed.df <- vega.speed %>% bind_rows()
vega.speed.df <- vega.speed.df[!(vega.speed.df$`Velocidad.[km/hr]` %>% is.na()),]
vega.speed.df$Comentario[vega.speed.df$Comentario %in% c(
  "cola por funeral",
  "forman cola"
)] <- "Forman cola"
vega.speed.df$Comentario[vega.speed.df$Comentario %in% c(
  "llega a cola",
  "llegan a cola",
  "llegan a cola, aprox 4 vehiculos",
  "llegan a cola formada antes de medir"
)] <- "Llega a cola"
vega.speed.df$Comentario[vega.speed.df$Comentario %in% c(
  "llegan juntos",
  "llegan juntos ",
  "llegan juntos, cola aprox 8 a 10 autos",
  "llegan juntos, generan cola"
)] <- "Llegan juntos"
vega.speed.df$Comentario[vega.speed.df$Comentario %in% c(
  "micro",
  "Micro"
)] <- "Micro"
vega.speed.df$Comentario[vega.speed.df$Comentario %in% c(
  "moto",
  "Moto"
)] <- "Moto"
vega.speed.df$Comentario <- vega.speed.df$Comentario %>% as.factor()
vega.speed.df$`Lugar.(dirección)` <- vega.speed.df$`Lugar.(dirección)` %>% as.factor()
vega.speed.df$dirección <- vega.speed.df$dirección %>% as.factor()
vega.speed.df %>% summary()
```

El dataset contiene 432 mediciones de velocidad vehicular capturadas en el cruce de Briceños con Miraflores, monitoreando el flujo entre 21 de Mayo y Avenida Costanera a través del sector Miraflores.

### Contexto Operacional

- **Ubicación**: Esquina Briceños con Miraflores, La Vega
- **Corredores viales**:
    - 21 de Mayo -> Briceños -> Miraflores
    - Av. Costanera -> Miraflores -> 21 de Mayo
- **Período de medición**: 25 de junio de 2024 entre las 08:08 y las 17:58 horas
- **Duración**: Aproximadamente 10 horas de monitoreo continuo

### Análisis de Velocidades

- **Rango de velocidades**: 5 a 23 km/h
- **Velocidad promedio**: 28.87 km/h
- **Velocidad mediana**: 29 km/h
- **Distribución**: Concentrada en velocidades bajas-medias, típicas de tráfico urbano congestionado

### Patrones de Movimiento

**Distribución direccional**:

- **Desde 21 de Mayo**: 250 mediciones
- **Hacia 21 de Mayo**: 182 mediciones
- **Balance**: Predominio del flujo desde 21 de Mayo

### Fenómenos de Congestión Documentados

**Patrones de formación de colas**:

- "Llegan juntos": 49 casos - agrupamiento vehicular sincronizado
- "Llega a cola": 22 casos - incorporación a colas existentes
- "Forman cola": 14 casos - generación de nuevas colas

**Composición vehicular adicional**:

- **Microbuses**: Registros específicamente identificados
- **Motocicletas**: Registros categorizados separadamente

### Aspectos que Requieren Clarificación

**Información Crítica Faltante**:

- **Fecha de medición**: No especificada en los datos originales
- **Contexto temporal**: Día de semana vs. fin de semana no identificado

### Procesamiento y Normalización de Datos

**Estrategia de Extracción Multi-hoja**:

- **Filtrado inteligente**: Identificación de hojas relevantes mediante patrones "21" y "mayo"
- **Organización direccional**: Cada hoja representa un sentido de flujo específico
- **Consolidación estructurada**: Unificación de múltiples hojas en dataset coherente

**Corrección de Formatos Temporales**

*Normalización de Horarios*

- **Problema identificado**: Formato decimal incorrecto en celdas horarias (ej: "8,15" en lugar de "8:15")
- **Solución aplicada**:
    - Conversión de formato decimal a fracción diaria
    - Reconstrucción de horas y minutos mediante operaciones matemáticas
    - Formateo consistente a "HH:MM:SS"

*Completitud de Series Temporales*

- **Rellenado inteligente**: Propagación de valores horarios hacia adelante
- **Consistencia temporal**: Garantía de continuidad en las mediciones

**Estandarización de Categorías y Comentarios**

*Unificación de Términos de Congestión*

Agrupamiento por patrones:

- *Formación de colas*: ["cola por funeral", "forman cola"] -> "Forman cola"
- *Incorporación a colas*: Variantes de "llega a cola" unificadas
- *Agrupamiento vehicular*: Múltiples expresiones de "llegan juntos" estandarizadas

*Clasificación Vehicular*

- *Transporte público*: ["micro", "Micro"] -> "Micro"
- *Motocicletas*: ["moto", "Moto"] -> "Moto"

### Optimizaciones Estructurales

- **Geolocalización unificada**: Consolidación de "Lugar.(dirección)" por hoja
- **Metadatos direccionales**: Incorporación sistemática desde nombres de hojas
- **Tipificación eficiente**: Conversión a factores para análisis categórico
- **Limpieza de datos**: Eliminación de registros sin medición de velocidad

## tb_gps_historial_eventos_202509161626(1).csv

```{r getData6, eval=FALSE, include=FALSE}
# tb_gps_historial_eventos_202509161626(1).csv
gps.events <- read_file("data/tb_gps_historial_eventos_202509161626(1).csv") %>% str_replace_all(., "\";\"", " ") %>% str_replace_all(., ",", ";") %>% str_replace_all(., "\"", "") %>% read.table(text = ., sep = ";", header = T, stringsAsFactors = F)
gps.events <- gps.events %>% select(-c(ubicacion_, velocidad_))
gps.events$fecha_auto <- gps.events$fecha_auto %>% as.POSIXct(format = "%Y-%m-%d %H:%M:%S")
gps.events$fecha_gps_ <- gps.events$fecha_gps_ %>% as.POSIXct(format = "%Y-%m-%d %H:%M:%S")
gps.events$evento_ <- gps.events$evento_ %>% as.factor()
gps.events$direccion_ <- gps.events$direccion_ %>% as.factor()
gps.events %>% nrow()
gps.events %>% summary()
```

El dataset contiene 1000 eventos registrados por sistemas GPS vehiculares, capturando transiciones de estado en una ventana temporal específica.

### Período de Monitoreo

- **Fecha de referencia**: Transición año nuevo 2024-2025
- **Según timestamp del auto**: 1 de enero de 2025, 00:00:06 - 01:06:29 (66 minutos)
- **Según timestamp del GPS**: 31 de diciembre de 2024, 23:59:22 - 1 de enero de 2025, 01:06:49 (67 minutos)
- **Discrepancia temporal**: Diferencia de sincronización entre sistemas de aproximadamente 1 minuto

### Distribución de Estados Vehiculares

**Tipos de eventos registrados**:

- **Apagado**: 552 eventos - vehículo sin operación
- **Detenido**: 264 eventos - vehículo inmovilizado pero encendido
- **Movimiento**: 184 eventos - vehículo en desplazamiento

### Patrones de Direccionalidad

**Valores de dirección registrados**:

- `0`: 316 casos
- `-280`: 184 casos
- `-223`: 184 casos
- `-85`: 184 casos
- `235`: 132 casos

**Observación**: Los valores negativos y positivos sugieren un sistema de coordenadas o ángulos específico.

### Aspectos Requieren Investigación

**Variables Críticas por Clarificar**

- `id_evento`: Valor constante `2` en todos los registros
- `direccion_`:
    - Sistema de representación angular (grados) o coordenadas relativas
    - Significado de valores negativos vs. positivos
    - Relación con puntos cardinales o sistema de referencia

### Procesamiento y Normalización de Datos

**Corrección de Formato de Archivo**

- **Problema original**: Formato CSV con delimitadores inconsistentes y caracteres de escape
- **Transformación aplicada**:
    - Reemplazo de ";" por espacio para unificación
    - Sustitución de , por ; como nuevo delimitador
    - Eliminación de comillas redundantes
- **Resultado**: Estructura tabular legible para importación

**Optimización de Estructura de Datos**

- **Eliminación de columnas vacías**: `ubicacion_` y `velocidad_` removidas por contener exclusivamente valores nulos
- **Normalización temporal**:
    - `fecha_auto` y `fecha_gps_` convertidas a formato datetime
    - Preservación de precisiones de segundos
- **Tipificación categórica**:
    - `evento_` y `direccion_` convertidas a factor para análisis estadístico

## Inventario CCTV Biobío(1).xlsx

```{r getData8, eval=FALSE, include=FALSE}
# Inventario CCTV Biobío(1).xlsx
biobio.inventary <- read_excel("data/Inventario CCTV Biobío(1).xlsx", 
    range = "A2:Q73", na = "----")
colnames(biobio.inventary) <- ifelse(
  grepl("\\...", biobio.inventary %>% colnames()),
  paste((biobio.inventary %>% colnames() %>% str_split_fixed("\\...", n = 2) %>% as.matrix() %>% {.[. == ""] <- NA; .})[, 1], ifelse((biobio.inventary %>% colnames() %>% str_split_fixed("\\...", n = 2) %>% as.matrix() %>% {.[. == ""] <- NA; .})[, 2] %>% as.numeric() <= 11, "DE LA CÁMARA", "DEL CODIFICADOR DE VIDEO")),
  biobio.inventary %>% colnames()
)
biobio.inventary$COMUNA <- biobio.inventary$COMUNA %>% as.factor()
biobio.inventary$ESTADO <- biobio.inventary$ESTADO %>% as.factor()
biobio.inventary$`TIPO DE ENLACE` <- biobio.inventary$`TIPO DE ENLACE` %>% as.factor()
biobio.inventary$PROVEEDOR <- biobio.inventary$PROVEEDOR %>% as.factor()
biobio.inventary$`MARCA DE LA CÁMARA` <- biobio.inventary$`MARCA DE LA CÁMARA` %>% as.factor()
biobio.inventary$`MODELO DE LA CÁMARA` <- biobio.inventary$`MODELO DE LA CÁMARA` %>% as.factor()
biobio.inventary$`MARCA DEL CODIFICADOR DE VIDEO` <- biobio.inventary$`MARCA DEL CODIFICADOR DE VIDEO` %>% as.factor()
biobio.inventary$`MODELO DEL CODIFICADOR DE VIDEO` <- biobio.inventary$`MODELO DEL CODIFICADOR DE VIDEO` %>% as.factor()
biobio.inventary$REGIÓN <- biobio.inventary$REGIÓN %>% as.factor()
biobio.inventary %>% summary()
```

El inventario documenta 71 ubicaciones de cámaras de vigilancia y sus respectivos sistemas de codificación de video desplegados en la Región del Biobío, representando la infraestructura de monitoreo vial regional.

### Distribución Geográfica

- **Comunas con mayor cobertura**:
    - **Concepción**: 31 cámaras
    - **San Pedro de la Paz**: 16 cámaras
    - **Los Ángeles**: 10 cámaras
- **Cobertura regional**: Múltiples comunas del Biobío con sistemas CCTV

### Estado Operacional del Sistema

- **Cámaras online**: 32 unidades
- **Cámaras offline**: 39 unidades
- **Disponibilidad general**: Sistema operando con 45% de disponibilidad inmediata

### Características Técnicas de la Infraestructura

**Conectividad y Proveedores**

- **Tipo de enlace**: 100% digital (71/71 cámaras)
- **Proveedor de servicios**: Exclusivamente "Red Comunicaciones Propia" (71/71)

**Especificaciones de Cámaras**

*Marcas predominantes*:

- Pelco: 38 cámaras
- Avigilon: 10 cámaras
- Axis: 10 cámaras

*Modelos más frecuentes*:

- Pelco Esprit: 27 unidades
- Avigilon 2.0C-H5A-RGDPTZ-DP36: 10 unidades
- Axis AXIS Q8685-E: 10 unidades

**Sistema de Codificación de Video**

*Codificadores identificados*:

- Axis AXIS Q7401: 26 unidades
- Sin especificar: 45 unidades - posiblemente integrados en cámaras o no documentados

### Evolución Temporal del Sistema

- **Rango de integración**: 1 de noviembre de 2003 - 1 de septiembre de 2024
- **Vida útil del sistema**: Más de 20 años de despliegue progresivo
- **Actualizaciones recientes**: Integraciones hasta septiembre 2024

### Procesamiento y Normalización de Datos

**Corrección de Estructura de Columnas**:

- **Problema original**: Columnas duplicadas "MARCA", "MODELO" y "NÚMERO DE SERIE" para cámara y codificador
- **Solución aplicada**:
    - Diferenciación clara mediante sufijos "DE LA CÁMARA" y "DEL CODIFICADOR DE VIDEO"
    - Asignación basada en posición original en el dataset (columnas 1-11: cámara, 12-17: codificador)

**Optimización para Análisis**:

- **Normalización categórica**: Conversión de 9 variables clave a tipo factor:
    - COMUNA
    - ESTADO
    - TIPO DE ENLACE
    - PROVEEDOR
    - MARCA DE LA CÁMARA
    - MODELO DE LA CÁMARA
    - MARCA DEL CODIFICADOR
    - MODELO DEL CODIFICADOR
    - REGIÓN
- **Manejo de valores faltantes**: Identificación explícita de valores "----" como NA

## Alertas de Tráfico.csv

```{r getData7, eval=FALSE, include=FALSE}
# Alertas de Tráfico.csv
trafic.alerts <- read_csv("data/Alertas de Tráfico.csv")
trafic.alerts <- trafic.alerts %>% mutate(
  lng = str_extract(Location, "(?<=Point\\()-?\\d+\\.?\\d*") %>% as.numeric(),
  lat = str_extract(Location, "-?\\d+\\.?\\d*(?=\\)$)") %>% as.numeric()
)
trafic.alerts <- trafic.alerts %>% select(-Location)
trafic.alerts$Date <- trafic.alerts$Date %>% str_replace_all(., setNames(
  c("jan", "feb", "mar", "apr", "may", "jun", "jul", "aug", "sep", "oct", "nov", "dec"),
  c("ene", "feb", "mar", "abr", "may", "jun", "jul", "ago", "sep", "oct", "nov", "dic")
)) %>% dmy()
trafic.alerts$Country <- trafic.alerts$Country %>% as.factor()
trafic.alerts$City <- trafic.alerts$City %>% as.factor()
trafic.alerts$Type <- trafic.alerts$Type %>% as.factor()
trafic.alerts$Subtype <- trafic.alerts$Subtype %>% as.factor()
trafic.alerts %>% summary()
```

El dataset comprende 281759 alertas de tráfico generadas por usuarios de Waze, representando un año completo de reportes ciudadanos sobre condiciones viales en el Gran Concepción.

### Período de Análisis

- **Cobertura temporal**: 23 de junio de 2023 - 15 de mayo de 2024
- **Duración**: Aproximadamente 11 meses de datos continuos
- **Registros diarios promedio**: \~850 alertas por día

### Contexto Geográfico

- **Distribución por ciudad**:
    - Concepción: 130747 alertas
    - San Pedro de la Paz: 51816 alertas
    - Talcahuano: 35122 alertas
    - Otras comunas: 64074 alertas

### Clasificación de Alertas

**Categorías Principales (Type)**

- **Embottellamiento (JAM)**: 178785 casos
- **Peligro (HAZARD)**: 53457 casos
- **Peligro meteorológico (WEATHERHAZARD)**: 35984 casos
- **Otras categorías**: 13533 casos

**Especificaciones por Subcategoría (Subtype)**

*Embottellamientos (JAM)*:

- Tráfico intenso (JAM_HEAVY_TRAFFIC): 77179 casos
- Tráfico paralizado (JAM_STAND_STILL_TRAFFIC): 52298 casos
- Tráfico moderado (JAM_MODERATE_TRAFFIC): 20947 casos

*Peligros (HAZARD)*:

- Vehículo detenido en franja lateral (HAZARD_ON_SHOULDER_CAR_STOPPED): 15869 casos
- Construcción en la vía (HAZARD_ON_ROAD_CONSTRUCTION): 9458 casos
- Peligro en la vía (HAZARD_ON_ROAD): 7494 casos
- Otros peligros: 20636 casos

*Peligros meteorológicos (WEATHERHAZARD)*:

- Vehículo detenido (HAZARD_ON_ROAD_CAR_STOPPED): 9467 casos
- Construcción en la vía (HAZARD_ON_ROAD_CONSTRUCTION): 6287 casos
- Vehículo detenido en franja lateral (HAZARD_ON_SHOULDER_CAR_STOPPED): 6097 casos
- Otros peligros meteorológicos: 14133 casos

### Procesamiento y Normalización de Datos

**Transformación de Coordenadas Geográficas**

- **Problema original**: Campo "Location" en formato WKT (Well-Known Text): `Point(lng lat)`
- **Solución aplicada**:
    - Extracción de longitud (`lng`) mediante regex: `(?<=Point\\()-?\\d+\\.?\\d*`
    - Extracción de latitud (`lat`) mediante regex: `-?\\d+\\.?\\d*(?=\\)$)`
    - Conversión a tipos numéricos para análisis espacial

**Normalización de Fechas**

- **Formato original**: Día-Mes-Año con abreviaturas en español
- **Conversión aplicada**:
    - Mapeo de abreviaturas españolas a inglesas: `{"ene":"jan", "feb":"feb", ..., "dic":"dec"}`
    - Transformación a formato Date usando `dmy()`

**Optimización para Análisis**

- **Tipificación categórica**: Conversión a factor de 4 variables clave:
    - Country
    - City
    - Type
    - Subtype
- Eliminación de redundancias: Remoción de columna "Location" original
- Estructura final: Dataset con 281759 registros × 8 columnas optimizadas

## Copia de Accidentes.csv

```{r getData9, eval=FALSE, include=FALSE}
# Copia de Accidentes.csv
accidents <- read_csv("data/Copia de Accidentes.csv")
accidents <- accidents %>% mutate(
  lng = str_extract(Location, "(?<=Point\\()-?\\d+\\.?\\d*") %>% as.numeric(),
  lat = str_extract(Location, "-?\\d+\\.?\\d*(?=\\)$)") %>% as.numeric()
)
accidents <- accidents %>% select(-Location)
accidents$Date <- accidents$Date %>% str_replace_all(., setNames(
  c("jan", "feb", "mar", "apr", "may", "jun", "jul", "aug", "sep", "oct", "nov", "dec"),
  c("ene", "feb", "mar", "abr", "may", "jun", "jul", "ago", "sep", "oct", "nov", "dic")
)) %>% dmy()
accidents$Country <- accidents$Country %>% as.factor()
accidents$City <- accidents$City %>% as.factor()
accidents %>% summary()
```

El dataset contiene 281981 registros de accidentes de tránsito, proporcionando una visión detallada de la siniestralidad vial en el Gran Concepción durante un período de 11 meses.

### Período de Monitoreo

- **Cobertura temporal**: 23 de junio de 2023 - 15 de mayo de 2024
- **Duración**: 327 días de reportes continuos
- **Densidad de datos**: \~862 accidentes reportados por día en promedio

### Contexto Geográfico

- **Distribución por ciudad**:
    - Concepción: 130516 alertas
    - San Pedro de la Paz: 51704 alertas
    - Talcahuano: 35059 alertas
    - Otras comunas: 64702 alertas

### Métricas de Confiabilidad

- **Rango de fiabilidad**: 5 a 10 puntos (escala no especificada)
- **Fiabilidad promedio**: 5.82 puntos
- **Fiabilidad mediana**: 5 puntos
- **Distribución**: Sesgada hacia valores bajos-medios de la escala

### Procesamiento y Normalización de Datos

**Transformación de Georreferenciación**

- **Formato original**: Campo "Location" en estándar WKT (Well-Known Text)
- **Metodología de extracción**:
    - Longitud (`lng`): Patrón regex `(?<=Point\\()-?\\d+\\.?\\d*`
    - Latitud (`lat`): Patrón regex `-?\\d+\\.?\\d*(?=\\)$)`
- **Resultado**: Coordenadas decimales para análisis geoespacial avanzado

**Estandarización de Fechas**

- **Problema identificado**: Nomenclatura de meses en español
- **Solución implementada**:
    - Mapeo sistemático: `{"ene":"jan", "feb":"feb", ..., "dic":"dec"}`
    - Conversión robusta mediante función `dmy()`
- **Output**: Timeline consistente para análisis temporal

**Optimización de Estructura de Datos**

- **Eliminación de redundancias**: Remoción de columna "Location" original
- **Normalización categórica**:
    - `Country` y `City` convertidas a tipo factor
    - Habilitación de análisis agregados por ubicación
- **Dataset final**: 281981 registros × 7 columnas optimizadas

## Waze for Cities Data Key Alerts Dashboard_Traffic Irregularities_Tabla(1).csv

```{r getData10, eval=FALSE, include=FALSE}
# Waze for Cities Data Key Alerts Dashboard_Traffic Irregularities_Tabla(1).csv
waze.data <- read_csv("data/Waze for Cities Data Key Alerts Dashboard_Traffic Irregularities_Tabla(1).csv", 
    na = "null")
waze.data$Day <- waze.data$Day %>% str_replace_all(., setNames(
  c("jan", "feb", "mar", "apr", "may", "jun", "jul", "aug", "sep", "oct", "nov", "dec"),
  c("ene", "feb", "mar", "abr", "may", "jun", "jul", "ago", "sep", "oct", "nov", "dic")
)) %>% dmy()
waze.data$Country <- waze.data$Country %>% as.factor()
waze.data$City <- waze.data$City %>% as.factor()
waze.data$Street <- waze.data$Street %>% as.factor()
waze.data$Cause <- waze.data$Cause %>% as.factor()
waze.data %>% summary()
```

El dataset contiene 13502 registros de irregularidades de tráfico documentadas a través de la plataforma Waze for Cities, proporcionando métricas detalladas sobre el impacto de incidentes viales en la Región del Biobío durante un período de 11 meses.

### Período de Análisis

- **Cobertura temporal**: 23 de junio de 2023 - 15 de mayo de 2024
- **Duración**: 327 días de monitoreo continuo
- **Frecuencia promedio**: \~41 irregularidades reportadas por día

### Distribución Geográfica

- **Concentración por ciudad**:
    - Concepción: 4236 registros
    - Los Ángeles: 3484 registros
    - San Pedro de la Paz: 2190 registros
    - Otras localidades: 3592 registros

### Clasificación por Causas Identificadas

- **Accidentes (ACCIDENT)**: 839 casos
- **Peligros en la vía (HAZARD)**: 826 casos
- **Carreteras cerradas (ROAD_CLOSED)**: 3 casos
- **Causa no especificada**: 11834 casos

### Métricas de Impacto de Tráfico

**Longitud de Afectación Vial**

- **Rango**: 500 m - 16.61 km
- **Longitud promedio**: 1.34 km
- **Mediana**: 947 m
- **Distribución**: Sesgo hacia afectaciones de mediana extensión

**Tiempos de Desfase**

- **Rango**: 1 minuto 7.33 segundos - 6 horas 27 minutos 26 segundos
- **Desfase promedio**: 11 minutos 4.97 segundos
- **Mediana**: 9 minutos 18.25 segundos
- **Significado**: Retrasos significativos en la movilidad urbana

**Impacto en Usuarios**

- **Usuarios afectados (Impacted Wazers)**: 1 - 122563 personas
- **Promedio de afectados**: 2033 usuarios por incidente
- **Mediana**: 465 usuarios
- **Distribución**: Alta variabilidad con eventos masivos ocasionales

### Procesamiento y Normalización de Datos

**Estandarización Temporal**

- **Formato original**: Fechas con nomenclatura de meses en español
- **Transformación aplicada**:
    - Mapeo sistemático: `{"ene":"jan", "feb":"feb", ..., "dic":"dec"}`
    - Conversión a formato Date mediante `dmy()`
- **Resultado**: Timeline consistente para análisis diario y estacional

**Optimización de Estructura de Datos**

- **Manejo de valores nulos**: Identificación explícita de "null" como NA
- **Normalización categórica**:
    - `Country`, `City`, `Street`, `Cause` convertidas a tipo factor
    - Habilitación de análisis agregados por múltiples dimensiones
- **Dataset final**: 13502 registros × 8 columnas optimizadas

# Discretización de datos

```{r quantum.data, eval=FALSE, include=FALSE}
meters.per.degree.lat <- 111320
meters.per.degree.lng <- function(lat.d) {
  meters.per.degree.lat * cos(lat.d * pi / 180)
}
quantum.data <- function(
  time.data = c(),
  lng.data = c(),
  lat.data = c(),
  field.data = c(),
  time.gap = 5,
  space.gap = 50,
  compile.function = mean
) {
  data.df <- data.frame(
    time = time.data,
    lng = lng.data,
    lat = lat.data,
    field = field.data,
    stringsAsFactors = F
  )
  data.df <- data.df[data.df$time %>% order(),]
  if (time.gap > 0) {
    min.time <- data.df$time %>% min()
    max.time <- data.df$time %>% max()
    time.bins <- seq(from = min.time, to = max.time, by = time.gap)
    data.df$time.bin <- data.df$time %>% cut(breaks = time.bins, include.lowest = T, labels = F)
    data.df$time.bin[data.df$time.bin %>% is.na()] <- data.df$time.bin %>% max(na.rm = T) + 1
  } else {
    data.df$time.bin <- 1:(data.df %>% nrow())
  }
  if(space.gap > 0) {
    lat.range.meters <- (lat.data %>% range()) * meters.per.degree.lat
    lng.range.meters <- (lng.data * (lat.data %>% meters.per.degree.lng)) %>% range()
    lat.bins.meters <- seq(from = lat.range.meters[1], to = lat.range.meters[2], by = space.gap)
    lng.bins.meters <- seq(from = lng.range.meters[1], to = lng.range.meters[2], by = space.gap)
    lat.bins <- lat.bins.meters / meters.per.degree.lat
    lng.bins <- lng.range.meters / (lat.bins %>% meters.per.degree.lng)
    data.df$lat.group <- data.df$lat %>% cut(breaks = lat.bins, include.lowest = T)
    data.df$lng.group <- data.df$lng %>% cut(breaks = lng.bins, include.lowest = T)
    data.df$lat.group[data.df$lat.group %>% is.na()] <- data.df$lat.group %>% max(na.rm = T) + 1
    data.df$lng.group[data.df$lng.group %>% is.na()] <- data.df$lng.group %>% max(na.rm = T) + 1
  } else {
    data.df$lat.group <- 1:(data.df %>% nrow)
    data.df$lng.group <- 1:(data.df %>% nrow)
  }
  result <- data.df %>% 
    group_by(time.bin, lat.group, lng.group) %>% 
    summarise(
      time = time %>% range() %>% mean(na.rm = T),
      lng = lng %>% range() %>% mean(na.rm = T),
      lat = lat %>% range() %>% mean(na.rm = T),
      field = field %>% compile.function(na.rm = T),
      n.points = n(),
      .groups = 'drop'
    )
  final.result <- data.frame(
    time = result$time,
    lng = result$lng,
    lat = result$lat,
    field = result$field,
    n.points = result$n.points
  )
  final.result <- final.result[final.result$time %>% order(),]
  return(final.result)
}
```

## Descripción Matemática

Sea la función:

$$quantum.data: \mathbb{R}^{4\times n}\times\mathbb{R}^2\times(\mathcal{P}(\mathbb{R})\to\mathbb{R})\to\mathbb{R}^{5\times m}$$

Donde:

- **Dominio**: Matrices de datos $4\times n$ + parámetros de discretización + función de compilación
- **Codominio**: Matrices de datos discretizados $5 \times m$ con $m \leq n$

## Parámetros de Entrada

- $\text{time.data} \in \mathbb{R}^n$: Vector temporal (segundos)
- $\text{lng.data} \in \mathbb{R}^n$: Vector de longitudes (grados)
- $\text{lat.data} \in \mathbb{R}^n$: Vector de latitudes (grados)
- $\text{field.data} \in \mathbb{R}^n$: Vector de valores del campo de interés
- $\text{time.gap} \in \mathbb{R}^+$: Intervalo temporal de discretización (segundos)
- $\text{space.gap} \in \mathbb{R}^+$: Intervalo espacial de discretización (metros)
- $\text{compile.function}: \mathcal{P}(\mathbb{R}) \to \mathbb{R}$: Función de agregación (ej: media, máximo, mínimo)

## Proceso de Discretización

### 1. Conversión de Unidades Espaciales

Definimos las constantes de conversión:

$$meters.per.degree.lat\equiv 111320$$

$$meters.per.degree.lng(x)\equiv 111320 \times \cos\left(x \times \frac{\pi}{180}\right)$$

### 2. Discretización Temporal

Para $\text{time.gap} > 0$:

- Sea $t_{\min} = \min(\text{time.data})$, $t_{\max} = \max(\text{time.data})$
- Construimos los intervalos: $B_t = {t_{\min}, t_{\min} + \Delta t, t_{\min} + 2\Delta t, \dots, t_{\max}}$ donde $\Delta t = \text{time.gap}$
- Asignamos cada $t_i$ al bin temporal $b_t(i) = k$ tal que $t_i \in [B_t[k], B_t[k+1])$

### 3. Discretización Espacial

Para $\text{space.gap} > 0$:

- Convertimos rangos a metros:
  - $R_{lat}^m = [\min(\text{lat.data}), \max(\text{lat.data})] \times 111320$
  - $R_{lng}^m = [\min(\text{lng.data} \times f_{lng}), \max(\text{lng.data} \times f_{lng})]$ donde $f_{lng} = \text{meters.per.degree.lng}(\text{lat.media})$
- Construimos bins en metros:
  - $B_{lat}^m = {R_{lat}^m[1], R_{lat}^m[1] + \Delta s, \dots, R_{lat}^m[2]}$
  - $B_{lng}^m = {R_{lng}^m[1], R_{lng}^m[1] + \Delta s, \dots, R_{lng}^m[2]}$ donde $\Delta s = \text{space.gap}$
- Convertimos bins a grados:
  - $B_{lat} = B_{lat}^m / 111320$
  - $B_{lng} = B_{lng}^m / f_{lng}$

### 4. Agregación por Celdas

Para cada celda espacio-temporal $(b_t, b_{lat}, b_{lng})$:

- $\text{time}{celda} = \text{mean}{t_i : t_i \in b_t, lat_i \in b{lat}, lng_i \in b_{lng}}$
- $\text{lng}{celda} = \text{mean}{lng_i : t_i \in b_t, lat_i \in b{lat}, lng_i \in b_{lng}}$
- $\text{lat}{celda} = \text{mean}{lat_i : t_i \in b_t, lat_i \in b{lat}, lng_i \in b_{lng}}$
- $\text{field}{celda} = \text{compile.function}{field_i : t_i \in b_t, lat_i \in b{lat}, lng_i \in b_{lng}}$
- $\text{n.points}{celda} = |{i : t_i \in b_t, lat_i \in b{lat}, lng_i \in b_{lng}}|$

## Salida

La función retorna una matriz $\mathbb{R}^{5 \times m}$ con columnas:

1. $\text{time}$: Tiempo representativo de la celda
2. $\text{lng}$: Longitud representativa de la celda
3. $\text{lat}$: Latitud representativa de la celda
4. $\text{field}$: Valor del campo agregado
5. $\text{n.points}$: Número de puntos originales en la celda

## Propiedades Matemáticas

- **Reducción dimensional**: $m \leq n$ (generalmente $m \ll n$)
- **Conservación de información**: Los valores agregados representan estadísticos de los datos originales
- **Adaptabilidad espacial**: La discretización longitudinal considera la variación métrica con la latitud
- **Robustez**: Manejo de valores en los límites mediante asignación a bins adicionales

Esta función implementa esencialmente un **proceso de cuantización vectorial** en el espacio $\mathbb{R}^3$ (tiempo × latitud × longitud) con métricas adaptativas.


# Visualización de datos

## Accidentes interurbanos

### Distribución por tipo de accidente según CONASET

```{r interurban.bus.accidents0, echo=FALSE, warning=FALSE}
ggplot(interurban.bus.accidents) +
  geom_bar(aes(x = `Tipo (CONASET)` %>% fct_infreq())) +
  labs(x = "Tipo (CONASET)")
```

### Distribución por tipo de accidente

```{r interurban.bus.accidents1, echo=FALSE, warning=FALSE}
ggplot(interurban.bus.accidents) +
  geom_bar(aes(fill = `Tipo (CONASET)` %>% fct_infreq() %>% fct_rev(), y = `Tipo Accidente` %>% fct_infreq() %>% fct_rev())) +
  labs(fill = "Tipo (CONASET)", y = "Tipo Accidente")
```

### Distribución por causa del accidente según CONASET

```{r interurban.bus.accidents2, echo=FALSE, warning=FALSE}
ggplot(interurban.bus.accidents) +
  geom_bar(aes(y = `Causa (CONASET)` %>% fct_infreq() %>% fct_rev(), fill = `Tipo (CONASET)`)) +
  labs(y = "Causa (CONASET)")
```

### Distribución por región del accidente

```{r interurban.bus.accidents3, echo=FALSE, warning=FALSE}
ggplot(interurban.bus.accidents) +
  geom_bar(aes(y = Región %>% fct_infreq() %>% fct_rev(), fill = `Tipo (CONASET)`)) +
  labs(y = "Región")
```

### 10 comunas con más accidentes

```{r interurban.bus.accidents4, echo=FALSE, warning=FALSE}
n <- 10
top <- interurban.bus.accidents %>%
  count(Comuna) %>%
  slice_max(n, n = n) %>%
  pull(Comuna)
ggplot(interurban.bus.accidents[interurban.bus.accidents$Comuna %in% top,]) +
  geom_bar(aes(
    fill = Región,
    y = Comuna %>%
      fct_infreq() %>%
      fct_lump_n(n = n, ties.method = "first") %>%
      fct_rev())) +
  labs(y = "Comuna")
```

## Mediciones de velocidad por satélite


```{r gh0269290, echo=FALSE, warning=FALSE}
ggplot(gh026929) +
  geom_density(aes(x = `GPS (2D speed) [m/s]`))
```


```{r gh0269291.html, echo=FALSE, warning=FALSE, eval=knitr::is_html_output()}
pal <- colorNumeric(
  palette = c("blue", "green", "yellow", "red"),
  domain = gh026929$`GPS (2D speed) [m/s]`
)
leaflet(gh026929) %>%
  addTiles() %>%
  addCircleMarkers(
    lng = ~`GPS (Long.) [deg]`,
    lat = ~`GPS (Lat.) [deg]`,
    color = ~pal(`GPS (2D speed) [m/s]`),
    radius = 6,
    stroke = F,
    fillOpacity = 0.8
  ) %>%
  addLegend(
    "bottomright",
    pal = pal,
    values = ~`GPS (2D speed) [m/s]`,
    title = "Velocidad 2D (m/s)",
    opacity = 1
  ) %>%
  addScaleBar(position = "bottomleft") %>%
  setView(
    lng = mean(gh026929$`GPS (Long.) [deg]`),
    lat = mean(gh026929$`GPS (Lat.) [deg]`),
    zoom = 15
  )
```


```{r gh0269291, echo=FALSE, warning=FALSE, eval=!knitr::is_html_output()}
ggplot() +
  annotation_map_tile(type = "osm", zoom = 15) +
  geom_point(data = gh026929, aes(x = `GPS (Long.) [deg]`, y = `GPS (Lat.) [deg]`, colour = `GPS (2D speed) [m/s]`)) +
  labs(x = "Longitud", y = "Latitud") +
  coord_sf(crs = 4326)
```

Los datos son de diferentes puntos de la Ruta 160 de San Pedro de la Paz

## Accidentes reportados por carabineros

### Distribución por tipo

```{r police.accidents0, echo=FALSE, warning=FALSE}
ggplot(police.accidents) +
  geom_bar(aes(y = TIPO %>% fct_infreq() %>% fct_rev(), fill = `MACRO TIPO`)) +
  labs(y = "TIPO")
```

### Distribución por región

```{r police.accidents1, echo=FALSE, warning=FALSE}
ggplot(police.accidents) +
  geom_bar(aes(y = ZONA %>% fct_infreq() %>% fct_rev(), fill = `MACRO TIPO`)) +
  labs(y = "ZONA")
```

### 10 comunas con más accidentes

```{r police.accidents2, echo=FALSE, warning=FALSE}
n <- 10
top <- police.accidents %>%
  count(COMUNA) %>%
  slice_max(n, n = n) %>%
  pull(COMUNA)
ggplot(police.accidents[police.accidents$COMUNA %in% top,]) +
  geom_bar(aes(
    fill = ZONA,
    y = COMUNA %>%
      fct_infreq() %>%
      fct_lump_n(n = n, ties.method = "first") %>%
      fct_rev())) +
  labs(y = "COMUNA")
```

### Distribución por fecha

```{r police.accidents3, echo=FALSE, warning=FALSE}
ggplot(police.accidents) +
  geom_bar(aes(x = FECHA %>% as.Date(), fill = `MACRO TIPO`)) +
  labs(x = "FECHA")
```

### Distribución por día de la semana

```{r police.accidents4, echo=FALSE, warning=FALSE}
w.days <- c("lunes", "martes", "miércoles", "jueves", "viernes", "sábado", "domingo")
ggplot(police.accidents) +
  geom_bar(aes(x = FECHA %>% weekdays() %>% factor(levels = w.days), fill = `MACRO TIPO`)) +
  labs(x = "DÍA")
```

### Distribución por hora

```{r police.accidents5, echo=FALSE, warning=FALSE}
ggplot(police.accidents) +
  geom_bar(aes(x = FECHA %>% hour(), fill = `MACRO TIPO`)) +
  labs(x = "HORA")
```

## Incidentes reportados por radio

### Distribución por fecha y hora

```{r radio.accidents.df0, echo=FALSE, warning=FALSE}
ggplot(radio.accidents.df) +
  geom_bar(aes(x = Hora %>% as.Date(), fill = Hora %>% hour() %>% as.factor())) +
  labs(x = "Fecha", fill = "Hora")
```

### Distribución por día de la semana

```{r radio.accidents.df1, echo=FALSE, warning=FALSE}
ggplot(radio.accidents.df) +
  geom_bar(aes(x = Hora %>% weekdays() %>% factor(levels = w.days), fill = (Hora %>% floor_date(., "week") + 24 * 3600) %>% as.factor())) +
  labs(x = "Día", fill = "Semana")
```

### Distribución por hora

```{r radio.accidents.df2, echo=FALSE, warning=FALSE}
ggplot(radio.accidents.df) +
  geom_bar(aes(x = Hora %>% hour(), fill = Hora %>% weekdays() %>% factor(levels = w.days))) +
  labs(x = "Hora", fill = "Día")
```

Hubo una gran cantidad de incidentes el día viernes 1ro de agosto a las 21 horas

### Distribución por tipo de incidente durante el 1ro de agosto entre las 20 y 22 horas

```{r radio.accidents.df3, echo=FALSE, warning=FALSE}
peak.radio <- radio.accidents.df[radio.accidents.df$Hora >= "2024-08-01 20:00" & radio.accidents.df$Hora <= "2024-08-01 22:00",]
ggplot(peak.radio) +
  geom_bar(aes(fill = dir, y = `Tipo de incidente` %>%
      fct_infreq() %>%
      fct_rev())) +
  labs(y = "Tipo de incidente")
```

### Distribución geográfica durante el 1ro de agosto entre las 20 y 22 horas

```{r radio.accidents.df4.html, echo=FALSE, warning=FALSE, eval=knitr::is_html_output()}
pal <- colorFactor(
  palette = c("#F0F", "#00F", "#0FF", "#0F0", "#FF0", "#F80", "#F00"),
  domain = peak.radio$`Tipo de incidente`
)
leaflet(peak.radio) %>%
  addTiles() %>%
  addCircleMarkers(
    lng = ~lng,
    lat = ~lat,
    color = ~pal(`Tipo de incidente`),
    radius = 6,
    stroke = F,
    fillOpacity = 0.8
  ) %>%
  addLegend(
    "bottomright",
    pal = pal,
    values = ~`Tipo de incidente`,
    title = "Tipo de incidente",
    opacity = 1
  ) %>%
  addScaleBar(position = "bottomleft") %>%
  setView(
    lng = mean(peak.radio$lng),
    lat = mean(peak.radio$lat),
    zoom = 15
  )
```


```{r radio.accidents.df4, echo=FALSE, warning=FALSE, eval=!knitr::is_html_output()}
ggplot() +
  annotation_map_tile(type = "osm", zoom = 10) +
  geom_point(data = peak.radio, aes(x = lng, y = lat, colour = `Tipo de incidente`)) +
  labs(x = "Longitud", y = "Latitud") +
  coord_sf(crs = 4326)
```

## Mediciones de velocidad en paradero "Bdo O'Higgins - Arauco", Chiguayante

### Velocidades por vehículo

```{r chiguayante.speed.df0, echo=FALSE, warning=FALSE}
ggplot(chiguayante.speed.df) +
  geom_density(aes(x = `Velocidad [km/hr]`, colour = Vehículo))
```

### Horas por vehículo

```{r chiguayante.speed.df1, echo=FALSE, warning=FALSE}
ggplot(chiguayante.speed.df) +
  geom_density(aes(x = Hora %>% as.numeric(), colour = Vehículo)) + 
  scale_x_continuous(
    name = "Hora",
    labels = function(x) {
      horas <- floor(x / 3600)
      minutos <- floor((x %% 3600) / 60)
      sprintf("%02d:%02d", horas, minutos)
    }
  )
```

### Distribución por vehículo

```{r chiguayante.speed.df2, echo=FALSE, warning=FALSE}
ggplot(chiguayante.speed.df) +
  geom_bar(aes(y = Vehículo %>% 
    fct_infreq() %>%
    fct_rev(), fill = dirección)) +
  labs(y = "Vehículo")
```

### Velocidades por dirección

```{r chiguayante.speed.df3, echo=FALSE, warning=FALSE}
ggplot(chiguayante.speed.df) +
  geom_density(aes(x = `Velocidad [km/hr]`, colour = dirección))
```

### Horas por dirección

```{r chiguayante.speed.df4, echo=FALSE, warning=FALSE}
ggplot(chiguayante.speed.df) +
  geom_density(aes(x = Hora %>% as.numeric(), colour = dirección)) + 
  scale_x_continuous(
    name = "Hora",
    labels = function(x) {
      horas <- floor(x / 3600)
      minutos <- floor((x %% 3600) / 60)
      sprintf("%02d:%02d", horas, minutos)
    }
  )
```

### Distribución por Velocidad y Hora

**Por Velocidad**

```{r chiguayante.speed.df5, echo=FALSE, warning=FALSE}
ggplot(chiguayante.speed.df) +
  geom_point(aes(x = Hora %>% as.numeric(), y = `Velocidad [km/hr]`, colour = Vehículo)) + 
  scale_x_continuous(
    name = "Hora",
    labels = function(x) {
      horas <- floor(x / 3600)
      minutos <- floor((x %% 3600) / 60)
      sprintf("%02d:%02d", horas, minutos)
    }
  )
```

**Por dirección**

```{r chiguayante.speed.df6, echo=FALSE, warning=FALSE}
ggplot(chiguayante.speed.df) +
  geom_point(aes(x = Hora %>% as.numeric(), y = `Velocidad [km/hr]`, colour = dirección)) + 
  scale_x_continuous(
    name = "Hora",
    labels = function(x) {
      horas <- floor(x / 3600)
      minutos <- floor((x %% 3600) / 60)
      sprintf("%02d:%02d", horas, minutos)
    }
  )
```

## Mediciones de velocidad en el cruce de Briceños con Miraflores

### Velocidades por comentario

```{r vega.speed.df0, echo=FALSE, warning=FALSE}
p.main <- ggplot(vega.speed.df) +
  geom_density(aes(x = `Velocidad.[km/hr]`, colour = Comentario)) +
  theme(legend.position = "none")
plot_legend <- ggplot(vega.speed.df) +
  geom_density(aes(x = `Velocidad.[km/hr]`, colour = Comentario)) +
  theme_minimal() +
  theme(axis.text = element_blank(),
        axis.title = element_blank(),
        panel.grid = element_blank(),
        plot.background = element_blank())
legend <- plot_legend %>% get_legend()
p.main
grid.newpage()
legend %>% grid.draw()
```

### Horas por comentario

```{r vega.speed.df1, echo=FALSE, warning=FALSE}
p.main <- ggplot(vega.speed.df) +
  geom_density(aes(x = Hora %>% as.numeric(), colour = Comentario)) +
  theme(legend.position = "none") + 
  scale_x_continuous(
    name = "Hora",
    labels = function(x) {
      horas <- floor(x / 3600)
      minutos <- floor((x %% 3600) / 60)
      sprintf("%02d:%02d", horas, minutos)
    }
  )
plot_legend <- ggplot(vega.speed.df) +
  geom_density(aes(x = `Velocidad.[km/hr]`, colour = Comentario)) +
  theme_minimal() +
  theme(axis.text = element_blank(),
        axis.title = element_blank(),
        panel.grid = element_blank(),
        plot.background = element_blank())
legend <- plot_legend %>% get_legend()
p.main
grid.newpage()
legend %>% grid.draw()
```

### 3 comentarios más frecuentes

```{r vega.speed.df2, echo=FALSE, warning=FALSE}
n <- 3
vega.speed.df.no.na.comment <- vega.speed.df[!(vega.speed.df$Comentario %>% is.na()),]
top <- vega.speed.df.no.na.comment %>%
  count(Comentario) %>%
  slice_max(n, n = n) %>%
  pull(Comentario)
ggplot(vega.speed.df.no.na.comment[vega.speed.df.no.na.comment$Comentario %in% top,]) +
  geom_bar(aes(y = Comentario %>%
      fct_infreq() %>%
      fct_lump_n(n = n, ties.method = "first") %>%
      fct_rev(), fill = dirección)) +
  labs(y = "Comentario")
```

## Alertas GPS

### Eventos por localización

```{r gps.events0.html, echo=FALSE, warning=FALSE, eval=knitr::is_html_output()}
pal <- colorFactor(
  palette = c("#00F", "#0F0", "#F00"),
  domain = gps.events$evento_
)
leaflet(gps.events) %>%
  addTiles() %>%
  addCircleMarkers(
    lng = ~longitud_,
    lat = ~latitud_,
    color = ~pal(evento_),
    radius = 6,
    stroke = F,
    fillOpacity = 0.8
  ) %>%
  addLegend(
    "bottomright",
    pal = pal,
    values = ~evento_,
    title = "evento_",
    opacity = 1
  ) %>%
  addScaleBar(position = "bottomleft") %>%
  setView(
    lng = mean(gps.events$longitud_),
    lat = mean(gps.events$latitud_),
    zoom = 6
  )
```

**Chile**

```{r gps.events0, echo=FALSE, warning=FALSE, eval=!knitr::is_html_output()}
gps.events.chile <- gps.events[gps.events$longitud_ <= -71,]
ggplot() +
  annotation_map_tile(type = "osm", zoom = 17) +
  geom_point(data = gps.events.chile, aes(x = longitud_, y = latitud_, colour = evento_, size = direccion_)) +
  labs(x = "Longitud", y = "Latitud") +
  coord_sf(crs = 4326)
```

**Argentina**

```{r gps.events1, echo=FALSE, warning=FALSE, eval=!knitr::is_html_output()}
gps.events.argentina <- gps.events[gps.events$longitud_ > -71,]
start.sys <- Sys.time()
ggplot() +
  annotation_map_tile(type = "osm", zoom = 10) +
  geom_point(data = gps.events.argentina, aes(x = longitud_, y = latitud_, colour = evento_, size = direccion_)) +
  labs(x = "Longitud", y = "Latitud") +
  coord_sf(crs = 4326)
end.sys <- Sys.time()
```

## Inventario de de cámaras de vigilancia

### Distribución por columna

```{r biobio.inventary0, echo=FALSE, warning=FALSE}
biobio.inventary.online <- biobio.inventary[biobio.inventary$ESTADO == "Online",]
ggplot(biobio.inventary.online) +
  geom_bar(aes(y = COMUNA %>%
    fct_infreq() %>%
    fct_rev(),
  fill = `MARCA DE LA CÁMARA` %>%
    fct_infreq() %>%
    fct_rev())) +
  labs(y = "COMUNA", fill = "MARCA DE LA CÁMARA")
```

### Distribución por modelo

```{r biobio.inventary1, echo=FALSE, warning=FALSE}
ggplot(biobio.inventary.online) +
  geom_bar(aes(y = `MODELO DE LA CÁMARA` %>%
    fct_infreq() %>%
    fct_rev(),
  fill = `MARCA DE LA CÁMARA`)) +
  labs(y = "MODELO DE LA CÁMARA")
```

### Marca de la cámara por localización

```{r biobio.inventary2.html, echo=FALSE, warning=FALSE, eval=knitr::is_html_output()}
pal <- colorFactor(
  palette = c("#F0F", "#00F", "#0FF", "#0F0", "#FF0", "#F00"),
  domain = biobio.inventary.online$`MARCA DE LA CÁMARA`
)
leaflet(biobio.inventary.online) %>%
  addTiles() %>%
  addCircleMarkers(
    lng = ~LONGITUD,
    lat = ~LATITUD,
    color = ~pal(`MARCA DE LA CÁMARA`),
    radius = 6,
    stroke = F,
    fillOpacity = 0.8
  ) %>%
  addLegend(
    "bottomright",
    pal = pal,
    values = ~`MARCA DE LA CÁMARA`,
    title = "MARCA DE LA CÁMARA",
    opacity = 1
  ) %>%
  addScaleBar(position = "bottomleft") %>%
  setView(
    lng = mean(biobio.inventary.online$LONGITUD),
    lat = mean(biobio.inventary.online$LATITUD),
    zoom = 10
  )
```

**Concepción**

```{r biobio.inventary2, echo=FALSE, warning=FALSE, eval=!knitr::is_html_output()}
ggplot() +
  annotation_map_tile(type = "osm", zoom = 15) +
  geom_point(data = biobio.inventary.online[biobio.inventary.online$COMUNA == "Concepción" & biobio.inventary.online$LATITUD < -36.6,], aes(x = LONGITUD, y = LATITUD, colour = `MARCA DE LA CÁMARA`, size = 2)) +
  labs(x = "Longitud", y = "Latitud") +
  coord_sf(crs = 4326) +
  guides(size = "none")
```

**San Pedro de la Paz**

```{r biobio.inventary3, echo=FALSE, warning=FALSE, eval=!knitr::is_html_output()}
ggplot() +
  annotation_map_tile(type = "osm", zoom = 15) +
  geom_point(data = biobio.inventary.online[biobio.inventary.online$COMUNA == "San Pedro de la Paz" & biobio.inventary.online$LONGITUD > -73.3,], aes(x = LONGITUD, y = LATITUD, colour = `MARCA DE LA CÁMARA`, size = 2)) +
  labs(x = "Longitud", y = "Latitud") +
  coord_sf(crs = 4326) +
  guides(size = "none")
```

**Chiguayante**

```{r biobio.inventary4, echo=FALSE, warning=FALSE, eval=!knitr::is_html_output()}
ggplot() +
  annotation_map_tile(type = "osm", zoom = 15) +
  geom_point(data = biobio.inventary.online[biobio.inventary.online$COMUNA == "Chiguayante",], aes(x = LONGITUD, y = LATITUD, colour = `MARCA DE LA CÁMARA`, size = 2)) +
  labs(x = "Longitud", y = "Latitud") +
  coord_sf(crs = 4326) +
  guides(size = "none")
```

**Talcahuano**

```{r biobio.inventary5, echo=FALSE, warning=FALSE, eval=!knitr::is_html_output()}
ggplot() +
  annotation_map_tile(type = "osm", zoom = 20) +
  geom_point(data = biobio.inventary.online[biobio.inventary.online$COMUNA == "Talcahuano",], aes(x = LONGITUD, y = LATITUD, colour = `MARCA DE LA CÁMARA`, size = 2)) +
  labs(x = "Longitud", y = "Latitud") +
  coord_sf(crs = 4326) +
  guides(size = "none")
```

### Distribución de las fechas de integración

```{r biobio.inventary6, echo=FALSE, warning=FALSE}
ggplot(biobio.inventary) +
  geom_density(aes(x = `FECHA INTEGRACION`, colour = COMUNA))
```

## Alertas de Tráfico

### Distribución por ciudad

```{r trafic.alerts0, echo=FALSE, warning=FALSE}
ggplot(trafic.alerts) +
  geom_bar(aes(y = City %>%
    fct_infreq() %>%
    fct_rev(),
  fill = Type %>%
    fct_infreq() %>%
    fct_rev()
  )) +
  labs(y = "City", fill = "Type")
```

### Distribución por subtipo

```{r trafic.alerts1, echo=FALSE, warning=FALSE}
n <- 6
top <- trafic.alerts[!(trafic.alerts$Subtype %>% is.na()),] %>%
  count(Subtype) %>%
  slice_max(n, n = n) %>%
  pull(Subtype)
ggplot(trafic.alerts[trafic.alerts$Subtype %in% top,]) +
  geom_bar(aes(y = Subtype %>%
    fct_infreq() %>%
    fct_lump_n(n = n, ties.method = "first") %>%
    fct_rev(),
  fill = Type %>%
    fct_infreq() %>%
    fct_rev()
  )) +
  labs(y = "Subtype", fill = "Type")
```

### Distribución geográfica

```{r trafic.alerts2.html, echo=FALSE, warning=FALSE, eval=knitr::is_html_output()}
pal <- colorFactor(
  palette = c("#F0F", "#00F", "#0FF", "#0F0", "#FF0", "#F00"),
  domain = trafic.alerts$Type
)
leaflet(trafic.alerts) %>%
  addTiles() %>%
  addCircleMarkers(
    lng = ~lng,
    lat = ~lat,
    color = ~pal(Type),
    radius = 6,
    stroke = F,
    fillOpacity = 0.8
  ) %>%
  addLegend(
    "bottomright",
    pal = pal,
    values = ~Type,
    title = "Type",
    opacity = 1
  ) %>%
  addScaleBar(position = "bottomleft") %>%
  setView(
    lng = mean(trafic.alerts$lng),
    lat = mean(trafic.alerts$lat),
    zoom = 10
  )
```

**Concepción, San Pedro de la Paz, Talcahuano, Hualpén, Penco y Hualqui**

*JAM*

```{r trafic.alerts2, echo=FALSE, warning=FALSE, eval=!knitr::is_html_output()}
ggplot() +
  annotation_map_tile(type = "osm", zoom = 12) +
  stat_density_2d(
    data = trafic.alerts[trafic.alerts$City %in% c("Concepción", "San Pedro de la Paz", "Talcahuano", "Hualpén", "Penco", "Hualqui") & trafic.alerts$Type == "JAM",],
    aes(x = lng, y = lat, fill = after_stat(level)),
    geom = "polygon", 
    alpha = 0.5
  ) +
  labs(x = "Longitud", y = "Latitud") +
  coord_sf(crs = 4326) +
  guides(size = "none")
```

*HAZARD*

```{r trafic.alerts3, echo=FALSE, warning=FALSE, eval=!knitr::is_html_output()}
ggplot() +
  annotation_map_tile(type = "osm", zoom = 12) +
  stat_density_2d(
    data = trafic.alerts[trafic.alerts$City %in% c("Concepción", "San Pedro de la Paz", "Talcahuano", "Hualpén", "Penco", "Hualqui") & trafic.alerts$Type == "HAZARD",],
    aes(x = lng, y = lat, fill = after_stat(level)),
    geom = "polygon", 
    alpha = 0.5
  ) +
  labs(x = "Longitud", y = "Latitud") +
  coord_sf(crs = 4326) +
  guides(size = "none")
```

*WEATHERHAZARD*

```{r trafic.alerts4, echo=FALSE, warning=FALSE, eval=!knitr::is_html_output()}
ggplot() +
  annotation_map_tile(type = "osm", zoom = 12) +
  stat_density_2d(
    data = trafic.alerts[trafic.alerts$City %in% c("Concepción", "San Pedro de la Paz", "Talcahuano", "Hualpén", "Penco", "Hualqui") & trafic.alerts$Type == "WEATHERHAZARD",],
    aes(x = lng, y = lat, fill = after_stat(level)),
    geom = "polygon", 
    alpha = 0.5
  ) +
  labs(x = "Longitud", y = "Latitud") +
  coord_sf(crs = 4326) +
  guides(size = "none")
```

*ACCIDENT*

```{r trafic.alerts5, echo=FALSE, warning=FALSE, eval=!knitr::is_html_output()}
ggplot() +
  annotation_map_tile(type = "osm", zoom = 12) +
  stat_density_2d(
    data = trafic.alerts[trafic.alerts$City %in% c("Concepción", "San Pedro de la Paz", "Talcahuano", "Hualpén", "Penco", "Hualqui") & trafic.alerts$Type == "ACCIDENT",],
    aes(x = lng, y = lat, fill = after_stat(level)),
    geom = "polygon", 
    alpha = 0.5
  ) +
  labs(x = "Longitud", y = "Latitud") +
  coord_sf(crs = 4326) +
  guides(size = "none")
```

*ROAD_CLOSED*

```{r trafic.alerts6, echo=FALSE, warning=FALSE, eval=!knitr::is_html_output()}
ggplot() +
  annotation_map_tile(type = "osm", zoom = 12) +
  stat_density_2d(
    data = trafic.alerts[trafic.alerts$City %in% c("Concepción", "San Pedro de la Paz", "Talcahuano", "Hualpén", "Penco", "Hualqui") & trafic.alerts$Type == "ROAD_CLOSED",],
    aes(x = lng, y = lat, fill = after_stat(level)),
    geom = "polygon", 
    alpha = 0.5
  ) +
  labs(x = "Longitud", y = "Latitud") +
  coord_sf(crs = 4326) +
  guides(size = "none")
```

**Los Ángeles**

*JAM*

```{r trafic.alerts7, echo=FALSE, warning=FALSE, eval=!knitr::is_html_output()}
ggplot() +
  annotation_map_tile(type = "osm", zoom = 10) +
  stat_density_2d(
    data = trafic.alerts[trafic.alerts$City == "Los Ángeles" & trafic.alerts$Type == "JAM",],
    aes(x = lng, y = lat, fill = after_stat(level)),
    geom = "polygon", 
    alpha = 0.5
  ) +
  labs(x = "Longitud", y = "Latitud") +
  coord_sf(crs = 4326) +
  guides(size = "none")
```

*HAZARD*

```{r trafic.alerts8, echo=FALSE, warning=FALSE, eval=!knitr::is_html_output()}
ggplot() +
  annotation_map_tile(type = "osm", zoom = 10) +
  stat_density_2d(
    data = trafic.alerts[trafic.alerts$City == "Los Ángeles" & trafic.alerts$Type == "HAZARD",],
    aes(x = lng, y = lat, fill = after_stat(level)),
    geom = "polygon", 
    alpha = 0.5
  ) +
  labs(x = "Longitud", y = "Latitud") +
  coord_sf(crs = 4326) +
  guides(size = "none")
```

*WEATHERHAZARD*

```{r trafic.alerts9, echo=FALSE, warning=FALSE, eval=!knitr::is_html_output()}
ggplot() +
  annotation_map_tile(type = "osm", zoom = 10) +
  stat_density_2d(
    data = trafic.alerts[trafic.alerts$City == "Los Ángeles" & trafic.alerts$Type == "WEATHERHAZARD",],
    aes(x = lng, y = lat, fill = after_stat(level)),
    geom = "polygon", 
    alpha = 0.5
  ) +
  labs(x = "Longitud", y = "Latitud") +
  coord_sf(crs = 4326) +
  guides(size = "none")
```

*ACCIDENT*

```{r trafic.alerts10, echo=FALSE, warning=FALSE, eval=!knitr::is_html_output()}
ggplot() +
  annotation_map_tile(type = "osm", zoom = 10) +
  stat_density_2d(
    data = trafic.alerts[trafic.alerts$City == "Los Ángeles" & trafic.alerts$Type == "ACCIDENT",],
    aes(x = lng, y = lat, fill = after_stat(level)),
    geom = "polygon", 
    alpha = 0.5
  ) +
  labs(x = "Longitud", y = "Latitud") +
  coord_sf(crs = 4326) +
  guides(size = "none")
```

*ROAD_CLOSED*

```{r trafic.alerts11, echo=FALSE, warning=FALSE, eval=!knitr::is_html_output()}
ggplot() +
  annotation_map_tile(type = "osm", zoom = 10) +
  stat_density_2d(
    data = trafic.alerts[trafic.alerts$City == "Los Ángeles" & trafic.alerts$Type == "ROAD_CLOSED",],
    aes(x = lng, y = lat, fill = after_stat(level)),
    geom = "polygon", 
    alpha = 0.5
  ) +
  labs(x = "Longitud", y = "Latitud") +
  coord_sf(crs = 4326) +
  guides(size = "none")
```

**Chiguayante**

*JAM*

```{r trafic.alerts12, echo=FALSE, warning=FALSE, eval=!knitr::is_html_output()}
ggplot() +
  annotation_map_tile(type = "osm", zoom = 15) +
  stat_density_2d(
    data = trafic.alerts[trafic.alerts$City == "Chiguayante" & trafic.alerts$Type == "JAM",],
    aes(x = lng, y = lat, fill = after_stat(level)),
    geom = "polygon", 
    alpha = 0.5
  ) +
  labs(x = "Longitud", y = "Latitud") +
  coord_sf(crs = 4326) +
  guides(size = "none")
```

*HAZARD*

```{r trafic.alerts13, echo=FALSE, warning=FALSE, eval=!knitr::is_html_output()}
ggplot() +
  annotation_map_tile(type = "osm", zoom = 15) +
  stat_density_2d(
    data = trafic.alerts[trafic.alerts$City == "Chiguayante" & trafic.alerts$Type == "HAZARD",],
    aes(x = lng, y = lat, fill = after_stat(level)),
    geom = "polygon", 
    alpha = 0.5
  ) +
  labs(x = "Longitud", y = "Latitud") +
  coord_sf(crs = 4326) +
  guides(size = "none")
```

*WEATHERHAZARD*

```{r trafic.alerts14, echo=FALSE, warning=FALSE, eval=!knitr::is_html_output()}
ggplot() +
  annotation_map_tile(type = "osm", zoom = 15) +
  stat_density_2d(
    data = trafic.alerts[trafic.alerts$City == "Chiguayante" & trafic.alerts$Type == "WEATHERHAZARD",],
    aes(x = lng, y = lat, fill = after_stat(level)),
    geom = "polygon", 
    alpha = 0.5
  ) +
  labs(x = "Longitud", y = "Latitud") +
  coord_sf(crs = 4326) +
  guides(size = "none")
```

*ACCIDENT*

```{r trafic.alerts15, echo=FALSE, warning=FALSE, eval=!knitr::is_html_output()}
ggplot() +
  annotation_map_tile(type = "osm", zoom = 15) +
  stat_density_2d(
    data = trafic.alerts[trafic.alerts$City == "Chiguayante" & trafic.alerts$Type == "ACCIDENT",],
    aes(x = lng, y = lat, fill = after_stat(level)),
    geom = "polygon", 
    alpha = 0.5
  ) +
  labs(x = "Longitud", y = "Latitud") +
  coord_sf(crs = 4326) +
  guides(size = "none")
```

*ROAD_CLOSED*

```{r trafic.alerts16, echo=FALSE, warning=FALSE, eval=!knitr::is_html_output()}
ggplot() +
  annotation_map_tile(type = "osm", zoom = 15) +
  stat_density_2d(
    data = trafic.alerts[trafic.alerts$City == "Chiguayante" & trafic.alerts$Type == "ROAD_CLOSED",],
    aes(x = lng, y = lat, fill = after_stat(level)),
    geom = "polygon", 
    alpha = 0.5
  ) +
  labs(x = "Longitud", y = "Latitud") +
  coord_sf(crs = 4326) +
  guides(size = "none")
```

**Tomé**

*JAM*

```{r trafic.alerts17, echo=FALSE, warning=FALSE, eval=!knitr::is_html_output()}
ggplot() +
  annotation_map_tile(type = "osm", zoom = 15) +
  stat_density_2d(
    data = trafic.alerts[trafic.alerts$City == "Tomé" & trafic.alerts$Type == "JAM",],
    aes(x = lng, y = lat, fill = after_stat(level)),
    geom = "polygon", 
    alpha = 0.5
  ) +
  labs(x = "Longitud", y = "Latitud") +
  coord_sf(crs = 4326) +
  guides(size = "none")
```

*HAZARD*

```{r trafic.alerts18, echo=FALSE, warning=FALSE, eval=!knitr::is_html_output()}
ggplot() +
  annotation_map_tile(type = "osm", zoom = 15) +
  stat_density_2d(
    data = trafic.alerts[trafic.alerts$City == "Tomé" & trafic.alerts$Type == "HAZARD",],
    aes(x = lng, y = lat, fill = after_stat(level)),
    geom = "polygon", 
    alpha = 0.5
  ) +
  labs(x = "Longitud", y = "Latitud") +
  coord_sf(crs = 4326) +
  guides(size = "none")
```

*WEATHERHAZARD*

```{r trafic.alerts19, echo=FALSE, warning=FALSE, eval=!knitr::is_html_output()}
ggplot() +
  annotation_map_tile(type = "osm", zoom = 15) +
  stat_density_2d(
    data = trafic.alerts[trafic.alerts$City == "Tomé" & trafic.alerts$Type == "WEATHERHAZARD",],
    aes(x = lng, y = lat, fill = after_stat(level)),
    geom = "polygon", 
    alpha = 0.5
  ) +
  labs(x = "Longitud", y = "Latitud") +
  coord_sf(crs = 4326) +
  guides(size = "none")
```

*ACCIDENT*

```{r trafic.alerts20, echo=FALSE, warning=FALSE, eval=!knitr::is_html_output()}
ggplot() +
  annotation_map_tile(type = "osm", zoom = 15) +
  stat_density_2d(
    data = trafic.alerts[trafic.alerts$City == "Tomé" & trafic.alerts$Type == "ACCIDENT",],
    aes(x = lng, y = lat, fill = after_stat(level)),
    geom = "polygon", 
    alpha = 0.5
  ) +
  labs(x = "Longitud", y = "Latitud") +
  coord_sf(crs = 4326) +
  guides(size = "none")
```

*ROAD_CLOSED*

```{r trafic.alerts21, echo=FALSE, warning=FALSE, eval=!knitr::is_html_output()}
ggplot() +
  annotation_map_tile(type = "osm", zoom = 15) +
  stat_density_2d(
    data = trafic.alerts[trafic.alerts$City == "Tomé" & trafic.alerts$Type == "ROAD_CLOSED",],
    aes(x = lng, y = lat, fill = after_stat(level)),
    geom = "polygon", 
    alpha = 0.5
  ) +
  labs(x = "Longitud", y = "Latitud") +
  coord_sf(crs = 4326) +
  guides(size = "none")
```

## Accidentes de tráfico

### Distribución por ciudad

```{r accidents0, echo=FALSE, warning=FALSE}
ggplot(accidents) +
  geom_bar(aes(
    y = City %>%
    fct_infreq() %>%
    fct_rev(),
    fill = `Avg Reliability` %>% round() %>% as.factor())
  ) +
  labs(y = "City", fill = "Avg Reliability")
```

### Distribución geográfica

```{r accidents1.html, echo=FALSE, warning=FALSE, eval=knitr::is_html_output()}
pal <- colorNumeric(
  palette = c("blue", "green", "yellow", "red"),
  domain = accidents$`Avg Reliability`
)
leaflet(accidents) %>%
  addTiles() %>%
  addCircleMarkers(
    lng = ~lng,
    lat = ~lat,
    color = ~pal(`Avg Reliability`),
    radius = 6,
    stroke = F,
    fillOpacity = 0.8
  ) %>%
  addLegend(
    "bottomright",
    pal = pal,
    values = ~`Avg Reliability`,
    title = "Avg Reliability",
    opacity = 1
  ) %>%
  addScaleBar(position = "bottomleft") %>%
  setView(
    lng = mean(accidents$lng),
    lat = mean(accidents$lat),
    zoom = 10
  )
```

**Concepción, San Pedro de la Paz, Talcahuano, Hualpén, Penco, Hualqui, Lirquén y Lenga**

```{r accidents1, echo=FALSE, warning=FALSE, eval=!knitr::is_html_output()}
ggplot() +
  annotation_map_tile(type = "osm", zoom = 12) +
  stat_density_2d(
    data = accidents[accidents$City %in% c("Concepción", "San Pedro de la Paz", "Talcahuano", "Hualpén", "Penco", "Hualqui", "Lirquén", "Lenga"),],
    aes(x = lng, y = lat, fill = after_stat(level)),
    geom = "polygon", 
    alpha = 0.5
  ) +
  labs(x = "Longitud", y = "Latitud") +
  coord_sf(crs = 4326) +
  guides(size = "none")
```

**Los Ángeles**

```{r accidents2, echo=FALSE, warning=FALSE, eval=!knitr::is_html_output()}
ggplot() +
  annotation_map_tile(type = "osm", zoom = 12) +
  stat_density_2d(
    data = accidents[accidents$City == "Los Ángeles",],
    aes(x = lng, y = lat, fill = after_stat(level)),
    geom = "polygon", 
    alpha = 0.5
  ) +
  labs(x = "Longitud", y = "Latitud") +
  coord_sf(crs = 4326) +
  guides(size = "none")
```

**Chiguayante**

```{r accidents3, echo=FALSE, warning=FALSE, eval=!knitr::is_html_output()}
ggplot() +
  annotation_map_tile(type = "osm", zoom = 12) +
  stat_density_2d(
    data = accidents[accidents$City == "Chiguayante",],
    aes(x = lng, y = lat, fill = after_stat(level)),
    geom = "polygon", 
    alpha = 0.5
  ) +
  labs(x = "Longitud", y = "Latitud") +
  coord_sf(crs = 4326) +
  guides(size = "none")
```

**Tomé**

```{r accidents4, echo=FALSE, warning=FALSE, eval=!knitr::is_html_output()}
ggplot() +
  annotation_map_tile(type = "osm", zoom = 12) +
  stat_density_2d(
    data = accidents[accidents$City == "Tomé",],
    aes(x = lng, y = lat, fill = after_stat(level)),
    geom = "polygon", 
    alpha = 0.5
  ) +
  labs(x = "Longitud", y = "Latitud") +
  coord_sf(crs = 4326) +
  guides(size = "none")
```

**Huertos Familiares**

```{r accidents5, echo=FALSE, warning=FALSE, eval=!knitr::is_html_output()}
ggplot() +
  annotation_map_tile(type = "osm", zoom = 12) +
  stat_density_2d(
    data = accidents[accidents$City == "Huertos Familiares",],
    aes(x = lng, y = lat, fill = after_stat(level)),
    geom = "polygon", 
    alpha = 0.5
  ) +
  labs(x = "Longitud", y = "Latitud") +
  coord_sf(crs = 4326) +
  guides(size = "none")
```

## Alertas de Waze

### Distribución por calles

```{r waze.data0, echo=FALSE, warning=FALSE}
n <- 10
top <- waze.data %>%
  count(Street) %>%
  slice_max(n, n = n) %>%
  pull(Street)
ggplot(waze.data[waze.data$Street %in% top,]) +
  geom_bar(aes(
    y = Street %>%
    fct_infreq() %>%
    fct_lump_n(n = n, ties.method = "first") %>%
    fct_rev(),
    fill = City)) +
  labs(y = "Street")
```

```{r waze.data1, echo=FALSE, warning=FALSE}
ggplot(waze.data[waze.data$Street %in% top & !(waze.data$Cause %>% is.na()),]) +
  geom_bar(aes(
    y = Street %>%
    fct_infreq() %>%
    fct_lump_n(n = n, ties.method = "first") %>%
    fct_rev(),
    fill = Cause)) +
  labs(y = "Street")
```

### Distribución por ciudad

```{r waze.data2, echo=FALSE, warning=FALSE}
ggplot(waze.data[!(waze.data$Cause %>% is.na()),]) +
  geom_bar(aes(
    y = City %>%
    fct_infreq() %>%
    fct_rev(),
    fill = Cause)) +
  labs(y = "City")
```

### Distribución por largo promedio

```{r waze.data3, echo=FALSE, warning=FALSE}
ggplot(waze.data) +
  geom_density(aes(x = `Avg Length (Meters)`, colour = Cause)) +
  scale_x_log10()
```

### Distribución por desfase promedio

```{r waze.data4, echo=FALSE, warning=FALSE}
ggplot(waze.data) +
  geom_density(aes(x = `Avg Delay (Seconds)`, colour = Cause)) +
  scale_x_log10()
```

### Distribución por usuarios impactados

```{r waze.data5, echo=FALSE, warning=FALSE}
ggplot(waze.data) +
  geom_density(aes(x = `Impacted Wazers`, colour = Cause)) +
  scale_x_log10()
```
