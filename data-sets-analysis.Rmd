---
title: "Análisis de los Sets de Datos"
author: "Luciano Hernández"
date: "`r Sys.Date()`"
output:
  pdf_document:
    toc: true
    toc_depth: 3
    keep_tex: true
  html_document:
    toc: true
    toc_depth: 3
    toc_float: true
    number_sections: true
---

```{r setup, include=FALSE}
if (Sys.getenv("JAVA_HOME")=="") {
  Sys.setenv(JAVA_HOME="C:/Program Files/Java/jre1.8.0_361")
}
knitr::opts_chunk$set(echo = TRUE)
options(future.globals.maxSize = 8000 * 1024^2)
options(java.parameters = "-Xmx2048m")
library(cowplot)
library(data.table)
library(dplyr)
library(ggmap)
library(ggplot2)
library(ggspatial)
library(googlesheets4)
library(grid)
library(gridExtra)
library(gtfsio)
library(httr)
library(knitr)
library(leaflet)
library(lubridate)
library(maps)
library(OpenStreetMap)
library(openxlsx)
library(osmdata)
library(prettymapr)
library(protolite)
library(purrr)
library(readr)
library(readxl)
library(rjson)
library(rnaturalearth)
library(rnaturalearthdata)
library(sf)
library(stringr)
library(tidyr)
library(tidytransit)
library(tidyverse)
library(tidyxl)
library(viridis)
```

```{r key.objects, include=FALSE}
key.objects <- c("interurban.bus.accidents", "gh026929", "police.accidents", "radio.accidents.df", "chiguayante.speed.df", "vega.speed.df", "gps.events", "biobio.inventary", "trafic.alerts", "accidents", "waze.data", "meters.per.degree.lat", "meters.per.degree.lng", "quantum.data", "tracking.gps.df", "waze.routes", "waze.routes.df")

sum.time <- function(dt.list){
  dt.list %>% sapply(., function(t){
    (t %>% as.numeric()) * switch (t %>% units(),
      "secs" = 1,
      "mins" = 60,
    )
  }) %>% sum()
}
```

```{r save, eval=FALSE, include=FALSE}
deleting.objects <- setdiff(ls(), key.objects)
rm(list = deleting.objects)
gc()
memory.limit()
memory.size()
save.image("~/GitHub/data-sets-analysis/.RData")
save.time.sys <- list()
for(ko in key.objects[key.objects != "tracking.gps.df"]) {
  start.sys <- Sys.time()
  file.name <- paste(ko, "rds", sep = ".")
  file.path. <- paste("~/GitHub/data-sets-analysis/rds-files", file.name, sep = "/")
  ko %>% get() %>% saveRDS(file = file.path.)
  end.sys <- Sys.time()
  dt.sys <- end.sys - start.sys
  print(ko)
  print(dt.sys)
  save.time.sys[[ko]] <- dt.sys
}
total.save.dt <- save.time.sys %>% sum.time()
```


```{r load, include=FALSE}
load.time.sys <- list()
for(ko in key.objects[key.objects != "tracking.gps.df"]) {
  start.sys <- Sys.time()
  file.name <- paste(ko, "rds", sep = ".")
  file.path. <- paste("~/GitHub/data-sets-analysis/rds-files", file.name, sep = "/")
  assign(ko, ko %>% readRDS(file = file.path.))
  end.sys <- Sys.time()
  dt.sys <- end.sys - start.sys
  print(ko)
  print(dt.sys)
  load.time.sys[[ko]] <- dt.sys
}
total.load.dt <- load.time.sys %>% sum.time()
```

```{r load.tracking.gps.df, include=FALSE}
ml <- 8 * 1024^3
ms <- 6 * 1024^3
Sys.setenv("R_MAX_VSIZE" = "8Gb")
memory.limit(size = ml)
options(future.globals.maxSize = ms)
gc()
loaded <- F
ko <- "tracking.gps.df"
start.sys <- Sys.time()
file.name <- paste(ko, "rds", sep = ".")
file.path. <- paste("~/GitHub/data-sets-analysis/rds-files", file.name, sep = "/")
tryCatch({
  assign(ko, ko %>% readRDS(file = file.path.))
  loaded <- T
}, error = function(e){
  print(paste("Error al cargar:", e$message))
  ml <- 2 * ml
  ms <- 2 * ms
  memory.limit(size = ml)
  options(future.globals.maxSize = ms)
  gc()
})
while(!loaded){
  tryCatch({
    assign(ko, ko %>% readRDS(file = file.path.))
    loaded <- T
  }, error = function(e){
    print(paste("Error al cargar:", e$message))
    ml <- 2 * ml
    ms <- 2 * ms
    memory.limit(size = ml)
    options(future.globals.maxSize = ms)
    gc()
  })
}
end.sys <- Sys.time()
dt.sys <- end.sys - start.sys
print(ko)
print(dt.sys)
load.time.sys[[ko]] <- dt.sys
```

# Extracción y caracterización de datos

## Siniestros buses interurbanos(1).xlsx

```{r getData0, eval=FALSE, include=FALSE}
# Siniestros buses interurbanos(1).xlsx
interurban.bus.accidents <- read_excel("data/Siniestros buses interurbanos(1).xlsx", 
    col_types = c("numeric", "numeric", "date", 
        "date", "numeric", "text", "text", 
        "text", "text", "text", "text", "text", 
        "text", "text", "text", "text", "numeric", 
        "text", "numeric", "numeric", "numeric", 
        "numeric", "numeric", "numeric", 
        "numeric", "numeric", "numeric"))
interurban.bus.accidents$Fecha <- paste(interurban.bus.accidents$Fecha, interurban.bus.accidents$Hora %>% format(format = "%H:%M:%S")) %>% as.POSIXct(format = "%Y-%m-%d %H:%M")
interurban.bus.accidents <- interurban.bus.accidents %>% select(-Hora)
interurban.bus.accidents$Región <- interurban.bus.accidents$Región %>% as.factor()
interurban.bus.accidents$Comuna <- interurban.bus.accidents$Comuna %>% as.factor()
interurban.bus.accidents$`Tipo Accidente` <- interurban.bus.accidents$`Tipo Accidente` %>% as.factor()
interurban.bus.accidents$`Tipo (CONASET)` <- interurban.bus.accidents$`Tipo (CONASET)` %>% as.factor()
interurban.bus.accidents$Zona <- interurban.bus.accidents$Zona %>% as.factor()
interurban.bus.accidents$`Ubicación Relativa` <- interurban.bus.accidents$`Ubicación Relativa` %>% as.factor()
interurban.bus.accidents$`Causa (CONASET)` <- interurban.bus.accidents$`Causa (CONASET)` %>% as.factor()
interurban.bus.accidents$`Causa Accidente` <- interurban.bus.accidents$`Causa Accidente` %>% as.factor()
interurban.bus.accidents %>% summary()
difference <- interurban.bus.accidents$Fecha %>% max() - interurban.bus.accidents$Fecha %>% min()
interurban.bus.accidents %>% nrow() / difference %>% as.numeric()
```

El análisis comprende 6268 registros de siniestros de buses interurbanos ocurridos entre el 1 de enero de 2014 y el 29 de diciembre de 2023.

### Granularidad temporal

- Diferencia Mínima: 0 (ocurren al mismo tiempo)
- Diferencia Máxima: 10 días, 22 horas y 5 minutos
- Diferencia Media: 13 horas, 58 minutos y 27.13 segundos
- Diferencia Mediana: 8 horas y 25 minutos
- Desviación Standard: 17 horas, 58 minutos, 46.71 segundos

```{r interurban.bus.accidents.time, echo=FALSE, warning=FALSE}
differences <- (interurban.bus.accidents$Fecha - c(NA, interurban.bus.accidents$Fecha[1:(interurban.bus.accidents %>% nrow() - 1)])) %>% as.numeric() / 3600
#differences %>% summary()
interurban.bus.accidents %>% ggplot() +
  geom_density(aes(x = Fecha)) +
  labs(title = "Frecuencia por fecha")
```


```{r interurban.bus.accidents.time.dif, echo=FALSE, warning=FALSE}
ggplot() +
  geom_histogram(aes(x = differences)) +
  labs(x = "Horas de diferencia (escala logarítmica)") +
  scale_x_log10()
```


```{r interurban.bus.accidents.time.days, echo=FALSE, warning=FALSE}
ggplot() +
  geom_bar(aes(x = (differences / 24) %>% floor())) +
  labs(x = "Días de diferencia") +
  scale_y_log10()
```


### Distribución Geográfica

- **Regiones más afectadas**: Región Metropolitana (1285 casos), Región del Maule (835 casos) y Región del Biobío (767 casos)
- **Comunas con mayor incidencia**: Curicó (244 siniestros), Valdivia (227) y Estación Central (186)

```{r interurban.bus.accidents.geografic, echo=FALSE, warning=FALSE}
interurban.bus.accidents[interurban.bus.accidents$Comuna %in% (interurban.bus.accidents %>%
  count(Comuna) %>%
  slice_max(n, n = 10) %>%
  pull(Comuna)),] %>%
  ggplot() +
  geom_bar(aes(
    y = Comuna %>% fct_infreq() %>% fct_rev(),
    fill = Región
  )) +
  labs(y = "Comuna", fill = "Región", title = "10 comunas más frecuentes")
```


### Características de los Siniestros

- **Tipos predominantes**: Colisión (3655 casos), choque (1464) y atropello (448)
- **Distribución por zona**: 4251 accidentes en zonas urbanas versus 2,017 en zonas rurales

```{r interurban.bus.accidents.features, echo=FALSE, warning=FALSE}
interurban.bus.accidents %>%
  ggplot() +
  geom_bar(aes(
    y = `Tipo (CONASET)` %>% fct_infreq() %>% fct_rev(),
    fill = Zona
  )) +
  labs(y = "Tipo (CONASET)", fill = "Zona", title = "Tipos predominantes") +
  scale_x_log10()
```

### Factores Causales

- **Principales causas**: Imprudencia del conductor (3597 casos), otras causas (599) y causas no determinadas (540)
- *Nota*: La alta frecuencia de la categoría "otras causas" sugiere la necesidad de ampliar la clasificación causal existente

```{r interurban.bus.accidents.causal, echo=FALSE, warning=FALSE}
interurban.bus.accidents[interurban.bus.accidents$`Causa (CONASET)` %in% (interurban.bus.accidents %>%
  count(`Causa (CONASET)`) %>%
  slice_max(n, n = 5) %>%
  pull(`Causa (CONASET)`)),] %>%
  ggplot() +
  geom_bar(aes(
    y = `Causa (CONASET)` %>% fct_infreq() %>% fct_rev(),
    fill = Región %>% fct_infreq()
  )) +
  labs(y = "Causa (CONASET)", fill = "Región", title = "5 causas principales") +
  scale_fill_discrete(labels = label_wrap_gen(width = 20)) +
  scale_x_log10()

interurban.bus.accidents[interurban.bus.accidents$`Causa (CONASET)` %in% (interurban.bus.accidents %>%
  count(`Causa (CONASET)`) %>%
  slice_max(n, n = 5) %>%
  pull(`Causa (CONASET)`)),] %>% 
  ggplot() +
  stat_bin2d(
    aes(
      x = Región,
      y = `Causa (CONASET)` %>% fct_infreq() %>% fct_rev()
    )
  ) +
  scale_fill_gradientn(
    name = "Cantidad",
    colors = c(
      "red",
      "orange",
      "yellow",
      "lightgreen",
      "darkgreen"
    )
  ) +
  labs(title = "5 causas principales", x = "Región", y = "Causa (CONASET)") +
  scale_x_discrete(labels = label_wrap_gen(width = 15)) +
  scale_y_discrete(labels = label_wrap_gen(width = 20)) +
  theme(axis.text.x = element_text(angle = 270, hjust = 1, vjust = 0.5))
```

### Consecuencias y Severidad

- Fallecidos: 94.58% de los siniestros no registran víctimas mortales
- Lesiones graves: Ausentes en 89.69% de los casos
- Lesiones menos graves: No ocurren en 94.16% de los accidentes
- Lesiones leves: No se presentan en 63.10% de los incidentes

```{r interurban.bus.accidents.severity, echo=FALSE, warning=FALSE}
total <- interurban.bus.accidents %>% nrow()
severity <- data.frame(
  severity = c(
    rep("Fallecidos", total),
    rep("Lesiones graves", total),
    rep("Lesiones menos graves", total),
    rep("Lesiones leves", total)
  ) %>% factor(levels = c(
    "Fallecidos",
    "Lesiones graves",
    "Lesiones menos graves",
    "Lesiones leves")
  ),
  quantity = c(
    interurban.bus.accidents$`Fallecidos total siniestro`,
    interurban.bus.accidents$`Graves total siniestro`,
    interurban.bus.accidents$`Menos Graves  total siniestro`,
    interurban.bus.accidents$`Leves total siniestro`
  )
)
for(sev in severity$severity %>% levels()){
  (severity[severity$severity == sev,] %>%
    ggplot() +
    geom_bar(aes(
      x = quantity
    )) +
    labs(x = paste("Cantidad de", sev), title = paste("Distribución de cantidad de", sev, "por accidente")) +
    scale_y_log10()) %>% print()
}
```

### Optimizaciones Realizadas

**Paso a paso**

- "Fecha" se convirtió en la concatenación de "Fecha" y "Hora" y se convierte en POSIXct con formato "%d/%m/%Y %H:%M:%S"
- Se elimina la columna "Hora"
- "Región" se convierte en factor
- "Comuna" se convierte en factor
- "Tipo Accidente" se convierte en factor
- "Tipo (CONASET)" se convierte en factor
- "Zona" se convierte en factor
- "Ubicación Relativa" se convierte en factor
- "Causa (CONASET)" se convierte en factor
- "Causa Accidente" se convierte en factor

## GH026929.xlsx

```{r getData1, eval=FALSE, include=FALSE}
# GH026929.xlsx
gh026929 <- read_excel("data/GH026929.xlsx", 
    range = "A1:L1727", col_types = c("numeric", 
        "date", "text", "numeric", "numeric", 
        "numeric", "numeric", "skip", "skip", 
        "numeric", "numeric", "numeric"))

## ¿Qué es cts?
## Rangos altura
## ¿Qué es fix?
## U.M. precision

gh026929$date <- paste(gh026929$date, gh026929$hora) %>% as.POSIXct(format = "%Y-%m-%d %H:%M")
gh026929 <- gh026929 %>% select(-hora)
reduce.coords <- function(n) {
  n * 10 ^ (1 - (n %>% abs() %>% log10() %>% floor()))
}
reduce.2d.speed <- function(n, m) {
  N <- n * 10 ^ ((m %>% log10() + 1) %>% floor() - (n %>% log10() + 1) %>% floor())
  N[(N / m) %>% log10() > 0.7] <- N[(N / m) %>% log10() > 0.7] / 10
  N[(N / m) %>% log10() < -0.7] <- N[(N / m) %>% log10() < -0.7] * 10
  N
}
gh026929$`GPS (2D speed) [m/s]` <- reduce.2d.speed(gh026929$`GPS (2D speed) [m/s]`, gh026929$`GPS (3D speed) [m/s]`)
gh026929$`GPS (Lat.) [deg]` <- gh026929$`GPS (Lat.) [deg]` %>% reduce.coords()
gh026929$`GPS (Long.) [deg]` <- gh026929$`GPS (Long.) [deg]` %>% reduce.coords()
gh026929 %>% summary()
gh026929.sf <- gh026929 %>% st_as_sf(
  coords = c("GPS (Long.) [deg]", "GPS (Lat.) [deg]"),
  crs = 4326
)
gh026929.sf %>% st_write(.,
  "~/GitHub/data-sets-analysis/shapefiles/gh026929.shp",
  driver = "ESRI Shapefile",
  append = F
)
```

El dataset contiene 1726 registros de telemetría GPS capturados durante un período específico de operación vehicular, .

### Características Temporales

- **Período de registro**: 29 de agosto de 2024, entre las 01:32 y 01:34 horas
- **Duración total**: Aproximadamente 2 minutos de monitoreo continuo

### Granularidad temporal

- Diferencia Mínima: 0.55 segundos
- Diferencia Máxima: 0.59 segundos
- Diferencia Media: 0.55 segundos
- Diferencia Mediana: 0.55 segundos
- Desviación Standard: $5.42\times10^{-4}$ segundos

```{r gh026929.time, echo=FALSE, warning=FALSE}
differences <- (gh026929$date - c(NA, gh026929$date[1:(gh026929 %>% nrow() - 1)])) %>% as.numeric()
#differences %>% summary()
ggplot() +
  geom_histogram(aes(x = differences))
```


```{r gh026929.time.dif, echo=FALSE, warning=FALSE}
ggplot() +
  geom_histogram(aes(x = differences)) +
  labs(x = "Segundos de diferencia")
```

### Parámetros de Velocidad

- **Velocidad 3D**: Rango de 0.01 a 19.06 m/s (0.036 a 68.62 km/h)
- **Velocidad promedio**: 9.1 m/s (32.76 km/h)
- **Velocidad mediana**: 9.81 m/s (35.32 km/h), indicando una distribución sesgada hacia velocidades moderadas-altas

```{r gh026929.speed, echo=FALSE, warning=FALSE}
gh026929 %>%
  ggplot() +
  geom_histogram(aes(x = `GPS (3D speed) [m/s]`)) +
  labs(title = "Distribución de velocidades")
```

### Calidad de Señal GPS

- **Valor fix**: Constante en 3 para todos los registros, indicando que calculó su posición a partir de 3 satélites
- **Precisión**: Oscila entre 121 y 158 m (media: 125.9 m, mediana: 125 m)

```{r gh026929.precision, echo=FALSE, warning=FALSE}
gh026929 %>%
  ggplot() +
  geom_histogram(aes(x = precision)) +
  labs(title = "Distribución de precisiones")
```

### Aspectos Requieren Clarificación

**Variables por Definir**

- `cts`: Propósito y unidades no especificadas
- **Rango de alturas**: Valores de altitud GPS no reportados en el resumen

**Problemas de Formato Identificados**

- Coordenadas GPS (`Lat.` y `Long.`) sin formato decimal apropiado
- Velocidad 2D con inconsistencias en la ubicación del punto decimal
- Múltiples campos numéricos presentados sin separador decimal

### Procesamiento de Datos Realizado

**Paso a paso**

- "date" se convirtió en la concatenación de "date" y "hora" y se convierte en POSIXct con formato "%d/%m/%Y %H:%M"
- Se elimina la columna "hora"
- "GPS (2D speed) [m/s]" se trató de poner al mismo orden de magnitud de "GPS (3D speed) [m/s]" mediante la siguiente fórmula:

$$\text{reduce.2d.speed}(n,m)\equiv n\times10^{\lfloor\log_{10}m+1\rfloor-\lfloor\log_{10}n+1\rfloor}$$

- "GPS (Lat.) [deg]" y "GPS (Long.) [deg]" se ajustaron para tener 2 dígitos enteros mediante la siguiente fórmula:

$$\text{reduce.coords}(n)\equiv n\times10^{1-\lfloor\log_{10}|n|\rfloor}$$

## DTPR

```{r getData1.5, eval=FALSE, include=FALSE}
tracking.route <- "data/Tracking GPS"
tracking.cols <- c("EVT_REGISTRO_ID", "EVT_OP_TR_ID", "EVT_OP_TE_ID", "EVT_MES_INFORMACION", "EVT_SERVICIO_ID_ORACLE", "EVT_SERVICIO_ID", "EVT_SENTIDO", "EVT_IMEI", "EVT_PPU", "EVT_GPS_TIME_CHILE_STR", "EVT_GPS_TIME_UTC_0", "EVT_GPS_DIR_GEO", "Y_EVT_GPS_LAT", "X_EVT_GPS_LON", "EVT_GPS_VEL", "EVT_GPS_DOP", "EVT_DISTANCIA_RECORRIDA (Km)", "EVT_ESTADO_MOTOR_GPS", "EVT_TIPO_EVENTO", "EVT_TIPO_VIAJE", "EVT_DISTACIA_A_SERVICIO", "EVT_CARPETA")
folders <- tracking.route %>% list.dirs(recursive = F) %>% basename()
tracking.gps <- list()
tracking.read <- list()
for(folder in folders) {
  start.sys <- Sys.time()
  base.route <- paste(tracking.route, folder, "ArchivosTxt", sep = "/") %>% list.files(pattern = "^MNT_TRACKING", full.names = T)
  df <- base.route %>% read.table(header = F, sep = ";")
  df$EVT_CARPETA <- folder
  tracking.gps[[folder]] <- df
  end.sys <- Sys.time()
  dt.sys <- end.sys - start.sys
  tracking.read[[folder]] <- dt.sys
  print(folder)
  print(dt.sys)
}
# Reading time: 7 m + 8.22 s
start.sys <- Sys.time()
tracking.gps.df <- tracking.gps %>% bind_rows()
colnames(tracking.gps.df) <- tracking.cols
end.sys <- Sys.time()
binding.time <- end.sys - start.sys
# Binding time: 5 m + 0.63 s
start.sys <- Sys.time()
tracking.gps.df$EVT_SERVICIO_ID <- tracking.gps.df$EVT_SERVICIO_ID %>% as.factor()
tracking.gps.df$EVT_PPU <- tracking.gps.df$EVT_PPU %>% as.factor()
tracking.gps.df$EVT_GPS_TIME_CHILE_STR <- tracking.gps.df$EVT_GPS_TIME_CHILE_STR %>% as.POSIXct(format = "%d/%m/%Y %H:%M:%S", tz = "America/Santiago")
tracking.gps.df$EVT_GPS_TIME_UTC_0 <- tracking.gps.df$EVT_GPS_TIME_UTC_0 %>% as.POSIXct(format = "%d/%m/%Y %H:%M:%S")
tracking.gps.df$Y_EVT_GPS_LAT <- gsub(",", ".", tracking.gps.df$Y_EVT_GPS_LAT) %>% as.numeric()
tracking.gps.df$X_EVT_GPS_LON <- gsub(",", ".", tracking.gps.df$X_EVT_GPS_LON) %>% as.numeric()
tracking.gps.df$`EVT_DISTANCIA_RECORRIDA (Km)` <- gsub(",", ".", tracking.gps.df$`EVT_DISTANCIA_RECORRIDA (Km)`) %>% as.numeric()
tracking.gps.df$EVT_DISTACIA_A_SERVICIO <- gsub(",", ".", tracking.gps.df$EVT_DISTACIA_A_SERVICIO) %>% as.numeric()
tracking.gps.df$EVT_CARPETA <- tracking.gps.df$EVT_CARPETA %>% as.factor()
tracking.gps.df$EVT_SEÑAL <- NA
tracking.gps.df$EVT_SEÑAL[tracking.gps.df$EVT_GPS_DOP < 1] <- "Excelente"
tracking.gps.df$EVT_SEÑAL[tracking.gps.df$EVT_GPS_DOP >= 1 & tracking.gps.df$EVT_GPS_DOP < 2] <- "Muy Buena"
tracking.gps.df$EVT_SEÑAL[tracking.gps.df$EVT_GPS_DOP >= 2 & tracking.gps.df$EVT_GPS_DOP < 5] <- "Buena"
tracking.gps.df$EVT_SEÑAL[tracking.gps.df$EVT_GPS_DOP >= 5 & tracking.gps.df$EVT_GPS_DOP <= 10] <- "Regular"
tracking.gps.df$EVT_SEÑAL[tracking.gps.df$EVT_GPS_DOP >= 5 & tracking.gps.df$EVT_GPS_DOP > 10] <- "Mala"
tracking.gps.df$EVT_SEÑAL <- tracking.gps.df$EVT_SEÑAL %>% as.factor()
end.sys <- Sys.time()
modifying.time <- end.sys - start.sys
# Modifying time: 30 m + 7.08 s
options(future.globals.maxSize = 16 * 1024^3)
shp.time <- list()
tracking.gps.df.sf <- list()
for(folder in folders){
  start.sys <- Sys.time()
  df <- tracking.gps.df[tracking.gps.df$EVT_CARPETA == folder,]
  df.rename <- df %>%
    rename(
      SERV_ID = EVT_SERVICIO_ID,
      SERV_ID_O = EVT_SERVICIO_ID_ORACLE,
      GPS_TIME_CH = EVT_GPS_TIME_CHILE_STR,
      GPS_TIME_UTC = EVT_GPS_TIME_UTC_0,
      DIST_REC = `EVT_DISTANCIA_RECORRIDA (Km)`,
      DIST_SERV = EVT_DISTACIA_A_SERVICIO,
      CARPETA = EVT_CARPETA,
      SEÑAL = EVT_SEÑAL
    )
  sf <- df.rename %>% st_as_sf(
    coords = c("X_EVT_GPS_LON", "Y_EVT_GPS_LAT"),
    crs = 4326
  )
  file.name <- paste(folder, "shp", sep = ".")
  file.path. <- paste("~/GitHub/data-sets-analysis/shapefiles/DTPR", file.name, sep = "/")
  sf %>% st_write(.,
    file.path.,
    driver = "ESRI Shapefile",
    append = F
  )
  tracking.gps.df.sf[[folder]] <- sf
  end.sys <- Sys.time()
  dt <- end.sys - start.sys
  shp.time[[folder]] <- dt
  print(folder)
  print(dt)
}
# Shapefile time: 4m + 3.76s
shp.total.time <- shp.time %>% sum.time()
```

```{r getData1.51, eval=FALSE, include=FALSE}
tracking.gps.df %>% summary()
```

El dataset consolidado comprende 21683856 registros de telemetría GPS provenientes del sistema de monitoreo de transporte público DTPR, capturados durante el mes de agosto de 2025 a través de 31 unidades operativas diferentes.

### Metadatos de Procesamiento

- **Tiempo total de lectura**: 7 minutos 8.22 segundos
- **Tiempo de consolidación**: 5 minutos 0.63 segundos
- **Tiempo de transformación**: 30 minutos 7.08 segundos
- **Total de procesamiento**: 42 minutos 15.93 segundos

### Período de Monitoreo

- **Fecha inicial**: 1 de agosto de 2025, 00:00:00 (hora Chile)
- **Fecha final**: 1 de septiembre de 2025, 00:05:27 (hora Chile)
- **Duración**: 31 días completos + 5 minutos
- **Cobertura temporal**: Mes completo de agosto 2025

### Granularidad temporal (separado por EVT_PPU)

- Diferencia Mínima: 0 (al mismo tiempo)
- Diferencia Máxima: 25 días, 22 horas, 42 minutos, 36 segundos
- Diferencia Media: 6 minutos, 51 segundos
- Diferencia Mediana: 1 minuto, 1 segundo
- Desviación Standard: 2 horas, 24 minutos, 17.19 segundos

```{r tracking.gps.df.time, echo=FALSE, warning=FALSE}
differences <- tracking.gps.df %>%
  mutate(
    prev_time = EVT_GPS_TIME_CHILE_STR %>% lag(),
    same_ppu = (EVT_PPU == (EVT_PPU %>% lag(default = EVT_PPU %>% first() - 1)))
  ) %>%
  mutate(
    diff = if_else(same_ppu, (EVT_GPS_TIME_CHILE_STR - prev_time) %>% as.numeric(), NA_real_)
  ) %>%
  pull(diff)
#differences %>% summary()
diff.mean <- differences %>% mean(na.rm = T)
diff.mediam <- differences %>% median(na.rm = T)
tracking.gps.df %>% ggplot() +
  geom_histogram(aes(x = differences)) +
  geom_vline(aes(xintercept = diff.mean, colour = "promedio")) +
  geom_vline(aes(xintercept = diff.mediam, colour = "mediana")) +
  scale_x_log10() +
  scale_y_log10() +
  scale_color_manual(
    values = c("promedio" = "red", "mediana" = "green"),
    breaks = c("promedio", "mediana")
  )
```

### Características Operacionales del Sistema

**Flota y Rutas Monitoreadas**

- **Rutas más frecuentes**:
  - "13GS": 617591 registros
  - "43JT": 500230 registros
  - "14HT": 481486 registros
- **Vehículos más activos**:
  - "FSLC62": 27847 registros
  - "TTHL10": 25901 registros
  - "SZDZ86": 25483 registros
  
```{r tracking.gps.df.routes, echo=FALSE, warning=FALSE}
tracking.gps.df[tracking.gps.df$EVT_SERVICIO_ID %in% (tracking.gps.df %>%
  count(EVT_SERVICIO_ID) %>%
  slice_max(n, n = 10) %>%
  pull(EVT_SERVICIO_ID)),] %>%
  ggplot() +
  geom_bar(aes(
    y = EVT_SERVICIO_ID %>% fct_infreq() %>% fct_rev(),
    fill = EVT_SERVICIO_ID
  ),
  show.legend = F) +
  labs(y = "Ruta", title = "10 rutas más frecuentes")
```

**Distribución Direccional**

- **Sentido ida (0)**: 10809559 registros
- **Sentido vuelta (1)**: 10671146 registros
- **Sentido indeterminado (-1)**: 203151 registros

```{r tracking.gps.df.direction, echo=FALSE, warning=FALSE}
tracking.gps.df[tracking.gps.df$EVT_SERVICIO_ID %in% (tracking.gps.df %>%
  count(EVT_SERVICIO_ID) %>%
  slice_max(n, n = 10) %>%
  pull(EVT_SERVICIO_ID)),] %>%
  ggplot() +
  geom_bar(aes(
    y = EVT_SERVICIO_ID %>% fct_infreq() %>% fct_rev(),
    fill = EVT_SENTIDO %>% as.factor()
  )) +
  labs(y = "Ruta", fill = "Sentido", title = "10 rutas más frecuentes")
```

**Métricas de Desempeño Técnico**

_Calidad de Señal GPS_

- Muy Buena: 17924666 registros
- Buena: 966491 registros
- Regular: 592320 registros
- Mala: 2200379 registros

```{r tracking.gps.df.signal, echo=FALSE, warning=FALSE}
tracking.gps.df %>% ggplot() +
  geom_histogram(aes(x = EVT_GPS_DOP, fill = EVT_SEÑAL)) +
  scale_x_log10() +
  scale_y_log10()
```

_Velocidades Operacionales_

- Rango: 0 - 193 km/h
- Velocidad promedio: 21.69 km/h
- Velocidad mediana: 19 km/h

```{r tracking.gps.df.speed, echo=FALSE, warning=FALSE}
tracking.gps.df %>% 
  ggplot() +
  geom_histogram(aes(x = EVT_GPS_VEL))
```


_Estados del Sistema_

- Motor encendido (1): 21619957 registros
- Motor apagado (0): 63899 registros

```{r tracking.gps.df.states, echo=FALSE, warning=FALSE}
tracking.gps.df[tracking.gps.df$EVT_ESTADO_MOTOR_GPS == 0,] %>%
  ggplot() +
  geom_bar(aes(
    y = EVT_CARPETA %>% fct_infreq() %>% fct_rev()
  )) +
  labs(y = "Carpeta", title = "Registros con motor apagado")
```

### Procesamiento y Normalización de Datos

**Paso a paso**

- Se lee la carpeta
- Se crea la columna "EVT_CARPETA" con el nombre de la carpeta
- Se unifican los datasets en uno
- "EVT_SERVICIO_ID" se convierte en factor
- "EVT_PPU" se convierte en factor
- "EVT_GPS_TIME_CHILE_STR" se convierte en POSIXct con formato "%d/%m/%Y %H:%M:%S" y zona horaria "America/Santiago"
- "EVT_GPS_TIME_UTC_0" se convierte en POSIXct con formato "%d/%m/%Y %H:%M:%S"
- En "Y_EVT_GPS_LAT", se reemplaza "," por "." y se convierte en numérico
- En "X_EVT_GPS_LON", se reemplaza "," por "." y se convierte en numérico
- En "EVT_DISTANCIA_RECORRIDA (Km)", se reemplaza "," por "." y se convierte en numérico
- En "EVT_DISTACIA_A_SERVICIO", se reemplaza "," por "." y se convierte en numérico
- "EVT_CARPETA" se convierte en factor
- Se crea la columna "EVT_SEÑAL" a partir de los valores de la columna "EVT_GPS_DOP":
  - `Excelente`: $EVT GPS DOP < 1$
  - `Muy Buena`: $1 \leq EVT GPS DOP < 2$
  - `Buena`: $2 \leq EVT GPS DOP < 5$
  - `Regular`: $5 \leq EVT GPS DOP \leq 10$
  - `Mala`: $EVT GPS DOP > 10$

### Análisis por Unidad Operativa

**Patrones de Operación por Unidad**

_Frecuencia de Reporte_

- **Típico**: 1:00-1:03 minutos entre registros por vehículo (mediana, separado por patente)
- **Variaciones**: UN52_265 muestra intervalos más irregulares (3.5s - 1min) (mediana, separado por patente)
- **Consistencia**: Mayoría mantiene intervalos estables

_Distribución por Unidad_

- **Mayor volumen**: UN80_274 (1459884 registros)
- **Menor volumen**: UN52_265 (118026 registros)
- **Promedio por unidad**: ~699479 registros

_Características Específicas Destacables_

- **UN13_247**: Operación exclusiva de ruta "13GS"
- **UN18_254**: Frecuencia muy consistente (1:03-1:03.5 min) (mediana, separado por patente)
- **UN22_257**: Mayor variabilidad en intervalos (59s - 22:31 min) (mediana, separado por patente)
- **UNB0_277**: Única unidad con datos en septiembre

```{r getData1.6, eval=FALSE, include=FALSE}
cities <- c(
  "Arica" = "arica",
  "Iquique" = "iquique",
  "Tocopilla" = "tocopilla",
  "Antofagasta" = "antofagasta",
  "Calama" = "calama",
  "Coquimbo - La Serena" = "serena",
  "Gran Valparaíso" = "valparaiso",
  "Región Metropolitana" = "rm-sur",
  "Linares" = "linares",
  "Chillán" = "chillan",
  "Gran Concepción" = "concepcion",
  "Villarrica" = "villarrica",
  "Temuco" = "temuco",
  "Valdivia" = "valdivia",
  "Osorno" = "osorno",
  "Puerto Montt" = "ptomontt",
  #"Castro" = "castro",
  #"Quellón" = "quellon",
  "Punta Arenas" = "punta-arenas"
)

get.data.gtfs.rt <- function(city = "concepcion"){
  if(!(city %in% cities)){
    stop(paste(city, "isn't a valid city code"))
  }
  url <- paste0("https://datamanager.dtpr.transapp.cl/data/gtfs-rt/", city, ".proto")
  response <- GET(url, add_headers("X-API-KEY" = token))
  if (response$status_code != 200) {
    stop(paste("Request Error:", response$status_code, "|", response))
  }
  raw.data <- content(response, "raw")
  temp.file <- tempfile(fileext = ".pb")
  writeBin(raw.data, temp.file)
  feed <- temp.file %>% readBin(what = "raw", n = file.info(temp.file)$size)
  safe.raw.to.char <- function(raw.vec){
    printable <- raw.vec[raw.vec >= 32 & raw.vec <= 126 | raw.vec == 10 | raw.vec == 13]
    printable %>% as.raw() %>% rawToChar()
  }
  visible.text <- feed %>% safe.raw.to.char()
  extract.all <- function(str){
    str_extract_all(visible.text, str)[[1]]
  }
  uuids <- extract.all("[a-f0-9]{8}-[a-f0-9]{4}-[a-f0-9]{4}-[a-f0-9]{4}-[a-f0-9]{12}")
  trip.ids <- extract.all("[0-9]{3}_[A-Z]_[A-Z]_[0-9]{4}")
  hours <- extract.all("[0-9]{2}:[0-9]{2}:[0-9]{2}")
  dates0 <- extract.all("202[0-9]{5}")
  dates <- paste(substr(dates0, 1, 4), substr(dates0, 5, 6), substr(dates0, 7, 8), sep = "-")
  datetimes <- paste(dates, hours) %>% as.POSIXct(format = "%Y-%m-%d %H:%M:%S")
  route.ids <- extract.all("P[0-9]{5}|[0-9]{4}0")
  timestamps <- extract.all("[0-9]{10}")
  datetimes.utc <- timestamps %>% as.numeric() %>% as.POSIXct(origin = "1970-01-01", tz = "UTC")
  datetimes.utc %>% summary()
  n <- min(uuids %>% length(), trip.ids %>% length(), route.ids %>% length() / 5)
  city.name <- cities[cities == city] %>% names()
  df <- data.frame(
    vehicle.uuid = if (uuids %>% length() >= n) uuids[1:n] else rep(NA, n),
    trip.id = if (trip.ids %>% length() >= n) trip.ids[1:n] else rep(NA, n),
    start.datetime = if (datetimes %>% length() >= n) datetimes[1:n] else rep(NA, n),
    sample.route.id = if (route.ids %>% length() >= n) route.ids[1:n] else rep(NA, n),
    city = city.name,
    stringsAsFactors = F
  )
  return(df)
}

get.all.data.gtfs.rt <- function(print.time = T){
  df.list <- list()
  if(print.time) dt.list <- list()
  for(city in cities){
    if(print.time) start.sys <- Sys.time()
    df <- city %>% get.data.gtfs.rt()
    if(print.time) end.sys <- Sys.time()
    city.name <- cities[cities == city] %>% names()
    df.list[[city.name]] <- df
    if(print.time){
      dt.sys <- end.sys - start.sys
      print(city.name)
      print(dt.sys)
      dt.list[[city.name]] <- dt.sys
    }
  }
  grfs.df <- df.list %>% bind_rows()
  grfs.df$city <- grfs.df$city %>% as.factor()
  grfs.df$trip.id <- grfs.df$trip.id %>% as.factor()
  grfs.df$sample.route.id <- grfs.df$sample.route.id %>% as.factor()
  if(print.time) {
    grfs.dt <- dt.list %>% sum.time()
    print("Total Reading Time:")
    print(grfs.dt)
  }
  return(grfs.df)
}

save.data.gtfs.rt <- function(city = "concepcion"){
  now <- Sys.time()
  real.time <- get.data.gtfs.rt()
  file.name <- paste(city, now %>% as.character() %>% str_replace_all(" ", "_") %>% str_replace_all(":", "."), "rds", sep = ".")
  file.path. <- paste("~/GitHub/data-sets-analysis/rds-files/DTPR API", file.name, sep = "/")
  real.time %>% saveRDS(file = file.path.)
}

run.continuously <- function(
  interval.minutes = 30,
  city = "concepcion"
) {
  while(T) {
    tryCatch({
      city %>% save.data.gtfs.rt()
      cat("GTFS data saved at", Sys.time() %>% as.character(), "\n")
    }, error = function(e) {
      cat("Error:", e$message, "at", Sys.time() %>% as.character(), "\n")
    })
    Sys.sleep(interval.minutes * 60)
  }
}
```


## Data accidentes de carabineros.xlsx

```{r getData2, eval=FALSE, include=FALSE}
# Data accidentes de carabineros.xlsx
police.accidents <- read_excel("data/Data accidentes de carabineros.xlsx", 
    col_types = c("numeric", "date", "skip", 
        "date", "text", "text", "text", "text", 
        "text", "numeric", "numeric", "numeric", 
        "numeric", "numeric", "text", "text", 
        "text", "text", "text"))
police.accidents$FECHA <- paste(police.accidents$FECHA, police.accidents$HORA %>% format(format = "%H:%M:%S")) %>% as.POSIXct(format = "%Y-%m-%d %H:%M")
police.accidents <- police.accidents %>% select(-HORA)
police.accidents$ZONA <- police.accidents$ZONA %>% as.factor()
police.accidents$COMUNA <- police.accidents$COMUNA %>% as.factor()
police.accidents$TIPO <- police.accidents$TIPO %>% as.factor()
police.accidents$CAUSA <- police.accidents$CAUSA %>% as.factor()
police.accidents$SECTOR <- police.accidents$SECTOR %>% as.factor()
police.accidents$KM <- police.accidents$KM %>% as.numeric()
police.accidents$PARTE <- police.accidents$PARTE %>% as.numeric()
police.accidents$TRIBUNAL <- police.accidents$TRIBUNAL %>% as.factor()
police.accidents$TIPO %>% summary()
police.accidents$`MACRO TIPO` <- police.accidents$TIPO %>% as.character()
police.accidents$`MACRO TIPO`[
  police.accidents$TIPO %in% c(
    "CHOQUE",
    "CHOQUE FRONTAL",
    "CHOQUE LATERAL",
    "CHOQUE POSTERIOR"
  )
] <- "CHOQUE"
police.accidents$`MACRO TIPO`[
  police.accidents$TIPO %in% c(
    "COLISION",
    "COLISION FRONTAL",
    "COLISION LATERAL",
    "COLISION PERPENDICULAR",
    "COLISION POR ALCANCE"
  )
] <- "COLISION"
police.accidents$`MACRO TIPO` <- police.accidents$`MACRO TIPO` %>% as.factor()
police.accidents %>% summary()
```

El dataset comprende 5739 registros de accidentes de tránsito documentados por Carabineros de Chile durante un período concentrado de 30 días.

### Período de Análisis

- **Cobertura temporal**: 1 al 30 de marzo de 2025 (30 días)
- **Registros diarios promedio**: aproximadamente 191 accidentes

### Granularidad Temporal

```{r police.accidents.time, echo=FALSE, warning=FALSE}
differences <- differences <- (police.accidents$FECHA - c(NA, police.accidents$FECHA[1:(police.accidents %>% nrow() - 1)])) %>% as.numeric() / 3600
#differences %>% summary()
ggplot() +
  geom_bar(aes(x = differences %>% floor())) +
  scale_y_log10() +
  labs(x = "Diferencia de tiempo entre registros (horas)")
```

### Distribución Geográfica

- **Regiones con mayor siniestralidad**:
    - Región Metropolitana (1513 casos)
    - Región del Biobío (699 casos)
    - Región del Maule (574 casos)

```{r police.accidents.regions, echo=FALSE, warning=FALSE}
police.accidents %>% ggplot() +
  geom_bar(aes(y = ZONA %>% fct_infreq() %>% fct_rev())) +
  labs(y = "ZONA")
```

- **Comunas más afectadas**:
    - Concepción (193 accidentes)
    - Temuco (175 accidentes)
    - Arica (150 accidentes)

```{r police.accidents.cities, echo=FALSE, warning=FALSE}
police.accidents[police.accidents$COMUNA %in% (police.accidents %>%
  count(COMUNA) %>%
  slice_max(n, n = 10) %>%
  pull(COMUNA)),] %>% ggplot() +
  geom_bar(aes(y = COMUNA %>% fct_infreq() %>% fct_rev(), fill = ZONA)) +
  labs(y = "COMUNA")
```

- **KM**:
    - **Rango**: Entre 0 y 112000 km
    - **Media**: 1629 km
    - **Mediana**: 312 km
    - **Nulos**: 3210 registros

```{r police.accidents.km, echo=FALSE, warning=FALSE}
police.accidents %>% ggplot() +
  geom_density(aes(x = KM)) +
  scale_x_log10()
```

- **PARTE**:
    - **Rango**: Entre $1 y 4157
    - **Media**: $491.4
    - **Mediana**: $282

```{r police.accidents.pay, echo=FALSE, warning=FALSE}
police.accidents %>% ggplot() +
  geom_density(aes(x = PARTE, colour = `MACRO TIPO`)) +
  scale_x_log10()
```

### Clasificación de Accidentes

- **Tipos predominantes**:
    - Colisión: 2,936 casos
    - Choque: 1,801 casos
    - Atropello: 461 casos

```{r police.accidents.types, echo=FALSE, warning=FALSE}
police.accidents %>% ggplot() +
  geom_bar(aes(y = `MACRO TIPO` %>% fct_infreq() %>% fct_rev(), fill = ZONA %>% fct_infreq())) +
  labs(y = "MACRO TIPO", fill = "ZONA")
```

- **Distribución por sector**:
    - Urbano: 4,432 casos
    - Rural: 1,304 casos
    - Vía férrea: 3 casos

```{r police.accidents.sectors, echo=FALSE, warning=FALSE}
police.accidents %>% ggplot() +
  geom_bar(aes(y = SECTOR %>% fct_infreq() %>% fct_rev(), fill = ZONA %>% fct_infreq())) +
  labs(y = "SECTOR", fill = "ZONA")
```

### Procesamiento y Normalización de Datos

**Paso a paso**

- "FECHA" se convirtió en la concatenación de "FECHA" y "HORA" y se convierte en POSIXct con formato "%d/%m/%Y %H:%M"
- Se elimina la columna "HORA"
- "ZONA" se convierte en factor
- "COMUNA" se convierte en factor
- "TIPO" se convierte en factor
- "CAUSA" se convierte en factor
- "SECTOR" se convierte en factor
- "KM" se convierte en numérico
- "PARTE" se convierte en numérico
- "TRIBUNAL" se convierte en factor
- Se crea la columna "MACRO TIPO" con el valor de "TIPO", pero unificando los valores de "CHOQUE", "CHOQUE FRONTAL", "CHOQUE LATERAL"y "CHOQUE POSTERIOR" como "CHOQUE" y "COLISION", "COLISION FRONTAL", "COLISION LATERAL", "COLISION PERPENDICULAR", "COLISION POR ALCANCE" como "COLISION"
- "MACRO TIPO" se convierte en factor

## Incidentes de tráfico radio.xlsx

```{r getData3, eval=FALSE, include=FALSE}
# Incidentes de tráfico radio.xlsx
file.path <- "data/Incidentes de tráfico radio.xlsx"
sheet.names <- file.path %>% excel_sheets()
date.sheets <- sheet.names[grepl("^\\d{1,2}-\\d{1,2}$", sheet.names)]
radio.accidents <- list()
cell.colors <- list()
get.cells.colors <- function(file.path, sheet.name, column.indices) {
  wb <- file.path %>% loadWorkbook()
  styles <- wb %>% getStyles()
  sheet <- wb[[sheet.name]]
  colors.list <- list()
  for(col.idx in column.indices) {
    col.letter <- col.idx %>% int2col()
    cell.refs <- paste0(col.letter, 1:(sheet$rows %>% length()))
    colors <- sapply(cell.refs, function(cell.ref) {
      cell.style <- sheet$styleObjects[[which(sapply(sheet$styleObjects, function(x) x$rows == as.numeric(gsub("\\D", "", cell.ref)) & x$cols == col.idx))]]
      if(!is.null(cell.style)) {
        cell.style$style$fill$fillFg
      } else {
        NA
      }
    })
    colors.list[[colnames(sheet)[col.idx]]] <- colors
  }
  colors.list
}
get.cell.colors.simple <- function(file.path, sheet.name) {
  wb <- file.path %>% loadWorkbook()
  all.styles <- wb %>% getStyles()
  sheet.styles <- wb$styleObjects[grepl(paste0("^", sheet.name, "\\."), wb$styleObjects %>% names())]
  sheet.data <- wb %>% read.xlsx(sheet = sheet.name)
  col.names <- sheet.data %>% names()
  tipo.cols <- (col.names %in% c("Tipo de incidente", "tipo de incidente")) %>% which()
  if(length(tipo.cols) == 0){
    list()
  } else {
    colors.df <- NA %>% matrix(nrow = sheet.data %>% nrow(), ncol = tipo.cols %>% length()) %>% data.frame()
    names(colors.df) <- col.names[tipo.cols]
    for(style.obj in wb$styleObjects) {
      if(style.obj$sheet == sheet.name && style.obj$cols %in% tipo.cols) {
        col.name <- col.names[style.obj$cols]
        for(row in style.obj$rows) {
          if(row <= colors.df %>% nrow()) {
            colors.df[row, col.name] <- style.obj$style$fill$fillFg
          }
        }
      }
    }
    colors.df
  }
}
get.cell.colors.tidyxl <- function(file.path, sheet.name) {
  cells <- file.path %>% xlsx_cells(sheets = sheet.name)
  formats <- file.path %>% xlsx_formats()
  target.cols <- c("Tipo de incidente", "tipo de incidente")
  col.indices <- cells %>%
    filter(!(character %>% is.na()) | !(numeric %>% is.na())) %>% 
    group_by(col) %>%
    summarise(
      header = character %>% first(na_rm = T),
      .groups = "drop"
    ) %>%
    filter(header %in% target.cols) %>%
    pull(col)
  if(col.indices %>% length() == 0){
    data.frame(
      row = integer(),
      col = integer(),
      color = character()
    )
  } else {
    colors.df <- cells %>%
      filter(col %in% col.indices) %>%
      select(row, col, address, character, numeric, local_format_id) %>%
      mutate(
        value = coalesce(character, numeric %>% as.character())
      ) %>%
      mutate(
        color = ifelse(
          !(local_format_id %>% is.na()),
          formats$local$fill$patternFill$fgColor$rgb[local_format_id],
          NA_character_
        )
      ) %>%
      select(row, col, value, color)
    colors.df
  }
}
for(sheet in date.sheets) {
  df <- file.path %>% read_excel(sheet = sheet)
  colors.info <- get.cell.colors.tidyxl(file.path, sheet)
  day.month <- (sheet %>% strsplit(., "-"))[[1]]
  day <- day.month[1] %>% as.numeric()
  month <- day.month[2] %>% as.numeric()
  ## ¿De qué año es?
  comp.date <- paste("2024", month, day, sep = "-") %>% as.Date()
  df$fecha <- comp.date
  df$`#ID` <- df$`#ID` %>% as.numeric()
  df$Hora <- df$Hora %>% as.numeric() %>% as.POSIXct() %>% format(format = "%H:%M")
  radio.accidents[[sheet]] <- df
  cell.colors[[sheet]] <- colors.info
}
radio.accidents.df <- radio.accidents %>% bind_rows()
all.colors.df <- cell.colors %>% bind_rows(.id = "sheet.name")
radio.accidents.df$sheet.name <- NA_character_
radio.accidents.df$original.row <- NA_integer_
row.counter <- 1
for(sheet in date.sheets) {
  n.rows <- radio.accidents[[sheet]] %>% nrow()
  if(n.rows > 0) {
    radio.accidents.df$sheet.name[row.counter:(row.counter + n.rows - 1)] <- sheet
    radio.accidents.df$original.row[row.counter:(row.counter + n.rows - 1)] <- 1:n.rows
  }
  row.counter <- row.counter + n.rows
}
radio.accidents.df <- radio.accidents.df %>%
  left_join(
    all.colors.df %>%
      select(sheet.name, row, color) %>%
      rename(original.row = row),
    by = c("sheet.name", "original.row")
  )
radio.accidents.df <- radio.accidents.df[!(radio.accidents.df$coord %>% is.na() | radio.accidents.df$`Reporte completo? (SI/NO)` %>% is.na()),]
radio.accidents.df$coord[!(radio.accidents.df$lat %>% is.na())] <- radio.accidents.df$lat[!(radio.accidents.df$lat %>% is.na())]
radio.accidents.df <- radio.accidents.df %>% select(-c(lat, `tipo de incidente`, ...7, ...13, sheet.name, original.row))
radio.accidents.df$dir[!(radio.accidents.df$...12 %>% is.na()) & (radio.accidents.df$dir %>% is.na())] <- radio.accidents.df$...12[!(radio.accidents.df$...12 %>% is.na()) & (radio.accidents.df$dir %>% is.na())]
radio.accidents.df <- radio.accidents.df %>% select(-...12)
radio.accidents.df$`Reporte completo? (SI/NO)`[(radio.accidents.df$`Reporte completo? (SI/NO)` %in% c("is", "si", "SI", "su")) %>% which()] <- "SI"
radio.accidents.df$`Reporte completo? (SI/NO)`[(radio.accidents.df$`Reporte completo? (SI/NO)` %in% c("no", "NO")) %>% which()] <- "NO"
radio.accidents.df$`Reporte completo? (SI/NO)`[(radio.accidents.df$`Reporte completo? (SI/NO)` == "-") %>% which()] <- NA
radio.accidents.df$`es incidente de tráfico? (si/no)`[(radio.accidents.df$`es incidente de tráfico? (si/no)` %in% c("si", "SI")) %>% which()] <- "SI"
radio.accidents.df$`es incidente de tráfico? (si/no)`[(radio.accidents.df$`es incidente de tráfico? (si/no)` %in% c("no", "NO")) %>% which()] <- "NO"
radio.accidents.df$dir[radio.accidents.df$dir %in% c("-", "n/a", "n/A")] <- NA
radio.accidents.df$dir[radio.accidents.df$dir %in% c("e-o", "E-O")] <- "E-O"
radio.accidents.df$dir[radio.accidents.df$dir %in% c("o-e", "O-E")] <- "O-E"
radio.accidents.df$dir[radio.accidents.df$dir %in% c("n-s", "n.s", "N-S")] <- "N-S"
radio.accidents.df$dir[radio.accidents.df$dir %in% c("s-n", "S-N")] <- "S-N"
radio.accidents.df$dir[radio.accidents.df$dir %in% c("n-s. s-n", "n-s.s-n", "N-S, S-N")] <- "N-S, S-N"
radio.accidents.df$dir[radio.accidents.df$dir %in% c("s-n.n-s", "S-N, N-S")] <- "S-N, N-S"
radio.accidents.df$`Reporte completo? (SI/NO)` <- radio.accidents.df$`Reporte completo? (SI/NO)` %>% as.factor()
radio.accidents.df$`es incidente de tráfico? (si/no)` <- radio.accidents.df$`es incidente de tráfico? (si/no)` %>% as.factor()
radio.accidents.df$dir <- radio.accidents.df$dir %>% as.factor()
radio.accidents.df$color <- radio.accidents.df$color %>% as.factor()
color_mapping <- c(
  "FF00B0F0" = "Intervenciones de Emergencia", 
  "FF00FFFF" = "Congestión",
  "FFFF0000" = "Accidente de tránsito",
  "FFFF00FF" = "Obstrucciones en la vía",
  "FFFF6600" = "Problema Infraestructura de control de tránsito",
  "FFFFC000" = "Condición de tráfico",
  "FFFFFF00" = "Congestión",
  "FF00B050" = "Otros"
)
radio.accidents.df$`Tipo de incidente` <- ifelse(
  radio.accidents.df$color %>% is.na(),
  "Congestión",
  color_mapping[radio.accidents.df$color]
) %>% as.factor()
radio.accidents.df <- radio.accidents.df %>% select(-color)
radio.accidents.df <- radio.accidents.df %>% fill(Hora, .direction = "down")
radio.accidents.df <- radio.accidents.df %>% separate(coord, into = c("lat", "lng"), sep = ",\\s*") %>% mutate(lat = lat %>% as.numeric(), lng = lng %>% as.numeric())
radio.accidents.df <- radio.accidents.df[!(radio.accidents.df$lat %>% is.na()),]
radio.accidents.df$Hora <- paste(radio.accidents.df$fecha, radio.accidents.df$Hora) %>% as.POSIXct(format = "%Y-%m-%d %H:%M")
radio.accidents.df <- radio.accidents.df %>% select(-fecha)
radio.accidents.df %>% summary()
radio.accidents.df.sf <- radio.accidents.df %>% st_as_sf(
  coords = c("lng", "lat"),
  crs = 4326
)
radio.accidents.df.sf %>% st_write(.,
  "~/GitHub/data-sets-analysis/shapefiles/radio.accidents.df.shp",
  driver = "ESRI Shapefile",
  append = F
)
```

El dataset contiene 312 registros de incidentes de tráfico reportados a través de sistemas de radio durante un período de 37 días.

### Período de Registro

- **Duración**: 15 de julio al 20 de agosto de 2024
- **Cobertura temporal**: 37 días de monitoreo continuo

### Granularidad Temporal

```{r radio.accidents.df.time, echo=FALSE, warning=FALSE}
radio.accidents.df.sorted <- radio.accidents.df[radio.accidents.df$Hora %>% order(),]
differences <- (radio.accidents.df.sorted$Hora - c(NA, radio.accidents.df.sorted$Hora[1:(radio.accidents.df.sorted %>% nrow() - 1)])) %>% as.numeric()
#differences %>% summary()
radio.accidents.df %>% ggplot() +
  geom_density(aes(x = Hora, colour = `Tipo de incidente`)) +
  scale_colour_discrete(labels = label_wrap_gen(width = 15))
```

### Clasificación de Incidentes

- **Naturaleza del incidente**:
    - **Incidentes de tráfico**: 263 casos
    - **No incidentes de tráfico**: 1 caso
    - **No especificado**: 48 casos

- **Completitud de reportes**:
    - **Reportes completos**: 257 casos
    - **Reportes incompletos**: 55 casos

```{r radio.accidents.df.complete.report, echo=FALSE, warning=FALSE}
radio.accidents.df %>% ggplot() +
  geom_bar(aes(y = `Reporte completo? (SI/NO)` %>% fct_infreq() %>% fct_rev(), fill = `es incidente de tráfico? (si/no)` %>% fct_infreq())) +
  labs(y = "Reporte completo? (SI/NO)", fill = "es incidente de tráfico? (si/no)")
```

### Tipología de Incidentes

*Distribución por categoría*:

- Congestión: 157 casos
- Accidentes de tránsito: 43 casos
- Problema Infraestructura de control de tránsito: 38 casos
- Condición de tráfico: 25 casos
- Obstrucciones en la vía: 20 casos
- Intervenciones de emergencia: 5 casos
- Otros: 24 casos

```{r radio.accidents.df.types, echo=FALSE, warning=FALSE}
radio.accidents.df %>% ggplot() +
  geom_bar(aes(y = `Tipo de incidente` %>% fct_infreq() %>% fct_rev(), fill = dir %>% fct_infreq())) +
  labs(y = "Tipo de incidente", fill = "dir") +
  scale_y_discrete(labels = label_wrap_gen(width = 15))
```


### Direccionalidad del Tráfico Afectado

**Patrones de flujo vehicular impactado**:

- Sur a Norte (S-N): 53 casos
- Norte a Sur (N-S): 51 casos
- Bidireccional (N-S, S-N): 17 casos
- Este a Oeste (E-O): 15 casos
- Oeste a Este (O-E): 10 casos
- Ambos sentidos (a/s): 2 casos
- Bidireccional (S-N, N-S): 1 caso
- No especificado: 163 casos

```{r radio.accidents.df.dir, echo=FALSE, warning=FALSE}
radio.accidents.df %>% ggplot() +
  geom_bar(aes(fill = `Tipo de incidente` %>% fct_infreq(), y = dir %>% fct_infreq() %>% fct_rev())) +
  labs(fill = "Tipo de incidente", y = "dir") +
  scale_fill_discrete(labels = label_wrap_gen(width = 15))
```

### Procesamiento y Normalización de Datos

**Paso a paso**

- Se lee la hoja
- Se lee el color de la columna "tipo de incidente"
- Se crea la columna "fecha" con el nombre de la hoja
- "#ID" se convierte en numérico
- "Hora" se convierte en POSIXct con formato "%H:%M"
- Se unen los datasets en uno
- Se crea la columna "sheet.name" con el nombre de las hojas
- Se crea la columna "original.row" con el número de la fila original
- Se crea la columna "color" con el código del color de la columna "tipo de incidente"
- Se eliminan las filas en las que "coord" o "Reporte completo? (SI/NO)" es nulo
- Se eliminan las columnas "lat", "tipo de incidente", "...7", "...13", "sheet.name", "original.row"
- "dir" toma el valor de "...12" cuando "...12" no es nulo y "dir" es nulo
- Se elimina la columna "...12"
- En "Reporte completo? (SI/NO)", los valores "is", "si", "SI" y "su" se unifican como "SI", los valores "no" y "NO", como "NO" y "-" se considera nulo
- En "es incidente de tráfico? (si/no)", los valores "si" y "SI" se unifican como "SI" y los valores "no" y "NO", como "NO"
- En "dir", los valores "e-o" y "E-O" se unifican como "E-O", "o-e" y "O-E", como "O-E", "n-s", "n.s" y "N-S", como "N-S", "s-n" y "S-N" como "S-N", "n-s. s-n", "n-s.s-n" y "N-S, S-N", como "N-S, S-N", "s-n.n-s" y "S-N, N-S", como "S-N, N-S" y "-", "n/a" y "n/A" se consideran nulos
- "Reporte completo? (SI/NO)" se convierte en factor
- "es incidente de tráfico? (si/no)" se convierte en factor
- "dir" se convierte en factor
- "color" se convierte en factor
- Se crea la columna "Tipo de incidente" a partir de "color":
  - "Congestión" cuando es nulo
  - "Intervenciones de Emergencia" cuando es <font color="#FF00B0F0">FF00B0F0</font>
  - "Congestión" cuando es <font color="#FF00FFFF">FF00FFFF</font>
  - "Accidente de tránsito" cuando es <font color="#FFFF0000">FFFF0000</font>
  - "Obstrucciones en la vía" cuando es <font color="#FFFF00FF">FFFF00FF</font>
  - "Problema Infraestructura de control de tránsito" cuando es <font color="#FFFF6600">FFFF6600</font>
  - "Condición de tráfico" cuando es <font color="#FFFFC000">FFFFC000</font>
  - "Congestión" cuando es <font color="#FFFFFF00">FFFFFF00</font>
  - "Otros" cuando es <font color="#FF00B050">FF00B050</font>
- Se elimina la columna "color"
- Cuando "Hora" es nulo, toma el valor de la fila anterior
- "coord" se separa en "lat" y "lng", separado por ",\\s*" y se convierten en numéricos
- Se eliminan las filas en las que "lat" es nulo
- "Hora" se convirtió en la concatenación de "fecha" y "hora" y se convierte en POSIXct con el formato "%Y-%m-%d %H:%M"

## Med velo CHIGUAYANTE.xlsx

```{r getData4, eval=FALSE, include=FALSE}
# Med velo CHIGUAYANTE.xlsx
date <- "2024-06-25"
file.path <- "data/Med velo CHIGUAYANTE.xlsx"
directions <- file.path %>% excel_sheets()
chiguayante.speed <- list()
for(sheet in directions) {
  df <- file.path %>% read_excel(sheet = sheet)
  df$dirección <- sheet
  df$`Lugar (dirección)` <- df$`Lugar (dirección)`[!(df$`Lugar (dirección)` %>% is.na())] %>% paste(collapse = ", ")
  chiguayante.speed[[sheet]] <- df
}
chiguayante.speed.df <- chiguayante.speed %>% bind_rows()
chiguayante.speed.df <- chiguayante.speed.df %>% select(-c(...5, ...6, ...7, ...8, ...9, ...10, ...11, ...12, ...13))
chiguayante.speed.df <- chiguayante.speed.df[!(chiguayante.speed.df$`Velocidad [km/hr]` %>% is.na()),]
chiguayante.speed.df <- chiguayante.speed.df %>% fill(Hora, .direction = "down")
chiguayante.speed.df$Hora <- paste(date, chiguayante.speed.df$Hora %>% as.POSIXct() %>% format(., "%H:%M:%S")) %>% as.POSIXct(format = "%Y-%m-%d %H:%M:%S")
chiguayante.speed.df$Comentario[chiguayante.speed.df$Comentario %in% c(
  "auto, doblo a Lo Plaza",
  "Auto, doblo a Lo Plaza",
  "Auto, gira a Lo Plaza"
)] <- "Auto, dobló a Lo Plaza"
chiguayante.speed.df$Comentario[chiguayante.speed.df$Comentario %in% c(
  "camion",
  "Camion"
)] <- "Camión"
chiguayante.speed.df$Comentario[chiguayante.speed.df$Comentario %in% c(
  "micro",
  "Micro"
)] <- "Micro"
chiguayante.speed.df$Comentario <- chiguayante.speed.df$Comentario %>% as.factor()
chiguayante.speed.df$dirección <- chiguayante.speed.df$dirección %>% as.factor()
chiguayante.speed.df$`Lugar (dirección)` <- chiguayante.speed.df$`Lugar (dirección)` %>% as.factor()
chiguayante.speed.df$Vehículo <- "Auto"
chiguayante.speed.df$Vehículo[chiguayante.speed.df$Comentario %in% c("Camión", "Micro", "MOTO", "retroexcavadora")] <- chiguayante.speed.df$Comentario[chiguayante.speed.df$Comentario %in% c("Camión", "Micro", "MOTO", "retroexcavadora")] %>% as.character()
chiguayante.speed.df$Vehículo <- chiguayante.speed.df$Vehículo %>% as.factor()
chiguayante.speed.df %>% summary()
```

El dataset contiene 338 mediciones de velocidad vehicular capturadas en el paradero "Bdo O'Higgins - Arauco" de Chiguayante, monitoreando el flujo entre Concepción y Hualqui.

### Contexto Operacional

- **Ubicación**: Paradero "Bdo O'Higgins - Arauco", Chiguayante
- **Corredor vial**: Concepción - Hualqui
- **Período de medición**: 26 de junio de 2024 entre las 09:06 y las 17:58 horas
- **Duración**: Aproximadamente 9 horas de monitoreo continuo

### Granularidad Temporal

```{r chiguayante.speed.df.time, echo=FALSE, warning=FALSE}
chiguayante.speed.df.sorted <- chiguayante.speed.df[chiguayante.speed.df$Hora %>% order(),]
differences <- chiguayante.speed.df.sorted %>%
  mutate(
    prev_time = Hora %>% lag(),
    same_dir = (dirección == (dirección %>% lag(default = dirección %>% first() - 1)))
  ) %>%
  mutate(
    diff = if_else(same_dir, (Hora - prev_time) %>% as.numeric(), NA_real_)
  ) %>%
  pull(diff)
#differences %>% summary()
chiguayante.speed.df %>% ggplot() +
  geom_density(aes(x = Hora, colour = dirección))
```

### Análisis de Velocidades

- **Rango de velocidades**: 3 a 71 km/h
- **Velocidad promedio**: 44.27 km/h
- **Velocidad mediana**: 43 km/h
- **Distribución**: Relativamente simétrica alrededor de la mediana

```{r chiguayante.speed.df.speed, echo=FALSE, warning=FALSE}
chiguayante.speed.df %>% ggplot() +
  stat_density2d_filled(aes(y = `Velocidad [km/hr]`, x = Hora))
```

### Composición Vehicular

**Tipos de vehículos identificados**:

- **Automóviles**: 273 registros
- **Microbuses**: 52 registros
- **Camiones**: 9 registros
- **Motos**: 3 registros
- **Retroexcavadora**: 1 registro

```{r chiguayante.speed.df.vehicles, echo=FALSE, warning=FALSE}
chiguayante.speed.df %>% ggplot() +
  geom_bar(aes(y = Vehículo %>% fct_infreq() %>% fct_rev(), fill = dirección %>% fct_infreq())) +
  labs(y = "Vehículo", fill = "dirección")
```

### Patrones de Movimiento

**Distribución direccional**:

- **Hacia Concepción**: 163 mediciones
- **Hacia Hualqui**: 175 mediciones
- **Balance**: Ligero predominio del flujo hacia Hualqui

```{r chiguayante.speed.df.direction, echo=FALSE, warning=FALSE}
chiguayante.speed.df %>% ggplot() +
  geom_bar(aes(y = dirección %>% fct_infreq() %>% fct_rev())) +
  labs(y = "dirección")
```

### Comportamientos Específicos

**Maniobras documentadas**:

- "Auto, dobló a Lo Plaza": 8 casos
- "Auto, iba a doblar a Lo Plaza": 1 caso
- "auto, se percibe cola": 1 caso

```{r chiguayante.speed.df.comment, echo=FALSE, warning=FALSE}
chiguayante.speed.df[chiguayante.speed.df$Vehículo == "Auto" & !(chiguayante.speed.df$Comentario %>% is.na()),] %>% ggplot() +
  geom_bar(aes(y = Comentario %>% fct_infreq() %>% fct_rev())) +
  labs(y = "Comentario")
```

### Procesamiento y Normalización de Datos

**Paso a paso**

- Se lee la hoja
- Se crea la columna "dirección" con el nombre de la hoja
- La columna "Lugar (dirección)" se unen en un único valor que se arrastra hacia todas las filas de la hoja
- Se unen los datasets
- Se eliminan las columnas "...5", "...6", "...7", "...8", "...9", "...10", "...11", "...12" y "...13"
- Se eliminan las filas en las que "Velocidad [km/hr]" es nulo
- Las filas donde "Hora" es nulo toman el valor de la fila anterior
- La columna "Hora" se convierte en la concatenación entre "2024-06-25" y "Hora" y se convierte en un POSIXct con formato "%Y-%m-%d %H:%M:%S"
- En la columna "Comentario", los valores "auto, doblo a Lo Plaza", "Auto, doblo a Lo Plaza" y "Auto, gira a Lo Plaza" se unifican como "Auto, dobló a Lo Plaza", los valores "camion" y "Camion", como "Camión" y "micro" y "Micro", como "Micro"
- "Comentario" se convierte en factor
- "dirección" se convierte en factor
- "Lugar (dirección)" se convierte en factor
- Se crea la columna "Vehículo" que toma el valor de la columna "Comentario" si su valor es "Camión", "Micro", "MOTO" o "retroexcavadora" y "Auto" en otro caso
- "Vehículo" se convierte en factor

## Med velo LA VEGA.xlsx

```{r getData5, eval=FALSE, include=FALSE}
#Med velo LA VEGA.xlsx
date <- "2024-06-25"
file.path <- "data/Med velo LA VEGA.xlsx"
sheets <- excel_sheets(file.path)
directions <- sheets[grepl("21", sheets) & grepl("mayo", sheets)]
vega.speed <- list()
for(sheet in directions) {
  df <- file.path %>% openxlsx::read.xlsx(sheet = sheet, colNames = T, fillMergedCells = T, detectDates = T, skipEmptyCols = F, skipEmptyRows = F)
  df <- df[, 2:5]
  df$Hora[!(df$Hora %>% is.na()) & df$Hora %>% as.numeric() > 1 & !((!(df$Hora %>% is.na()) & df$Hora %>% as.numeric() %>% is.numeric() & df$Hora %>% as.numeric() > 1) %>% is.na())] <- ((df$Hora[!(df$Hora %>% is.na()) & df$Hora %>% as.numeric() > 1 & !((!(df$Hora %>% is.na()) & df$Hora %>% as.numeric() %>% is.numeric() & df$Hora %>% as.numeric() > 1) %>% is.na())] %>% as.numeric() %>% round(digits = 2)) / 24) %>% as.character()
  df <- df %>% fill(Hora, .direction = "down")
  hour <- ((df$Hora %>% as.numeric()) * 24) %>% floor()
  minute <- (((df$Hora %>% as.numeric()) * 24 - hour) * 60) %>% floor()
  df$Hora <- sprintf("%02d:%02d:00", hour, minute)
  df$Hora <- paste(date, df$Hora) %>% as.POSIXct(format = "%Y-%m-%d %H:%M:%S")
  df$dirección <- sheet
  df$`Lugar.(dirección)` <- df$`Lugar.(dirección)`[!(df$`Lugar.(dirección)` %>% is.na())] %>% paste(collapse = ", ")
  vega.speed[[sheet]] <- df
}
vega.speed.df <- vega.speed %>% bind_rows()
vega.speed.df <- vega.speed.df[!(vega.speed.df$`Velocidad.[km/hr]` %>% is.na()),]
vega.speed.df$Comentario[vega.speed.df$Comentario %in% c(
  "cola por funeral",
  "forman cola"
)] <- "Forman cola"
vega.speed.df$Comentario[vega.speed.df$Comentario %in% c(
  "llega a cola",
  "llegan a cola",
  "llegan a cola, aprox 4 vehiculos",
  "llegan a cola formada antes de medir"
)] <- "Llega a cola"
vega.speed.df$Comentario[vega.speed.df$Comentario %in% c(
  "llegan juntos",
  "llegan juntos ",
  "llegan juntos, cola aprox 8 a 10 autos",
  "llegan juntos, generan cola"
)] <- "Llegan juntos"
vega.speed.df$Comentario[vega.speed.df$Comentario %in% c(
  "micro",
  "Micro"
)] <- "Micro"
vega.speed.df$Comentario[vega.speed.df$Comentario %in% c(
  "moto",
  "Moto"
)] <- "Moto"
vega.speed.df$Comentario <- vega.speed.df$Comentario %>% as.factor()
vega.speed.df$`Lugar.(dirección)` <- vega.speed.df$`Lugar.(dirección)` %>% as.factor()
vega.speed.df$dirección <- vega.speed.df$dirección %>% as.factor()
vega.speed.df %>% summary()
```

El dataset contiene 432 mediciones de velocidad vehicular capturadas en el cruce de Briceños con Miraflores, monitoreando el flujo entre 21 de Mayo y Avenida Costanera a través del sector Miraflores.

### Contexto Operacional

- **Ubicación**: Esquina Briceños con Miraflores, La Vega
- **Corredores viales**:
    - 21 de Mayo -> Briceños -> Miraflores
    - Av. Costanera -> Miraflores -> 21 de Mayo
- **Período de medición**: 25 de junio de 2024 entre las 08:08 y las 17:58 horas
- **Duración**: Aproximadamente 10 horas de monitoreo continuo

### Granularidad Temporal

```{r vega.speed.df.time, echo=FALSE, warning=FALSE}
vega.speed.df.sorted <- vega.speed.df[vega.speed.df$Hora %>% order(),]
differences <- vega.speed.df.sorted %>%
  mutate(
    prev_time = Hora %>% lag(),
    same_dir = (dirección == (dirección %>% lag(default = dirección %>% first() - 1)))
  ) %>%
  mutate(
    diff = if_else(same_dir, (Hora - prev_time) %>% as.numeric(), NA_real_)
  ) %>%
  pull(diff)
#differences %>% summary()
vega.speed.df %>% ggplot() +
  geom_density(aes(x = Hora, colour = dirección))
```

### Análisis de Velocidades

- **Rango de velocidades**: 5 a 53 km/h
- **Velocidad promedio**: 28.87 km/h
- **Velocidad mediana**: 29 km/h
- **Distribución**: Concentrada en velocidades bajas-medias, típicas de tráfico urbano congestionado

```{r vega.speed.df.speed, echo=FALSE, warning=FALSE}
vega.speed.df %>% ggplot() +
  stat_density2d_filled(aes(y = `Velocidad.[km/hr]`, x = Hora))
```

### Patrones de Movimiento

**Distribución direccional**:

- **Desde 21 de Mayo**: 250 mediciones
- **Hacia 21 de Mayo**: 182 mediciones
- **Balance**: Predominio del flujo desde 21 de Mayo

```{r vega.speed.df.direction, echo=FALSE, warning=FALSE}
vega.speed.df %>% ggplot() +
  geom_bar(aes(y = dirección %>% fct_infreq() %>% fct_rev())) +
  labs(y = "dirección")
```

### Fenómenos de Congestión Documentados

**Patrones de formación de colas**:

- "Llegan juntos": 49 casos - agrupamiento vehicular sincronizado
- "Llega a cola": 22 casos - incorporación a colas existentes
- "Forman cola": 14 casos - generación de nuevas colas

**Composición vehicular adicional**:

- **Microbuses**: Registros específicamente identificados
- **Motocicletas**: Registros categorizados separadamente

### Procesamiento y Normalización de Datos

**Paso a paso**

- Se lee la hoja
- En la columna "Hora", se cambian las "," por ":" (ej: "8,15" -> "8:15")
- Las filas donde "Hora" es nulo toman el valor de la fila anterior
- La columna "Hora" se convierte en la concatenación entre "2024-06-25" y "Hora" y se convierte en un POSIXct con formato "%Y-%m-%d %H:%M:%S"
- Se crea la columna "dirección" con el nombre de la hoja
- La columna "Lugar (dirección)" se unen en un único valor que se arrastra hacia todas las filas de la hoja
- Se unen los datasets
- Se eliminan las filas en las que "Velocidad.[km/hr]" es nulo
- En la columna "Comentario", los valores "llega a cola", "llegan a cola", "llegan a cola, aprox 4 vehiculos" y "llegan a cola formada antes de medir" se unifican como "Llega a cola", los valores "llegan juntos", "llegan juntos ", "llegan juntos, cola aprox 8 a 10 autos" y "llegan juntos, generan cola", como "Llegan juntos", los valores "micro" y "Micro", como "Micro" y los valores "moto" y "Moto", como "Moto"
- "Comentario" se convierte en factor
- "Lugar (dirección)" se convierte en factor
- "dirección" se convierte en factor

## tb_gps_historial_eventos_202509161626(1).csv

```{r getData6, eval=FALSE, include=FALSE}
# tb_gps_historial_eventos_202509161626(1).csv
gps.events <- read_file("data/tb_gps_historial_eventos_202509161626(1).csv") %>% str_replace_all(., "\";\"", " ") %>% str_replace_all(., ",", ";") %>% str_replace_all(., "\"", "") %>% read.table(text = ., sep = ";", header = T, stringsAsFactors = F)
gps.events <- gps.events %>% select(-c(ubicacion_, velocidad_))
gps.events$fecha_auto <- gps.events$fecha_auto %>% as.POSIXct(format = "%Y-%m-%d %H:%M:%S")
gps.events$fecha_gps_ <- gps.events$fecha_gps_ %>% as.POSIXct(format = "%Y-%m-%d %H:%M:%S")
gps.events$evento_ <- gps.events$evento_ %>% as.factor()
gps.events$direccion_ <- gps.events$direccion_ %>% as.factor()
gps.events %>% nrow()
gps.events %>% summary()
gps.events.sf <- gps.events %>% st_as_sf(
  coords = c("longitud_", "latitud_"),
  crs = 4326
)
gps.events.sf %>% st_write(.,
  "~/GitHub/data-sets-analysis/shapefiles/gps.events.shp",
  driver = "ESRI Shapefile",
  append = F
)
```

El dataset contiene 1000 eventos registrados por sistemas GPS vehiculares, capturando transiciones de estado en una ventana temporal específica.

### Período de Monitoreo

- **Fecha de referencia**: Transición año nuevo 2024-2025
- **Según timestamp del auto**: 1 de enero de 2025, 00:00:06 - 01:06:29 (1 hora, 6 minutos)
- **Según timestamp del GPS**: 31 de diciembre de 2024, 23:59:22 - 1 de enero de 2025, 01:06:49 (1 hora, 7 minutos)
- **Discrepancia temporal**: Diferencia de sincronización entre sistemas de aproximadamente 1 minuto

### Granularidad Temporal

```{r gps.events.time, echo=FALSE, warning=FALSE}
gps.events.odd <- gps.events[1:(gps.events %>% nrow()) %% 2 == 1,]
differences <- (gps.events.odd$fecha_auto - c(NA, gps.events.odd$fecha_auto[1:(gps.events.odd %>% nrow() - 1)])) %>% as.numeric()
differences %>% summary()
ggplot() +
  geom_histogram(aes(x = differences, fill = gps.events.odd$evento_ %>% fct_infreq())) +
  labs(x = "differences", fill = "evento_")
```

### Distribución de Estados Vehiculares

**Tipos de eventos registrados**:

- **Apagado**: 552 eventos - vehículo sin operación
- **Detenido**: 264 eventos - vehículo inmovilizado pero encendido
- **Movimiento**: 184 eventos - vehículo en desplazamiento

### Patrones de Direccionalidad

**Valores de dirección registrados**:

- `0`: 316 casos
- `-280`: 184 casos
- `-223`: 184 casos
- `-85`: 184 casos
- `235`: 132 casos

```{r gps.events.event, echo=FALSE, warning=FALSE}
gps.events %>% ggplot() +
  geom_bar(aes(y = evento_ %>% fct_infreq() %>% fct_rev(), fill = direccion_ %>% fct_infreq())) +
  labs(y = "evento_", fill = "direccion_")
```

**Observación**: Los valores negativos y positivos sugieren un sistema de coordenadas o ángulos específico.

### Aspectos Requieren Investigación

**Variables Críticas por Clarificar**

- `id_evento`: Valor constante `2` en todos los registros
- `direccion_`:
    - Sistema de representación angular (grados) o coordenadas relativas
    - Significado de valores negativos vs. positivos
    - Relación con puntos cardinales o sistema de referencia

### Procesamiento y Normalización de Datos

**Paso a paso**

- Se eliminan las columnas "ubicacion_" y "velocidad_" debido a que todos sus valores son nulos
- "fecha_auto" se convierte en un POSIXct con formato "%Y-%m-%d %H:%M:%S"
- "fecha_gps_" se convierte en un POSIXct con formato "%Y-%m-%d %H:%M:%S"
- "evento_" se convierte en factor
- "direccion_" se convierte en factor

## Inventario CCTV Biobío(1).xlsx

```{r getData8, eval=FALSE, include=FALSE}
# Inventario CCTV Biobío(1).xlsx
biobio.inventary <- read_excel("data/Inventario CCTV Biobío(1).xlsx", 
    range = "A2:Q73", na = "----")
colnames(biobio.inventary) <- ifelse(
  grepl("\\...", biobio.inventary %>% colnames()),
  paste((biobio.inventary %>% colnames() %>% str_split_fixed("\\...", n = 2) %>% as.matrix() %>% {.[. == ""] <- NA; .})[, 1], ifelse((biobio.inventary %>% colnames() %>% str_split_fixed("\\...", n = 2) %>% as.matrix() %>% {.[. == ""] <- NA; .})[, 2] %>% as.numeric() <= 11, "DE LA CÁMARA", "DEL CODIFICADOR DE VIDEO")),
  biobio.inventary %>% colnames()
)
biobio.inventary$COMUNA <- biobio.inventary$COMUNA %>% as.factor()
biobio.inventary$ESTADO <- biobio.inventary$ESTADO %>% as.factor()
biobio.inventary$`TIPO DE ENLACE` <- biobio.inventary$`TIPO DE ENLACE` %>% as.factor()
biobio.inventary$PROVEEDOR <- biobio.inventary$PROVEEDOR %>% as.factor()
biobio.inventary$`MARCA DE LA CÁMARA` <- biobio.inventary$`MARCA DE LA CÁMARA` %>% as.factor()
biobio.inventary$`MODELO DE LA CÁMARA` <- biobio.inventary$`MODELO DE LA CÁMARA` %>% as.factor()
biobio.inventary$`MARCA DEL CODIFICADOR DE VIDEO` <- biobio.inventary$`MARCA DEL CODIFICADOR DE VIDEO` %>% as.factor()
biobio.inventary$`MODELO DEL CODIFICADOR DE VIDEO` <- biobio.inventary$`MODELO DEL CODIFICADOR DE VIDEO` %>% as.factor()
biobio.inventary$REGIÓN <- biobio.inventary$REGIÓN %>% as.factor()
biobio.inventary %>% summary()
biobio.inventary.sf <- biobio.inventary %>% st_as_sf(
  coords = c("LONGITUD", "LATITUD"),
  crs = 4326
)
biobio.inventary.sf %>% st_write(.,
  "~/GitHub/data-sets-analysis/shapefiles/biobio.inventary.shp",
  driver = "ESRI Shapefile",
  append = F
)
```

El inventario documenta 71 ubicaciones de cámaras de vigilancia y sus respectivos sistemas de codificación de video desplegados en la Región del Biobío, representando la infraestructura de monitoreo vial regional.

### Distribución Geográfica

- **Comunas con mayor cobertura**:
    - **Concepción**: 31 cámaras
    - **San Pedro de la Paz**: 16 cámaras
    - **Los Ángeles**: 10 cámaras
- **Cobertura regional**: Múltiples comunas del Biobío con sistemas CCTV

### Estado Operacional del Sistema

- **Cámaras online**: 32 unidades
- **Cámaras offline**: 39 unidades
- **Disponibilidad general**: Sistema operando con 45% de disponibilidad inmediata

```{r biobio.inventary.cities, echo=FALSE, warning=FALSE}
biobio.inventary %>% ggplot() +
  geom_bar(aes(y = COMUNA %>% fct_infreq() %>% fct_rev(), fill = ESTADO %>% fct_infreq())) +
  labs(y = "COMUNA", fill = "ESTADO")
```

### Características Técnicas de la Infraestructura

**Conectividad y Proveedores**

- **Tipo de enlace**: 100% digital (71/71 cámaras)
- **Proveedor de servicios**: Exclusivamente "Red Comunicaciones Propia" (71/71)

**Especificaciones de Cámaras**

*Marcas predominantes*:

- Pelco: 38 cámaras
- Avigilon: 10 cámaras
- Axis: 10 cámaras

*Modelos más frecuentes*:

- Pelco Esprit: 27 unidades
- Avigilon 2.0C-H5A-RGDPTZ-DP36: 10 unidades
- Axis AXIS Q8685-E: 10 unidades

```{r biobio.inventary.cameras, echo=FALSE, warning=FALSE}
biobio.inventary %>% ggplot() +
  geom_bar(aes(y = `MODELO DE LA CÁMARA` %>% fct_infreq() %>% fct_rev(), fill = `MARCA DE LA CÁMARA` %>% fct_infreq())) +
  labs(y = "MODELO DE LA CÁMARA", fill = "MARCA DE LA CÁMARA" %>% str_wrap(width = 10))
```

**Sistema de Codificación de Video**

*Codificadores identificados*:

- Axis AXIS Q7401: 26 unidades
- Sin especificar: 45 unidades - posiblemente integrados en cámaras o no documentados

```{r biobio.inventary.video, echo=FALSE, warning=FALSE}
biobio.inventary %>% ggplot() +
  geom_bar(aes(y = `MODELO DEL CODIFICADOR DE VIDEO` %>% fct_infreq() %>% fct_rev(), fill = `MARCA DEL CODIFICADOR DE VIDEO` %>% fct_infreq())) +
  labs(y = "MODELO DEL CODIFICADOR DE VIDEO", fill = "MARCA DEL CODIFICADOR DE VIDEO" %>% str_wrap(width = 10))
```

### Evolución Temporal del Sistema

- **Rango de integración**: 1 de noviembre de 2003 - 1 de septiembre de 2024
- **Vida útil del sistema**: Más de 20 años de despliegue progresivo
- **Actualizaciones recientes**: Integraciones hasta septiembre 2024

```{r biobio.inventary.integration, echo=FALSE, warning=FALSE}
biobio.inventary %>% ggplot() +
  geom_density(aes(x = `FECHA INTEGRACION`, colour = COMUNA))
```

### Procesamiento y Normalización de Datos

**Paso a paso**

- Las columnas "MARCA", "MODELO" y "NÚMERO DE SERIE" estaban duplicadas, por lo que se les agregó "DE LA CÁMARA" y "DEL CODIFICADOR DE VIDEO" para distinguirlos
- "COMUNA" se convierte en factor
- "ESTADO" se convierte en factor
- "TIPO DE ENLACE" se convierte en factor
- "PROVEEDOR" se convierte en factor
- "MARCA DE LA CÁMARA" se convierte en factor
- "MODELO DE LA CÁMARA" se convierte en factor
- "MARCA DEL CODIFICADOR DE VIDEO" se convierte en factor
- "MODELO DEL CODIFICADOR DE VIDEO" se convierte en factor
- "REGIÓN" se convierte en factor

## Alertas de Tráfico.csv

```{r getData7, eval=FALSE, include=FALSE}
# Alertas de Tráfico.csv
trafic.alerts <- read_csv("data/Alertas de Tráfico.csv")
trafic.alerts <- trafic.alerts %>% mutate(
  lng = str_extract(Location, "(?<=Point\\()-?\\d+\\.?\\d*") %>% as.numeric(),
  lat = str_extract(Location, "-?\\d+\\.?\\d*(?=\\)$)") %>% as.numeric()
)
trafic.alerts <- trafic.alerts %>% select(-Location)
trafic.alerts$Date <- trafic.alerts$Date %>% str_replace_all(., setNames(
  c("jan", "feb", "mar", "apr", "may", "jun", "jul", "aug", "sep", "oct", "nov", "dec"),
  c("ene", "feb", "mar", "abr", "may", "jun", "jul", "ago", "sep", "oct", "nov", "dic")
)) %>% dmy()
trafic.alerts$Country <- trafic.alerts$Country %>% as.factor()
trafic.alerts$City <- trafic.alerts$City %>% as.factor()
trafic.alerts$Type <- trafic.alerts$Type %>% as.factor()
trafic.alerts$Subtype <- trafic.alerts$Subtype %>% as.factor()
trafic.alerts %>% summary()
trafic.alerts.sf <- trafic.alerts %>% st_as_sf(
  coords = c("lng", "lat"),
  crs = 4326
)
trafic.alerts.sf %>% st_write(.,
  "~/GitHub/data-sets-analysis/shapefiles/trafic.alerts.shp",
  driver = "ESRI Shapefile",
  append = F
)
```

El dataset comprende 281759 alertas de tráfico generadas por usuarios de Waze, representando un año completo de reportes ciudadanos sobre condiciones viales en el Gran Concepción.

### Período de Análisis

- **Cobertura temporal**: 23 de junio de 2023 - 15 de mayo de 2024
- **Duración**: 327 de datos continuos
- **Registros diarios promedio**: 861.65 alertas por día

### Granularidad Temporal

```{r trafic.alerts.time, echo=FALSE, warning=FALSE}
trafic.alerts %>% ggplot() +
  geom_histogram(aes(x = Date, fill = City)) +
  scale_fill_discrete(labels = label_wrap_gen(width = 15))
```

### Contexto Geográfico

- **Distribución por ciudad**:
    - Concepción: 130747 alertas
    - San Pedro de la Paz: 51816 alertas
    - Talcahuano: 35122 alertas
    - Otras comunas: 64074 alertas

```{r trafic.alerts.cities, echo=FALSE, warning=FALSE}
trafic.alerts %>% ggplot() +
  geom_bar(aes(y = City %>% fct_infreq() %>% fct_rev())) +
  labs(y = "City") +
  scale_x_log10()
```

### Clasificación de Alertas

**Categorías Principales (Type)**

- **Embottellamiento (JAM)**: 178785 casos
- **Peligro (HAZARD)**: 53457 casos
- **Peligro meteorológico (WEATHERHAZARD)**: 35984 casos
- **Otras categorías**: 13533 casos

**Especificaciones por Subcategoría (Subtype)**

*Embottellamientos (JAM)*:

- Tráfico intenso (JAM_HEAVY_TRAFFIC): 77179 casos
- Tráfico paralizado (JAM_STAND_STILL_TRAFFIC): 52298 casos
- Tráfico moderado (JAM_MODERATE_TRAFFIC): 20947 casos

*Peligros (HAZARD)*:

- Vehículo detenido en franja lateral (HAZARD_ON_SHOULDER_CAR_STOPPED): 15869 casos
- Construcción en la vía (HAZARD_ON_ROAD_CONSTRUCTION): 9458 casos
- Peligro en la vía (HAZARD_ON_ROAD): 7494 casos
- Otros peligros: 20636 casos

*Peligros meteorológicos (WEATHERHAZARD)*:

- Vehículo detenido (HAZARD_ON_ROAD_CAR_STOPPED): 9467 casos
- Construcción en la vía (HAZARD_ON_ROAD_CONSTRUCTION): 6287 casos
- Vehículo detenido en franja lateral (HAZARD_ON_SHOULDER_CAR_STOPPED): 6097 casos
- Otros peligros meteorológicos: 14133 casos

```{r trafic.alerts.types, echo=FALSE, warning=FALSE}
trafic.alerts[trafic.alerts$Subtype %in% (trafic.alerts %>%
  count(Subtype) %>%
  slice_max(n, n = 10) %>%
  pull(Subtype)),] %>% ggplot() +
  geom_bar(aes(y = Subtype %>% fct_infreq() %>% fct_rev(), fill = Type %>% fct_infreq())) +
  labs(y = "Subtype", fill = "Type")
```

### Procesamiento y Normalización de Datos

**Paso a paso**

- La columna "Location" se separa en "lng" y "lat" mediante los regex `"(?<=Point\\()-?\\d+\\.?\\d*"` y `"-?\\d+\\.?\\d*(?=\\)$)"`, respectivamente
- Se elimina la columna "Location"
- En la columna "Date", se reemplazan los valores "ene", "feb", "mar", "abr", "may", "jun", "jul", "ago", "sep", "oct", "nov" y "dic" por "jan", "feb", "mar", "apr", "may", "jun", "jul", "aug", "sep", "oct", "nov" y "dec", respectivamente
- "Country" se convierte en factor
- "City" se convierte en factor
- "Type" se convierte en factor
- "Subtype" se convierte en factor

## Copia de Accidentes.csv

```{r getData9, eval=FALSE, include=FALSE}
# Copia de Accidentes.csv
accidents <- read_csv("data/Copia de Accidentes.csv")
accidents <- accidents %>% mutate(
  lng = str_extract(Location, "(?<=Point\\()-?\\d+\\.?\\d*") %>% as.numeric(),
  lat = str_extract(Location, "-?\\d+\\.?\\d*(?=\\)$)") %>% as.numeric()
)
accidents <- accidents %>% select(-Location)
accidents$Date <- accidents$Date %>% str_replace_all(., setNames(
  c("jan", "feb", "mar", "apr", "may", "jun", "jul", "aug", "sep", "oct", "nov", "dec"),
  c("ene", "feb", "mar", "abr", "may", "jun", "jul", "ago", "sep", "oct", "nov", "dic")
)) %>% dmy()
accidents$Country <- accidents$Country %>% as.factor()
accidents$City <- accidents$City %>% as.factor()
accidents %>% summary()
accidents.sf <- accidents %>% st_as_sf(
  coords = c("lng", "lat"),
  crs = 4326
)
accidents.sf %>% st_write(.,
  "~/GitHub/data-sets-analysis/shapefiles/accidents.shp",
  driver = "ESRI Shapefile",
  append = F
)
```

El dataset contiene 281981 registros de accidentes de tránsito, proporcionando una visión detallada de la siniestralidad vial en el Gran Concepción durante un período de 11 meses.

### Período de Monitoreo

- **Cobertura temporal**: 23 de junio de 2023 - 15 de mayo de 2024
- **Duración**: 327 días de reportes continuos
- **Densidad de datos**: ~862.33 accidentes reportados por día en promedio

### Granularidad Temporal

```{r accidents.time, echo=FALSE, warning=FALSE}
accidents %>% ggplot() +
  geom_histogram(aes(x = Date, fill = City)) +
  scale_fill_discrete(labels = label_wrap_gen(width = 15))
```

### Contexto Geográfico

- **Distribución por ciudad**:
    - Concepción: 130516 alertas
    - San Pedro de la Paz: 51704 alertas
    - Talcahuano: 35059 alertas
    - Otras comunas: 64702 alertas

```{r accidents.cities, echo=FALSE, warning=FALSE}
accidents %>% ggplot() +
  geom_bar(aes(y = City %>% fct_infreq() %>% fct_rev())) +
  labs(y = "City") +
  scale_x_log10()
```

### Métricas de Confiabilidad

- **Rango de fiabilidad**: 5 a 10 puntos (escala no especificada)
- **Fiabilidad promedio**: 5.82 puntos
- **Fiabilidad mediana**: 5 puntos
- **Distribución**: Sesgada hacia valores bajos-medios de la escala

```{r accidents.reliability, echo=FALSE, warning=FALSE}
accidents %>% ggplot() +
  geom_histogram(aes(x = `Avg Reliability`, fill = City)) +
  scale_y_log10() +
  scale_fill_discrete(labels = label_wrap_gen(width = 15))
```

### Procesamiento y Normalización de Datos

**Paso a paso**

- La columna "Location" se separa en "lng" y "lat" mediante los regex `"(?<=Point\\()-?\\d+\\.?\\d*"` y `"-?\\d+\\.?\\d*(?=\\)$)"`, respectivamente
- Se elimina la columna "Location"
- En la columna "Date", se reemplazan los valores "ene", "feb", "mar", "abr", "may", "jun", "jul", "ago", "sep", "oct", "nov" y "dic" por "jan", "feb", "mar", "apr", "may", "jun", "jul", "aug", "sep", "oct", "nov" y "dec", respectivamente
- "Country" se convierte en factor
- "City" se convierte en factor

## Waze for Cities Data Key Alerts Dashboard_Traffic Irregularities_Tabla(1).csv

```{r getData10, eval=FALSE, include=FALSE}
# Waze for Cities Data Key Alerts Dashboard_Traffic Irregularities_Tabla(1).csv
waze.data <- read_csv("data/Waze for Cities Data Key Alerts Dashboard_Traffic Irregularities_Tabla(1).csv", 
    na = "null")
waze.data$Day <- waze.data$Day %>% str_replace_all(., setNames(
  c("jan", "feb", "mar", "apr", "may", "jun", "jul", "aug", "sep", "oct", "nov", "dec"),
  c("ene", "feb", "mar", "abr", "may", "jun", "jul", "ago", "sep", "oct", "nov", "dic")
)) %>% dmy()
waze.data$Country <- waze.data$Country %>% as.factor()
waze.data$City <- waze.data$City %>% as.factor()
waze.data$Street <- waze.data$Street %>% as.factor()
waze.data$Cause <- waze.data$Cause %>% as.factor()
waze.data %>% summary()
```

El dataset contiene 13502 registros de irregularidades de tráfico documentadas a través de la plataforma Waze for Cities, proporcionando métricas detalladas sobre el impacto de incidentes viales en la Región del Biobío durante un período de 11 meses.

### Período de Análisis

- **Cobertura temporal**: 23 de junio de 2023 - 15 de mayo de 2024
- **Duración**: 327 días de monitoreo continuo
- **Frecuencia promedio**: 41.29 irregularidades reportadas por día

### Granularidad Temporal

```{r waze.data.time, echo=FALSE, warning=FALSE}
waze.data %>% ggplot() +
  geom_histogram(aes(x = Day, fill = City)) +
  scale_fill_discrete(labels = label_wrap_gen(width = 15))
```

### Distribución Geográfica

- **Concentración por ciudad**:
    - Concepción: 4236 registros
    - Los Ángeles: 3484 registros
    - San Pedro de la Paz: 2190 registros
    - Otras localidades: 3592 registros

```{r waze.data.cities, echo=FALSE, warning=FALSE}
waze.data %>% ggplot() +
  geom_bar(aes(y = City %>% fct_infreq() %>% fct_rev(), fill = Cause %>% fct_infreq())) +
  labs(y = "City", fill = "Cause")
```

### Clasificación por Causas Identificadas

- **Accidentes (ACCIDENT)**: 839 casos
- **Peligros en la vía (HAZARD)**: 826 casos
- **Carreteras cerradas (ROAD_CLOSED)**: 3 casos
- **Causa no especificada**: 11834 casos

```{r waze.data.causes, echo=FALSE, warning=FALSE}
waze.data[!(waze.data$Cause %>% is.na()),] %>% ggplot() +
  geom_bar(aes(y = Cause %>% fct_infreq() %>% fct_rev(), fill = City %>% fct_infreq())) +
  scale_fill_discrete(labels = label_wrap_gen(width = 15)) +
  labs(y = "Cause", fill = "City")
```

### Métricas de Impacto de Tráfico

**Longitud de Afectación Vial**

- **Rango**: 500 m - 16.61 km
- **Longitud promedio**: 1.34 km
- **Mediana**: 947 m
- **Distribución**: Sesgo hacia afectaciones de mediana extensión

```{r waze.data.length, echo=FALSE, warning=FALSE}
waze.data %>% ggplot() +
  geom_density(aes(x = `Avg Length (Meters)`, colour = Cause)) +
  scale_x_log10()
```

**Tiempos de Desfase**

- **Rango**: 1 minuto 7.33 segundos - 6 horas 27 minutos 26 segundos
- **Desfase promedio**: 11 minutos 4.97 segundos
- **Mediana**: 9 minutos 18.25 segundos
- **Significado**: Retrasos significativos en la movilidad urbana

```{r waze.data.delay, echo=FALSE, warning=FALSE}
waze.data %>% ggplot() +
  geom_density(aes(x = `Avg Delay (Seconds)`, colour = Cause)) +
  scale_x_log10()
```

**Impacto en Usuarios**

- **Usuarios afectados (Impacted Wazers)**: 1 - 122563 personas
- **Promedio de afectados**: 2033 usuarios por incidente
- **Mediana**: 465 usuarios
- **Distribución**: Alta variabilidad con eventos masivos ocasionales

```{r waze.data.impacted.wazers, echo=FALSE, warning=FALSE}
waze.data %>% ggplot() +
  geom_density(aes(x = `Impacted Wazers`, colour = Cause)) +
  scale_x_log10()
```

### Procesamiento y Normalización de Datos

**Paso a paso**

- En la columna "Date", se reemplazan los valores "ene", "feb", "mar", "abr", "may", "jun", "jul", "ago", "sep", "oct", "nov" y "dic" por "jan", "feb", "mar", "apr", "may", "jun", "jul", "aug", "sep", "oct", "nov" y "dec", respectivamente
- "Country" se convierte en factor
- "City" se convierte en factor
- "Street" se convierte en factor
- "Cause" se convierte en factor

## Red de Waze

```{r getData11, eval=FALSE, include=FALSE}
json.route <- "data/json"
folders <- json.route %>% list.dirs(recursive = F) %>% basename()
routes.list <- list()
folder.time.list <- list()
subfolder.time.list <- list()
file.time.list <- list()
for(folder in folders){
  folder.start.sys <- Sys.time()
  subfolders <- paste(json.route, folder, sep = "/") %>% list.dirs(recursive = F) %>% basename()
  for(subfolder in subfolders){
    subfolder.start.sys <- Sys.time()
    base.routes <- paste(json.route, folder, subfolder, sep = "/") %>% list.files(full.names = T)
    for(base.route in base.routes){
      file.start.sys <- Sys.time()
      json <- fromJSON(file = base.route)
      routes.data <- json$routes %>% lapply(., function(route) {
        new.row <- route[!names(route) %in% c("line", "bbox", "subRoutes", "leadAlert", "alternateRoute")]
        if(!(route$leadAlert %>% is.null())){
          new.row$leadAlert.numComments <- route$leadAlert$numComments
          new.row$leadAlert.city <- route$leadAlert$city
          new.row$leadAlert.externalImageId <- route$leadAlert$externalImageId
          new.row$leadAlert.numThumbsUp <- route$leadAlert$numThumbsUp
          new.row$leadAlert.street <- route$leadAlert$street
          new.row$leadAlert.subType <- route$leadAlert$subType
          new.row$leadAlert.id <- route$leadAlert$id
          new.row$leadAlert.position <- route$leadAlert$position
          new.row$leadAlert.type <- route$leadAlert$type
          new.row$leadAlert.numNotThereReports <- route$leadAlert$numNotThereReports
        } else {
          new.row$leadAlert.numComments <- NA
          new.row$leadAlert.city <- NA
          new.row$leadAlert.externalImageId <- NA
          new.row$leadAlert.numThumbsUp <- NA
          new.row$leadAlert.street <- NA
          new.row$leadAlert.subType <- NA
          new.row$leadAlert.id <- NA
          new.row$leadAlert.position <- NA
          new.row$leadAlert.type <- NA
          new.row$leadAlert.numNotThereReports <- NA
        }
        if(!(route$bbox %>% is.null())) {
          new.row$minY <- route$bbox$minY
          new.row$minX <- route$bbox$minX
          new.row$maxY <- route$bbox$maxY
          new.row$maxX <- route$bbox$maxX
        } else {
          new.row$minY <- NA
          new.row$minX <- NA
          new.row$maxY <- NA
          new.row$maxX <- NA
        }
        if(!(route$line %>% is.null()) && route$line %>% length() > 0) {
          route$line %>% seq_along() %>% lapply(., function(i) {
            row <- new.row
            row$x <- route$line[[i]]$x
            row$y <- route$line[[i]]$y
            row$point_index <- i
            row$total_points <- route$line %>% length()
            return(row %>% as.data.frame(stringsAsFactors = F))
          })
        } else {
          row <- new.row
          row$x <- NA
          row$y <- NA
          row$point_index <- NA
          row$total_points <- NA
          list(row %>% as.data.frame(stringsAsFactors = F))
        }
      })
      df.routes <- rbind %>% do.call(., routes.data %>% unlist(recursive = F))
      df.routes$speed <- df.routes$length / df.routes$time
      df.routes$broadcasterId <- json$broadcasterId
      df.routes$areaName <- json$areaName
      df.routes$isMetric <- json$isMetric
      df.routes$updateTime <- json$updateTime
      df.routes$date <- gsub("_", "-", folder)
      df.routes$subfolder <- subfolder
      file <- gsub(".json", "", (base.route %>% basename() %>% str_split(pattern = "_"))[[1]][3])
      df.routes$file <- file
      routes.list[[base.route]] <- df.routes
      file.end.sys <- Sys.time()
      file.dt.sys <- file.end.sys - file.start.sys
      file.time.list[[base.route]] <- file.dt.sys
      print("File time:")
      print(base.route %>% basename())
      print(file.dt.sys)
    }
    subfolder.end.sys <- Sys.time()
    subfolder.dt.sys <- subfolder.end.sys - subfolder.start.sys
    subfolder.time.list[[paste(folder, subfolder, sep = "/")]] <- subfolder.dt.sys
    print("Subfolder time:")
    print(subfolder)
    print(subfolder.dt.sys)
  }
  folder.end.sys <- Sys.time()
  folder.dt.sys <- folder.end.sys - folder.start.sys
  folder.time.list[[folder]] <- folder.dt.sys
  print("Folder time:")
  print(folder)
  print(folder.dt.sys)
}
total.dt <- folder.time.list %>% sum.time()
# Reading Time: 4h + 13m + 36.01s
start.sys <- Sys.time()
waze.routes.df <- routes.list %>% bind_rows()
end.sys <- Sys.time()
binding.time <- end.sys - start.sys
# Binding Time: 15.76s
start.sys <- Sys.time()
waze.routes.df$toName <- waze.routes.df$toName %>% as.factor()
waze.routes.df$name <- waze.routes.df$name %>% as.factor()
waze.routes.df$fromName <- waze.routes.df$fromName %>% as.factor()
waze.routes.df$type <- waze.routes.df$type %>% as.factor()
waze.routes.df$leadAlert.city <- waze.routes.df$leadAlert.city %>% as.factor()
waze.routes.df$leadAlert.externalImageId <- waze.routes.df$leadAlert.externalImageId %>% as.factor()
waze.routes.df$leadAlert.street <- waze.routes.df$leadAlert.street %>% as.factor()
waze.routes.df$leadAlert.subType <- waze.routes.df$leadAlert.subType %>% as.factor()
waze.routes.df$leadAlert.id <- waze.routes.df$leadAlert.id %>% as.factor()
lat.lng <- function(n = 1){
  waze.routes.df$leadAlert.position %>% sapply(., function(p){
    if(p %>% is.na()) {
      return(NA)
    }
    str_split(p, " ")[[1]][n] %>% as.numeric()
  })
}
waze.routes.df$leadAlert.position.lat <- lat.lng(1)
waze.routes.df$leadAlert.position.lng <- lat.lng(2)
waze.routes.df <- waze.routes.df %>% select(-leadAlert.position)
waze.routes.df$leadAlert.type <- waze.routes.df$leadAlert.type %>% as.factor()
waze.routes.df$broadcasterId <- waze.routes.df$broadcasterId %>% as.factor()
waze.routes.df$areaName <- waze.routes.df$areaName %>% as.factor()
waze.routes.df$date <- waze.routes.df$date %>% as.POSIXct(format = "%d-%m-%Y")
waze.routes.df$subfolder <- waze.routes.df$subfolder %>% as.factor()
waze.routes.df$file <- waze.routes.df$file %>% as.factor()
waze.routes.df$updateTime <- (waze.routes.df$updateTime / 1000) %>% as.POSIXct(origin = "1970-01-01", tz = "UTC")
waze.routes.df$weekday <- waze.routes.df$updateTime %>% weekdays() %>% as.factor()
end.sys <- Sys.time()
modifying.time <- end.sys - start.sys
# Modifying Time: 4m + 35.99s
waze.routes.df %>% summary()
waze.routes <- waze.routes.df %>% distinct(id, date, file, .keep_all = T) %>% select(-x, -y, -point_index)
waze.routes %>% summary()
waze.routes.df.short <- waze.routes.df %>%
  rename(
    alert_lat = leadAlert.position.lat,
    alert_lng = leadAlert.position.lng,
    alert_city = leadAlert.city,
    alert_img = leadAlert.externalImageId,
    alert_strt = leadAlert.street,
    alert_sub = leadAlert.subType,
    alert_id = leadAlert.id,
    alert_type = leadAlert.type,
    alert_com = leadAlert.numComments,
    alert_thumbs = leadAlert.numThumbsUp,
    alert_notthere = leadAlert.numNotThereReports,
    date_str = date
  )
waze.routes.df.short$date_str <- waze.routes.df.short$date_str %>% as.character()
waze.routes.df.clean <- waze.routes.df.short %>%
  filter(!(x %>% is.na()), !(y %>% is.na()))
waze.routes.df.sf <- waze.routes.df.clean %>% st_as_sf(
  coords = c("x", "y"),
  crs = 4326
)
waze.routes.df.sf %>% st_write(.,
  "~/GitHub/data-sets-analysis/shapefiles/waze.routes.df.shp",
  driver = "ESRI Shapefile",
  append = F,
  delete_dsn = T
)
create.bbox.polygons <- function(df){
  polygons.list <- list()
  for (i in df %>% nrow() %>% seq_len()) {
    minX <- df$minX[i]
    minY <- df$minY[i]
    maxX <- df$maxX[i]
    maxY <- df$maxY[i]
    if (c(minX, minY, maxX, maxY) %>% is.na() %>% any()) {
      next
    }
    polygon.coords <- matrix(c(
      minX, minY,
      minX, maxY,
      maxX, maxY,
      maxX, minY,
      minX, minY
    ), ncol = 2, byrow = TRUE)
    polygon <- polygon.coords %>% list() %>% st_polygon()
    polygons.list[[i]] <- polygon
  }
  valid.rows <- !sapply(polygons.list, is.null)
  df.valid <- df[valid.rows, ]
  df.sf <- df.valid %>% st_sf(geometry = polygons.list[valid.rows] %>% st_sfc(crs = 4326)) %>% select(-minX, -minY, -maxX, -maxY)
  return(df.sf)
}
waze.routes.polygons <- waze.routes %>% create.bbox.polygons() %>%
  rename(
    alert_lat = leadAlert.position.lat,
    alert_lng = leadAlert.position.lng,
    alert_city = leadAlert.city,
    alert_img = leadAlert.externalImageId,
    alert_strt = leadAlert.street,
    alert_sub = leadAlert.subType,
    alert_id = leadAlert.id,
    alert_type = leadAlert.type,
    alert_com = leadAlert.numComments,
    alert_thumbs = leadAlert.numThumbsUp,
    alert_notthere = leadAlert.numNotThereReports,
    date_str = date
  )
waze.routes.polygons %>% st_write(
  dsn = "~/GitHub/data-sets-analysis/shapefiles",
  layer = "waze.routes",
  driver = "ESRI Shapefile",
  append = F,
  delete_dsn = T
)

# Mapa de calor (Velocidad, tramo x hora)
## Datos de Carrera y Pedro Aguirre Cerda
## Martes y miércoles, respectivamente
waze.routes.df %>% summary()
waze.routes.heatmap <- waze.routes.df[
  waze.routes.df$weekday %in% c("martes", "miércoles") &
  (
    grepl("Av. Los Carrera", waze.routes.df$name) |
    grepl("Av. Pedro Aguirre Cerda", waze.routes.df$name)
  ),
]
waze.routes.heatmap$hour <- waze.routes.heatmap$updateTime %>% hour()
waze.routes.heatmap$placeName <- NA
for(n in c(waze.routes.heatmap$toName %>% levels(), waze.routes.heatmap$fromName %>% levels())){
  waze.routes.heatmap$placeName[grepl(n, waze.routes.heatmap$name)] <- n
}
waze.routes.heatmap$placeName <- waze.routes.heatmap$placeName %>% as.factor()
waze.routes.heatmap$dirName <- NA
for(n in c("O.P", "P.O")){
  waze.routes.heatmap$dirName[grepl(n, waze.routes.heatmap$name)] <- n
}
waze.routes.heatmap$dirName <- waze.routes.heatmap$dirName %>% as.factor()
waze.routes.heatmap$placeName %>% summary()

waze.routes.heatmap$name[waze.routes.heatmap$placeName == "Av. Los Carrera" & waze.routes.heatmap$dirName == "O.P"] %>% as.character() %>% as.factor() %>% levels()

waze.routes.heatmap$name.number <- waze.routes.heatmap$name %>% sapply(., function(n) str_split(n, "_")[[1]][1]) %>% as.numeric()

waze.routes.heatmap$name.number %>% summary()

display.heat.map = function(placeName = "Av. Los Carrera", dirName = "O.P", filter = T, title = "") {
  filtered.data <- waze.routes.heatmap[waze.routes.heatmap$placeName == placeName & waze.routes.heatmap$dirName == dirName & filter,]
  name.order <- filtered.data %>%
    select(name, name.number) %>%
    distinct() %>%
    arrange(name.number) %>%
    pull(name)
  plot.data <- filtered.data %>%
    group_by(name, hour, name.number) %>%
    summarise(speed = speed %>% mean(na.rm = T)) %>%
    ungroup() %>%
    mutate(name = name %>% factor(levels = name.order))
  plot.data %>% 
    ggplot() +
    geom_tile(aes(
      x = name,
      y = hour,
      fill = speed
    )) +
    scale_fill_gradientn(
      colors = c(
        "red",
        "orange",
        "yellow",
        "lightgreen",
        "darkgreen"
      )
    ) +
    labs(title = paste("Mapa de calor en", placeName, "en dirección", dirName, title), x = "Tramo", y = "Hora", fill = "Velocidad") +
    theme(axis.text.x = element_text(angle = 270, hjust = 1, vjust = 0.5))
}

for(placeName in waze.routes.heatmap$placeName %>% levels()){
  for(dirName in waze.routes.heatmap$dirName %>% levels()){
    for(weekday in waze.routes.heatmap$weekday %>% as.character() %>% as.factor() %>% levels()){
      display.heat.map(placeName, dirName, waze.routes.heatmap$date >= "2025-12-16" & waze.routes.heatmap$weekday == weekday, paste("durante el día", weekday)) %>% print()
    }
  }
}
```

El sistema procesó 766668 registros de datos de rutas provenientes de la API de Waze, consolidando información de navegación y alertas de tráfico durante un período de 21 días.

### Metadatos de Procesamiento

- **Tiempo de lectura**: 4 horas, 13 minutos, 36.01 segundos
- **Tiempo de unión**: 15.76 segundos
- **Tiempo de transformación**: 4 minutos, 35.99 segundos
- **Total de procesamiento**: 4 horas, 18 minutos, 27.76 segundos

### Período de Monitoreo

- **Fecha inicial**: 24 de noviembre de 2025 a las 15:31:51
- **Fecha final**: 29 de diciembre de 2025 a las 19:46:46
- **Duración**: 35 días, 4 horas, 14 minutos, 55 segundos
- **Estructura temporal**: Datos organizados por fecha en estructura de carpetas

### Granularidad Temporal

- Diferencia Mínima: 1 minuto, 51.2 segundos
- Diferencia máxima: 1 día, 23 horas, 25 minutos, 2.3 segundos
- Diferencia Media: 5 minutos, 33 segundos
- Diferencia Mediana: 5 minutos
- Desviación Standard: 30 minutos, 34.06 segundos

```{r waze.routes.time, echo=FALSE, warning=FALSE}
waze.routes.times <- waze.routes[waze.routes$updateTime %>% order(),] %>% distinct(updateTime)
differences <- (waze.routes.times$updateTime - c(NA, waze.routes.times$updateTime[1:(waze.routes.times %>% nrow() - 1)])) %>% as.numeric()
#differences %>% summary()
ggplot() +
  geom_density(aes(x = differences)) +
  geom_vline(aes(xintercept = differences %>% mean(na.rm = T), colour = "promedio")) +
  geom_vline(aes(xintercept = differences %>% median(na.rm = T), colour = "mediana")) +
  scale_x_log10() +
  scale_color_manual(
    values = c("promedio" = "red", "mediana" = "green"),
    breaks = c("promedio", "mediana")
  )
```

### Características del Dataset Consolidado

**Volumen y Estructura**

- **Registros totales**: 4399211 puntos de ruta
- **Rutas únicas (agrupadas)**: 766668 rutas
- **Nivel de detalle**: Desagregación punto por punto de trayectos

**Análisis de Orígenes y Destinos**

*Principales Destinos* (`toName`)

- "Av. Los Carrera": 492858 referencias
- "Av. Pedro Aguirre Cerda": 109524 referencias
- "Ruta 160": 54762 referencias

```{r waze.routes.toName, echo=FALSE, warning=FALSE}
waze.routes %>% ggplot() +
  geom_bar(aes(y = toName %>% fct_infreq() %>% fct_rev(), fill = total_points %>% as.factor())) +
  labs(y = "toName", fill = "total_points")
```

*Principales Orígenes* (`fromName`)

- "Av. Los Carrera": 511112 referencias
- "Av. Pedro Aguirre Cerda": 118651 referencias
- "Ruta 160": 45635 referencias

```{r waze.routes.fromName, echo=FALSE, warning=FALSE}
waze.routes %>% ggplot() +
  geom_bar(aes(y = fromName %>% fct_infreq() %>% fct_rev(), fill = total_points %>% as.factor())) +
  labs(y = "fromName", fill = "total_points")
```

**Métricas de Desempeño de Rutas**

*Tiempos de Viaje*

- **Tiempo histórico** (`historicTime`): 1-344 unidades (media: 20.74, mediana: 13)
- **Tiempo estimado** (`time`): 0-952 unidades (media: 26.96, mediana: 16)
- **Unidades por confirmar**: Minutos o segundos (requiere validación)

```{r waze.routes.historicTime, echo=FALSE, warning=FALSE}
waze.routes %>% ggplot() +
  geom_density(aes(x = historicTime)) +
  scale_x_log10()
```

*Distancias y Velocidades*
- **Longitud de ruta** (`length`): 0-1257 unidades (media: 175.4, mediana: 126)
- **Velocidad calculada** (`speed`): 0.52-24 unidades (media: 8.06, mediana: 7.89)
- **Relación distancia/tiempo**: Consistente con tráfico urbano congestionado

```{r waze.routes.length, echo=FALSE, warning=FALSE}
waze.routes %>% ggplot() +
  stat_density_2d(
    aes(x = time, y = length, fill = after_stat(level), alpha = after_stat(level)),
    geom = "polygon",
    show.legend = F
  ) +
  scale_x_log10() +
  scale_y_log10()
```

**Sistema de Alertas Waze**

*Distribución de Alertas*

- **Total de alertas registradas**: 301

```{r waze.routes.alerts, echo=FALSE, warning=FALSE}
waze.routes.alerts <- waze.routes[!(waze.routes$leadAlert.id %>% is.na()),]
```

*Tipología de Alertas* (`leadAlert.type`)

**Accidentes (ACCIDENT) - 159 casos**:

- `NO_SUBTYPE`: 146 casos
- `ACCIDENT_MAJOR`: 13 casos

**Peligros (HAZARD) - 134 casos**:

- `HAZARD_ON_ROAD`: 60 casos
- `HAZARD_ON_ROAD_OBJECT`: 32 casos
- `HAZARD_ON_ROAD_TRAFFIC_LIGHT_FAULT`: 22 casos
- `HAZARD_ON_ROAD_CAR_STOPPED`: 10 casos
- `HAZARD_ON_ROAD_CONSTRUCTION`: 6 casos
- `HAZARD_WEATHER_FLOOD`: 4 casos

**Carreteras cerradas (ROAD_CLOSED) - 8 casos**

- `NO_SUBTYPE`: 8 casos

```{r waze.routes.alerts.types, echo=FALSE, warning=FALSE}
waze.routes.alerts %>% ggplot() +
  geom_bar(aes(y = leadAlert.subType %>% fct_infreq() %>% fct_rev(), fill = leadAlert.type %>% fct_infreq())) +
  labs(y = "leadAlert.subType", fill = "leadAlert.type")
```

*Interacción de Usuarios con Alertas*

- **Comentarios** (`numComments`): 0-89 (media: 9.2, mediana: 4)
- **Me gusta** (`numThumbsUp`): 0-46 (media: 7.5, mediana: 3)
- **Reportes de inexistencia** (`numNotThereReports`): 0 (120 casos)  y 1 (89 casos)

```{r waze.routes.alerts.users, echo=FALSE, warning=FALSE}
waze.routes.alerts %>% ggplot() +
  geom_point(aes(x = leadAlert.numComments, y = leadAlert.numThumbsUp, colour = leadAlert.numNotThereReports %>% as.factor())) +
  labs(colour = "leadAlert.numNotThereReports")
```

*Contexto Geográfico de Alertas*

- **Calles más reportadas**:
  - "Ruta 160": 176 alertas
  - "Av. Pedro Aguirre Cerda": 108 alertas
  - "Av. Los Carrera Poniente": 9 alertas
  - "Av. Los Carrera": 8 alertas
- **Ciudades involucradas**:
  - "San Pedro de la Paz": 108 alertas
  - "Concepción": 17 alertas
  - Sin especificar: 176 alertas

```{r waze.routes.alerts.cities, echo=FALSE, warning=FALSE}
waze.routes.alerts %>% ggplot() +
  geom_bar(aes(y = leadAlert.street %>% fct_infreq() %>% fct_rev(), fill = leadAlert.city %>% fct_infreq())) +
  labs(y = "leadAlert.street", fill = "leadAlert.city")
```

### Procesamiento y Normalización de Datos

**Paso a paso**

- Se leen las carpetas
- En cada carpeta, se leen las sub-carpetas
- En cada sub-capreta, se leen los archivos .json
- En cada archivo, se leen las rutas
- Por cada ruta, se crea la fila con todos sus valores, excepto "line", "bbox", "subRoutes", "leadAlert" y "alternateRoute"
- Si "leadAlert" no es nulo, las columnas "leadAlert.numComments", "leadAlert.city", "leadAlert.externalImageId", "leadAlert.numThumbsUp", "leadAlert.street", "leadAlert.subType", "leadAlert.id", "leadAlert.position", "leadAlert.type" y "leadAlert.numNotThereReports" toman los valores de "numComments", "city", "externalImageId", "numThumbsUp", "street", "subType", "id", "position", "type" y "numNotThereReports", respectivamente de "leadAlert"
- Si "bbox" no es nulo, las columnas "minY", "minX", "maxY" y "maxX" toman los valores de "minY", "minX", "maxY" y "maxX" de "bbox", respectivamente
- Si "line" no es nulo, se clona la fila una vez por cada elemento en "line", por cada punto, "x" e "y" toman el valor de "x" e "y", respectivamente del elemento de "line", "point_index", la posición del punto en "line" y "total_points", la cantidad de puntos en "line"
- Se unen las filas en un data.frame
- Se crea la columna "speed" con el valor de "lenght" / "time"
- Se crea la columna "broadcasterId" con el valor de "broadcasterId" del archivo
- Se crea la columna "areaName" con el valor de "areaName" del archivo
- Se crea la columna "isMetric" con el valor de "isMetric" del archivo
- Se crea la columna "updateTime" con el valor de "updateTime" del archivo
- Se crea la columna "date" con el nombre de la carpeta
- Se crea la columna "subfolder" con el nombre de la sub-carpeta
- Se crea la columna "file" con el nombre del archivo quitando la cadena ".json", separándolo en una lista de cadenas con el caracter "_" y tomando en último elemento (ej: "1763409379301_2025-12-01_000004.267298.json" -> "000004.267298")
- Se unen las filas en un solo data.frame
- "toName" se convierte en factor
- "name" se convierte en factor
- "fromName" se convierte en factor
- "type" se convierte en factor
- "leadAlert.city" se convierte en factor
- "leadAlert.externalImageId" se convierte en factor
- "leadAlert.street" se convierte en factor
- "leadAlert.subType" se convierte en factor
- "leadAlert.position" se divide en "leadAlert.position.lat" y "leadAlert.position.lng" separándolo por el caracter " "
- Se elimina la columna "leadAlert.position"
- "leadAlert.type" se convierte en factor
- "broadcasterId" se convierte en factor
- "areaName" se convierte en factor
- "date" se convierte en POSIXct con formato "%d-%m-%Y"
- "subfolder" se convierte en factor
- "file" se convierte en factor
- "updateTime" se divide por 1000 y se convierte en POSIXct con origen en "1970-01-01" y zona horaria "UTC"
- Se crea la columna "weekday" siendo el día de la semana de "updateTime" y se convierte en factor

# Discretización de datos

```{r quantum.data, eval=FALSE, include=FALSE}
meters.per.degree.lat <- 111320

meters.per.degree.lng <- function(lat.d) {
  meters.per.degree.lat * cos(lat.d * pi / 180)
}

calculate.street.heading <- function(lng.data, lat.data) {
  n <- length(lng.data)
  headings <- numeric(n)
  for(i in 2:(n-1)) {
    dx_meters <- (lng.data[i+1] - lng.data[i-1]) * meters.per.degree.lng(lat.data[i])
    dy_meters <- (lat.data[i+1] - lat.data[i-1]) * meters.per.degree.lat
    headings[i] <- atan2(dy_meters, dx_meters)
  }
  headings[1] <- headings[2]
  headings[n] <- headings[n-1]
  
  return(headings)
}

quantum.data <- function(
  time.data = c(),
  lng.data = c(),
  lat.data = c(),
  field.data = c(),
  time.gap = 5,
  space.gap = 50,
  street.aligned = T,
  street.angle.tolerance = 30,
  compile.function = mean
) {
  if (length(unique(c(length(time.data), length(lng.data), length(lat.data), length(field.data)))) != 1) {
    stop("All vectors must have the same length")
  }
  data.df <- data.frame(
    time = time.data,
    lng = lng.data,
    lat = lat.data,
    field = field.data,
    stringsAsFactors = F
  )
  data.df <- data.df[order(data.df$time), ]
  if (street.aligned) {
    data.df$heading <- calculate.street.heading(data.df$lng, data.df$lat)
  }
  if (time.gap > 0) {
    min.time <- min(data.df$time)
    max.time <- max(data.df$time)
    time.bins <- seq(from = min.time, to = max.time, by = time.gap)
    data.df$time.bin <- cut(data.df$time, breaks = time.bins, include.lowest = T, labels = F)
    data.df$time.bin[is.na(data.df$time.bin)] <- max(data.df$time.bin, na.rm = T) + 1
  } else {
    data.df$time.bin <- 1:nrow(data.df)
  }
  if (space.gap > 0) {
    if (street.aligned) {
      lat_meters <- data.df$lat * meters.per.degree.lat
      lng_meters <- data.df$lng * meters.per.degree.lng(data.df$lat)
      data.df$x_along_street <- numeric(nrow(data.df))
      data.df$y_across_street <- numeric(nrow(data.df))
      for(i in 1:nrow(data.df)) {
        angle <- data.df$heading[i]
        rot_matrix <- matrix(c(cos(angle), sin(angle), -sin(angle), cos(angle)), nrow = 2)
        coords <- rot_matrix %*% c(lng_meters[i], lat_meters[i])
        data.df$x_along_street[i] <- coords[1]
        data.df$y_across_street[i] <- coords[2]
      }
      x_range <- range(data.df$x_along_street)
      x_bins <- seq(from = x_range[1], to = x_range[2], by = space.gap)
      data.df$x_bin <- cut(data.df$x_along_street, breaks = x_bins, include.lowest = T, labels = F)
      data.df$x_bin[is.na(data.df$x_bin)] <- max(data.df$x_bin, na.rm = T) + 1
      cross_gap <- space.gap * sin(street.angle.tolerance * pi / 180)
      y_range <- range(data.df$y_across_street)
      y_bins <- seq(from = y_range[1], to = y_range[2], by = cross_gap)
      data.df$y_bin <- cut(data.df$y_across_street, breaks = y_bins, include.lowest = T, labels = F)
      data.df$y_bin[is.na(data.df$y_bin)] <- max(data.df$y_bin, na.rm = T) + 1
      result <- data.df %>% 
        group_by(time.bin, x_bin, y_bin) %>% 
        summarise(
          time = mean(time, na.rm = T),
          lng = mean(lng, na.rm = T),
          lat = mean(lat, na.rm = T),
          field = compile.function(field, na.rm = T),
          n.points = n(),
          mean_heading = mean(heading, na.rm = T),
          .groups = 'drop'
        )
    } else {
      lat.range.meters <- range(data.df$lat) * meters.per.degree.lat
      lng_meters_temp <- data.df$lng * meters.per.degree.lng(mean(data.df$lat))
      lng.range.meters <- range(lng_meters_temp)
      lat.bins.meters <- seq(from = lat.range.meters[1], to = lat.range.meters[2], by = space.gap)
      lng.bins.meters <- seq(from = lng.range.meters[1], to = lng.range.meters[2], by = space.gap)
      lat.bins <- lat.bins.meters / meters.per.degree.lat
      lng.bins <- lng.bins.meters / meters.per.degree.lng(mean(data.df$lat))
      data.df$lat.group <- cut(data.df$lat, breaks = lat.bins, include.lowest = T)
      data.df$lng.group <- cut(data.df$lng, breaks = lng.bins, include.lowest = T)
      data.df$lat.group[is.na(data.df$lat.group)] <- max(as.numeric(data.df$lat.group), na.rm = T) + 1
      data.df$lng.group[is.na(data.df$lng.group)] <- max(as.numeric(data.df$lng.group), na.rm = T) + 1
      result <- data.df %>% 
        group_by(time.bin, lat.group, lng.group) %>% 
        summarise(
          time = mean(time, na.rm = T),
          lng = mean(lng, na.rm = T),
          lat = mean(lat, na.rm = T),
          field = compile.function(field, na.rm = T),
          n.points = n(),
          .groups = 'drop'
        )
    }
  } else {
    data.df$lat.group <- 1:nrow(data.df)
    data.df$lng.group <- 1:nrow(data.df)
    result <- data.df %>% 
      group_by(time.bin, lat.group, lng.group) %>% 
      summarise(
        time = mean(time, na.rm = T),
        lng = mean(lng, na.rm = T),
        lat = mean(lat, na.rm = T),
        field = compile.function(field, na.rm = T),
        n.points = n(),
        .groups = 'drop'
      )
  }
  if (street.aligned && space.gap > 0) {
    final.result <- data.frame(
      time = result$time,
      lng = result$lng,
      lat = result$lat,
      field = result$field,
      n.points = result$n.points,
      street_heading = result$mean_heading
    )
  } else {
    final.result <- data.frame(
      time = result$time,
      lng = result$lng,
      lat = result$lat,
      field = result$field,
      n.points = result$n.points
    )
  }
  final.result <- final.result[order(final.result$time), ]
  return(final.result)
}
```

## Descripción Matemática

La función implementa un proceso de cuantización vectorial adaptativa para datos espacio-temporales, donde la discretización espacial se alinea con la dirección de las calles. Formalmente:

$$quantum.data: \mathbb{R}^{4\times n}\times\mathbb{R}^2\times(\mathcal{P}(\mathbb{R})\to\mathbb{R})\to\mathbb{R}^{6\times m}$$

Donde:

- **Dominio**: 4 vectores de dimensión $n$ (tiempo, longitud, latitud y campo), parámetros de discretización y función de agregación
- **Codominio**: Matriz de datos discretizados con 6 atributos y $m \leq n$ puntos

## Parámetros de Entrada

- $\text{time.data} \in \mathbb{R}^n$: Vector de tiempos en segundos
- $\text{lng.data} \in \mathbb{R}^n$: Vector de longitudes en grados decimales
- $\text{lat.data} \in \mathbb{R}^n$: Vector de latitudes en grados decimales
- $\text{field.data} \in \mathbb{R}^n$: Vector de valores del campo de interés
- $\text{time.gap} \in \mathbb{R}^+$: Intervalo temporal de discretización en segundos
- $\text{space.gap} \in \mathbb{R}^+$: Intervalo espacial a lo largo de la calle en metros
- $\text{street.aligned} = \text{TRUE}$: Activa discretización alineada a calles
- $\text{street.angle.tolerance} = 30$: Tolerancia angular para agrupación transversal en grados
- $\text{compile.function}: \mathcal{P}(\mathbb{R}) \to \mathbb{R}$: Función de agregación (media, mediana, moda, máximo, mínimo, etc.)

## Proceso de Discretización

### 1. Constantes de Conversión Geográfica

Para convertir coordenadas geográficas a distancias métricas:

$$C_{lat}\equiv 111320 m/°$$

$$C_{lng}(\phi)\equiv C_{lat} \times \cos\left(\phi \times \frac{\pi}{180}\right)$$

Donde $\phi$ es la latitud en grados.

### 2. Cálculo de la Dirección de la Calle (Heading)

Para cada punto $P_i = (t_i, \lambda_i, \phi_i, v_i)$ donde:

- $t_i$: tiempo
- $\lambda_i$: longitud
- $\phi_i$: latitud
- $v_i$: valor del campo

Calculamos el ángulo de dirección $\theta_i$ usando diferencias centrales:

$$\Delta x_i^m = (\lambda_{i+1} - \lambda_{i-1}) \times C_{lng}(\phi_i)$$

$$\Delta y_i^m = (\phi_{i+1} - \phi_{i-1}) \times C_{lat}$$

$$\theta_i = \text{atan2}(\Delta y_i^m, \Delta x_i^m)$$

Donde $\text{atan2}(y, x)$ es la función arcotangente de dos argumentos que devuelve el ángulo en radianes entre el eje X positivo y el vector $(x, y)$.

### 3. Transformación al Sistema de Coordenadas de la Calle

Para cada punto $P_i = (\lambda_i, \phi_i, \theta_i)$, donde:

- $\lambda_i$: longitud en grados
- $\phi_i$: latitud en grados
- $\theta_i$: ángulo de dirección de la calle en radianes (calculado en el paso anterior)

Realizamos una transformación de coordenadas afín que alinea el sistema de referencia local con la dirección de la calle:

**3.1 Conversión a Coordenadas Métricas Cartesianas**

Primero, convertimos las coordenadas geográficas a un sistema métrico local:

$$x_i^G = \lambda_i \times C_{lng}(\phi_i)$$
$$y_i^G = \phi_i \times C_{lat}$$

Donde:

- $x_i^G$: coordenada este-oeste en metros
- $y_i^G$: coordenada norte-sur en metros
- $C_{lng}(\phi_i) = 111320 \times \cos(\phi_i \times \frac{\pi}{180})$: metros por grado de longitud a latitud $\phi_i$
- $C_{lat} = 111320$: metros por grado de latitud

**3.2 Construcción del Sistema de Coordenadas Local**

Definimos una base ortonormal $\mathcal{B}i = {\vec{e}{\parallel}, \vec{e}_{\perp}}$ donde:

- $\vec{e}_{\parallel} = (\cos\theta_i, \sin\theta_i)$: vector unitario paralelo a la calle
- $\vec{e}_{\perp} = (-\sin\theta_i, \cos\theta_i)$: vector unitario perpendicular a la calle

Esta base satisface:

- $|\vec{e}{\parallel}| = |\vec{e}{\perp}| = 1$
- $\vec{e}{\parallel} \cdot \vec{e}{\perp} = 0$ (ortogonalidad)
- $\det(\vec{e}{\parallel}, \vec{e}{\perp}) = 1$ (orientación positiva)

**3.3 Transformación de Coordenadas**

La transformación del sistema global de coordenadas geográficas al sistema local alineado con la calle se realiza mediante una rotación ortogonal que depende del ángulo de dirección $\theta_i$.

*Definición Formal*

Dado un punto $P_i$ con:

- Coordenadas geográficas originales: $(\lambda_i, \phi_i)$ en grados
- Coordenadas métricas globales: $(x_i^G, y_i^G)$ en metros
- Ángulo de dirección de la calle: $\theta_i$ en radianes

La transformación al sistema local es:

$$
\begin{bmatrix}
x_i' \\
y_i'
\end{bmatrix} = R(\theta_i)^\top \cdot 
\begin{bmatrix}
x_i^G \\
y_i^G
\end{bmatrix}
$$

donde $R(\theta_i)$ es la matriz de rotación:

$$
R(\theta_i) = \begin{bmatrix} 
\cos\theta_i & \sin\theta_i \\ 
-\sin\theta_i & \cos\theta_i 
\end{bmatrix}
$$

y por lo tanto:

$$
R(\theta_i)^\top = R(-\theta_i) = \begin{bmatrix} \cos\theta_i & \sin\theta_i \\ -\sin\theta_i & \cos\theta_i \end{bmatrix}
$$

*Desarrollo Paso a Paso*

1. Vector de posición en sistema global:
  $$
  \mathbf{r}_i^G = \begin{bmatrix} x_i^G \\ y_i^G \end{bmatrix}
  $$
2. Bases de los sistemas de coordenadas:
  Sistema global $\mathcal{G}$:
  $$
  \begin{bmatrix}
  \mathcal{G} = \left\{ \vec{e}_x^G = \begin{bmatrix} 1 \\ 0 \end{bmatrix}, \ \vec{e}_y^G = \begin{bmatrix} 0 \\ 1 \end{bmatrix} \right\}
  \end{bmatrix}
  $$
  Sistema local $\mathcal{L}_i$:
  $$
  \mathcal{L}_i = \left\{ 
  \vec{e}_{\parallel} = \begin{bmatrix} \cos\theta_i \\ \sin\theta_i \end{bmatrix}, 
  \quad 
  \vec{e}_{\perp} = \begin{bmatrix} -\sin\theta_i \\ \cos\theta_i \end{bmatrix} 
  \right\}
  $$
3. Cambio de base:
  Las coordenadas $(x_i', y_i')$ en el sistema local satisfacen:
  $$
  \vec{r}_i^G = x_i' \vec{e}_{\parallel} + y_i' \vec{e}_{\perp}
  $$
  En forma matricial:
  $$
  \begin{bmatrix}
  x_i^G \\
  y_i^G
  \end{bmatrix} =
  \begin{bmatrix}
  \cos\theta_i & -\sin\theta_i \\
  \sin\theta_i & \cos\theta_i
  \end{bmatrix}
  \begin{bmatrix}
  x_i' \\
  y_i'
  \end{bmatrix}
  $$
4. Solución para coordenadas locales:
  Despejando $(x_i', y_i')$:
  $$
  \begin{bmatrix}
  x_i' \\
  y_i'
  \end{bmatrix}
  =
  \begin{bmatrix}
  \cos\theta_i & -\sin\theta_i \\
  \sin\theta_i & \cos\theta_i
  \end{bmatrix}
  \begin{bmatrix}
  x_i^G \\
  y_i^G
  \end{bmatrix}
  $$

*Interpretación Geométrica*

1. Sistema global:
  - Eje X: dirección este (positivo hacia el este)
  - Eje Y: dirección norte (positivo hacia el norte)
2. Sistema local:
  - Eje $x'$ (longitudinal): paralelo a la dirección de la calle $\theta_i$
  - Eje $y'$ (transversal): perpendicular a la calle ($\theta_i + \frac{\pi}{2}$)
3. Transformación como rotación activa vs. pasiva:
  Esta transformación puede interpretarse de dos formas equivalentes:
  a) Rotación pasiva del sistema de referencia: Rotamos los ejes de coordenadas en un ángulo $-\theta_i$, manteniendo fijo el vector $\vec{r}_i^G$.
  b) Rotación activa del vector: Rotamos el vector $\vec{r}_i^G$ en un ángulo $\theta_i$ en sentido contrario a las agujas del reloj, manteniendo fijos los ejes.

### 4. Discretización Temporal

Sea $T = {t_1, t_2, \dots, t_n}$ el conjunto ordenado de tiempos, con $t_1 < t_2 < \dots < t_n$.

**4.1 Construcción de Bins Temporales**

Definimos el ancho de bin temporal como $\Delta t = \text{time.gap}$. Los límites temporales son:

- $t_{\min} = \min(T)$
- $t_{\max} = \max(T)$

El número de bins temporales $N_t$ se calcula como:

$$
N_t = \left\lceil \frac{t_{\max} - t_{\min}}{\Delta t} \right\rceil + 1
$$

Los bins temporales son intervalos semiabiertos:

$$
B_t[k] = [t_{\min} + (k-1)\Delta t,\ t_{\min} + k\Delta t),\quad k = 1, 2, \dots, N_t-1
$$

El último bin es cerrado para incluir $t_{\max}$:

$$
B_t[N_t] = [t_{\min} + (N_t-1)\Delta t,\ t_{\max}]
$$

**4.2 Asignación de Puntos a Bins Temporales**

Para cada tiempo $t_i$, determinamos su bin temporal:

$$
b_t(i) = \left\lfloor \frac{t_i - t_{\min}}{\Delta t} \right\rfloor + 1
$$

Con la restricción: $1 \leq b_t(i) \leq N_t$

### 5. Discretización Espacial Orientada a Calles

**5.1 Discretización Longitudinal (a lo largo de $x'$)**

Sea $X' = \{x_1', x_2', \dots, x_n'\}$ el conjunto de coordenadas longitudinales transformadas.

*Paso 1*: Determinación del rango:

$$
x_{\min}' = \min(X'), \quad x_{\max}' = \max(X')
$$

*Paso 2*: Construcción de bins longitudinales con ancho $\Delta s = \text{space.gap}$:

$$
N_x = \left\lceil \frac{x_{\max}' - x_{\min}'}{\Delta s} \right\rceil + 1
$$

Los bins longitudinales son:

$$
B_x[\ell] = [x_{\min}' + (\ell-1)\Delta s,\ x_{\min}' + \ell\Delta s),\quad \ell = 1, 2, \dots, N_x-1
$$

El último bin incluye el límite superior:

$$
B_x[N_x] = [x_{\min}' + (N_x-1)\Delta s,\ x_{\max}']
$$

*Paso 3*: Asignación de puntos a bins:

$$
b_x(i) = \left\lfloor \frac{x_i' - x_{\min}'}{\Delta s} \right\rfloor + 1
$$

**5.2 Discretización Transversal (a lo largo de $y'$)**

*Paso 1*: Cálculo del ancho de bin transversal:

$$
\Delta s_y = \Delta s \times \sin\left(\alpha \times \frac{\pi}{180}\right)
$$

donde $\alpha = \text{street.angle.tolerance} = 30°$.

Para $\alpha = 30°$:

$$
\sin(30°) = \frac{1}{2} \Rightarrow \Delta s_y = \frac{\Delta s}{2}
$$

**Interpretación**: Esta elección crea bins con relación de aspecto 2:1, lo que significa que los bins son el doble de largos que de anchos. Esto refleja la intuición de que la variación a lo largo de una calle es más importante que la variación transversal para análisis de tráfico.

*Paso 2*: Determinación del rango transversal:

$$
y_{\min}' = \min(Y'), \quad y_{\max}' = \max(Y')
$$

donde $Y' = \{y_1', y_2', \dots, y_n'\}$ es el conjunto de coordenadas transversales transformadas.

*Paso 3*: Construcción de bins transversales:

$$
N_y = \left\lceil \frac{y_{\max}' - y_{\min}'}{\Delta s_y} \right\rceil + 1
$$

Los bins transversales son:

$$
B_y[m] = [y_{\min}' + (m-1)\Delta s_y,\ y_{\min}' + m\Delta s_y),\quad m = 1, 2, \dots, N_y-1
$$

El último bin incluye el límite superior:

$$
B_y[N_y] = [y_{\min}' + (N_y-1)\Delta s_y,\ y_{\max}']
$$

*Paso 4*: Asignación de puntos a bins:

$$
b_y(i) = \left\lfloor \frac{y_i' - y_{\min}'}{\Delta s_y} \right\rfloor + 1
$$

### 6. Agregación por Celdas 3D

**6.1 Definición de Celdas**

Una **celda** $C_{k,\ell,m}$ se define como la intersección de:
- Bin temporal $B_t[k]$
- Bin longitudinal $B_x[\ell]$
- Bin transversal $B_y[m]$

Formalmente:

$$
C_{k,\ell,m} = \{i \in \{1,\dots,n\} : b_t(i) = k,\ b_x(i) = \ell,\ b_y(i) = m\}
$$

**6.2 Estadísticos por Celda**

Para cada celda no vacía ($|C_{k,\ell,m}| > 0$):

1. **Tiempo representativo** (promedio temporal):
   $$
   \bar{t}_{k,\ell,m} = \frac{1}{|C|} \sum_{i \in C} t_i
   $$
2. **Posición representativa** (centroide en coordenadas originales):
   - Longitud promedio: $\bar{\lambda}_{k,\ell,m} = \frac{1}{|C|} \sum_{i \in C} \lambda_i$
   - Latitud promedio: $\bar{\phi}_{k,\ell,m} = \frac{1}{|C|} \sum_{i \in C} \phi_i$
3. **Valor del campo agregado**:
   $$
   \bar{v}_{k,\ell,m} = \text{compile.function}(\{v_i : i \in C\})
   $$
   Donde $\text{compile.function}$ puede ser:
   - Media: $\frac{1}{|C|} \sum_{i \in C} v_i$
   - Máximo: $\max\{v_i : i \in C\}$
   - Mínimo: $\min\{v_i : i \in C\}$
   - Suma: $\sum_{i \in C} v_i$
4. **Número de puntos**:
   $$
   n_{k,\ell,m} = |C| = \text{cardinalidad de } C
   $$
5. **Dirección promedio de la calle** (promedio circular):
   Para ángulos $\theta_i$, el promedio circular se calcula como:
   
   - Componente coseno: $C_{\theta} = \frac{1}{|C|} \sum_{i \in C} \cos\theta_i$
   - Componente seno: $S_{\theta} = \frac{1}{|C|} \sum_{i \in C} \sin\theta_i$
   - Dirección promedio: $\bar{\theta}_{k,\ell,m} = \text{atan2}(S_{\theta}, C_{\theta})$

   **Nota**: Este método evita problemas en el promedio de ángulos cerca de $0°/360°$.

**6.3 Propiedades de la Agregación**

1. **Conservación de masa** (para funciones de suma):
   $$
   \sum_{k,\ell,m} \bar{v}_{k,\ell,m} = \sum_{i=1}^n v_i
   $$
2. **Monotonicidad**: Si $\text{compile.function}$ es monótona, el orden se preserva.
3. **Idempotencia**: Si todos los puntos caen en la misma celda y $\text{compile.function} = \text{identidad}$, entonces $\bar{v} = v_i$ para todo $i$.

### 7. Construcción de la Salida

La función retorna un conjunto de $m$ puntos discretizados:

$$
D = \{(\bar{t}_j, \bar{\lambda}_j, \bar{\phi}_j, \bar{v}_j, n_j, \bar{\theta}_j)\}_{j=1}^m
$$

donde $j$ indexa las celdas no vacías ordenadas por:

1. Tiempo $\bar{t}_j$ (creciente)
2. Coordenada longitudinal transformada $x_j'$ (creciente)
3. Coordenada transversal transformada $y_j'$ (creciente)

**7.1 Transformación Inversa para Visualización**

Para visualizar o analizar los resultados en coordenadas originales, cada punto discretizado representa una **celda rectangular** en el sistema de coordenadas de la calle:

- Centro: $(\bar{\lambda}_j, \bar{\phi}_j)$
- Dimensiones: $\Delta s$ (largo) × $\Delta s_y$ (ancho)
- Orientación: $\bar{\theta}_j$

Los vértices de la celda en coordenadas globales son:

$$
\begin{bmatrix}
\lambda_{\text{vértice}} \\
\phi_{\text{vértice}}
\end{bmatrix} = 
\begin{bmatrix}
\bar{\lambda}_j \\
\bar{\phi}_j
\end{bmatrix} + \frac{1}{C_{lng}(\bar{\phi}_j)} R(\bar{\theta}_j) 
\begin{bmatrix}
\pm\frac{\Delta s}{2} \\
\pm\frac{\Delta s_y}{2}
\end{bmatrix}
$$

### 8. Propiedades Matemáticas Globales

**8.1 Reducción Dimensional**

El número de puntos de salida $m$ satisface:

$$
m \leq \min(n,\ N_t \times N_x \times N_y)
$$

En la práctica, típicamente:

$$
m \approx \frac{n}{\left\lfloor \frac{\Delta t}{\Delta t_{\text{original}}} \right\rfloor \times \left\lfloor \frac{\Delta s}{\Delta s_{\text{original}}} \right\rfloor}
$$

donde $\Delta t_{\text{original}}$ y $\Delta s_{\text{original}}$ son las resoluciones originales de los datos.

**8.2 Error de Discretización**

Definimos el **error de representación** para una celda $C$:
$$
\epsilon_C = \frac{1}{|C|} \sum_{i \in C} \|P_i - \bar{P}_C\|
$$

donde $P_i = (\lambda_i, \phi_i)$ y $\bar{P}_C = (\bar{\lambda}_C, \bar{\phi}_C)$.

Bajo condiciones suaves:

$$
\mathbb{E}[\epsilon_C] \approx \frac{\Delta s}{2\sqrt{3}} \ \text{(longitudinal)} + \frac{\Delta s_y}{2\sqrt{3}} \ \text{(transversal)}
$$

**8.3 Conservación de Información**

La transformación preserva:
1. **Orden temporal**: Si $t_i < t_j$, entonces $\bar{t}_{C(i)} \leq \bar{t}_{C(j)}$
2. **Vecindad espacial**: Puntos cercanos en la misma dirección se mantienen cercanos
3. **Propiedades estadísticas**: Dependiendo de $\text{compile.function}$

### 9. Ventajas sobre Discretización Cartesiana Tradicional

1. **Adaptabilidad direccional**: Se ajusta a la geometría de la red vial
2. **Mejor agrupación semántica**: Agrupa puntos que están en la misma calle
3. **Reducción de error en curvas**: Menor distorsión en tramos curvos
4. **Separación natural de direcciones**: Diferentes sentidos de circulación se discretizan por separado
5. **Interpretabilidad física**: Las dimensiones de las celdas tienen significado físico (largo/ancho de calle)
