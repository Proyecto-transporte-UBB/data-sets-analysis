---
title: "Análisis de los Sets de Datos"
author: "Luciano Hernández"
date: "`r Sys.Date()`"
output:
  pdf_document:
    toc: true
    toc_depth: 3
    keep_tex: true
  html_document:
    toc: true
    toc_depth: 3
    toc_float: true
    number_sections: true
---

```{r setup, include=FALSE}
if (Sys.getenv("JAVA_HOME")=="") {
  Sys.setenv(JAVA_HOME="C:/Program Files/Java/jre1.8.0_361")
}
knitr::opts_chunk$set(echo = TRUE)
options(future.globals.maxSize = 8000 * 1024^2)
options(java.parameters = "-Xmx2048m")
library(cowplot)
library(data.table)
library(dplyr)
library(ggmap)
library(ggplot2)
library(ggspatial)
library(googlesheets4)
library(grid)
library(gridExtra)
library(gtfsio)
library(httr)
library(knitr)
library(leaflet)
library(lubridate)
library(maps)
library(OpenStreetMap)
library(openxlsx)
library(osmdata)
library(prettymapr)
library(protolite)
library(purrr)
library(readr)
library(readxl)
library(rjson)
library(rnaturalearth)
library(rnaturalearthdata)
library(sf)
library(stringr)
library(tidyr)
library(tidytransit)
library(tidyverse)
library(tidyxl)
library(viridis)
```

```{r key.objects, include=FALSE}
key.objects <- c("interurban.bus.accidents", "gh026929", "police.accidents", "radio.accidents.df", "chiguayante.speed.df", "vega.speed.df", "gps.events", "biobio.inventary", "trafic.alerts", "accidents", "waze.data", "meters.per.degree.lat", "meters.per.degree.lng", "quantum.data", "tracking.gps.df", "waze.routes", "waze.routes.df")
```

```{r save, eval=FALSE, include=FALSE}
deleting.objects <- setdiff(ls(), key.objects)
rm(list = deleting.objects)
gc()
memory.limit()
memory.size()
save.image("~/GitHub/data-sets-analysis/.RData")
save.time.sys <- ls()
for(ko in key.objects) {
  start.sys <- Sys.time()
  file.name <- paste(ko, "rds", sep = ".")
  file.path. <- paste("~/GitHub/data-sets-analysis/rds-files", file.name, sep = "/")
  ko %>% get() %>% saveRDS(file = file.path.)
  end.sys <- Sys.time()
  dt.sys <- end.sys - start.sys
  print(ko)
  print(dt.sys)
  save.time.sys[[ko]] <- dt.sys
}
```


```{r load, include=FALSE}
load.time.sys <- list()
for(ko in key.objects[key.objects != "tracking.gps.df"]) {
  start.sys <- Sys.time()
  file.name <- paste(ko, "rds", sep = ".")
  file.path. <- paste("~/GitHub/data-sets-analysis/rds-files", file.name, sep = "/")
  assign(ko, ko %>% readRDS(file = file.path.))
  end.sys <- Sys.time()
  dt.sys <- end.sys - start.sys
  print(ko)
  print(dt.sys)
  load.time.sys[[ko]] <- dt.sys
}
sum.time <- function(dt.list){
  dt.list %>% sapply(., function(t){
    (t %>% as.numeric()) * switch (t %>% units(),
      "secs" = 1,
      "mins" = 60,
    )
  }) %>% sum()
}
total.load.dt <- load.time.sys %>% sum.time()
```

```{r load.tracking.gps.df, include=FALSE}
ml <- 8 * 1024^3
ms <- 6 * 1024^3
Sys.setenv("R_MAX_VSIZE" = "8Gb")
memory.limit(size = ml)
options(future.globals.maxSize = ms)
gc()
loaded <- F
ko <- "tracking.gps.df"
start.sys <- Sys.time()
file.name <- paste(ko, "rds", sep = ".")
file.path. <- paste("~/GitHub/data-sets-analysis/rds-files", file.name, sep = "/")
tryCatch({
  assign(ko, ko %>% readRDS(file = file.path.))
  loaded <- T
}, error = function(e){
  print(paste("Error al cargar:", e$message))
  ml <- 2 * ml
  ms <- 2 * ms
  memory.limit(size = ml)
  options(future.globals.maxSize = ms)
  gc()
})
while(!loaded){
  tryCatch({
    assign(ko, ko %>% readRDS(file = file.path.))
    loaded <- T
  }, error = function(e){
    print(paste("Error al cargar:", e$message))
    ml <- 2 * ml
    ms <- 2 * ms
    memory.limit(size = ml)
    options(future.globals.maxSize = ms)
    gc()
  })
}
end.sys <- Sys.time()
dt.sys <- end.sys - start.sys
print(ko)
print(dt.sys)
load.time.sys[[ko]] <- dt.sys
```

# Extracción y caracterización de datos

## Siniestros buses interurbanos(1).xlsx

```{r getData0, eval=FALSE, include=FALSE}
# Siniestros buses interurbanos(1).xlsx
interurban.bus.accidents <- read_excel("data/Siniestros buses interurbanos(1).xlsx", 
    col_types = c("numeric", "numeric", "date", 
        "date", "numeric", "text", "text", 
        "text", "text", "text", "text", "text", 
        "text", "text", "text", "text", "numeric", 
        "text", "numeric", "numeric", "numeric", 
        "numeric", "numeric", "numeric", 
        "numeric", "numeric", "numeric"))
interurban.bus.accidents$Fecha <- paste(interurban.bus.accidents$Fecha, interurban.bus.accidents$Hora %>% format(format = "%H:%M:%S")) %>% as.POSIXct(format = "%Y-%m-%d %H:%M")
interurban.bus.accidents <- interurban.bus.accidents %>% select(-Hora)
interurban.bus.accidents$Región <- interurban.bus.accidents$Región %>% as.factor()
interurban.bus.accidents$Comuna <- interurban.bus.accidents$Comuna %>% as.factor()
interurban.bus.accidents$`Tipo Accidente` <- interurban.bus.accidents$`Tipo Accidente` %>% as.factor()
interurban.bus.accidents$`Tipo (CONASET)` <- interurban.bus.accidents$`Tipo (CONASET)` %>% as.factor()
interurban.bus.accidents$Zona <- interurban.bus.accidents$Zona %>% as.factor()
interurban.bus.accidents$`Ubicación Relativa` <- interurban.bus.accidents$`Ubicación Relativa` %>% as.factor()
interurban.bus.accidents$`Causa (CONASET)` <- interurban.bus.accidents$`Causa (CONASET)` %>% as.factor()
interurban.bus.accidents$`Causa Accidente` <- interurban.bus.accidents$`Causa Accidente` %>% as.factor()
interurban.bus.accidents %>% summary()
```

El análisis comprende 6268 registros de siniestros de buses interurbanos ocurridos entre el 1 de enero de 2014 y el 29 de diciembre de 2023.

### Distribución Geográfica

- **Regiones más afectadas**: Región Metropolitana (1285 casos), Región del Maule (835 casos) y Región del Biobío (767 casos)
- **Comunas con mayor incidencia**: Curicó (244 siniestros), Valdivia (227) y Estación Central (186)

### Características de los Siniestros

- **Tipos predominantes**: Colisión (3655 casos), choque (1464) y atropello (448)
- **Distribución por zona**: 4251 accidentes en zonas urbanas (67.82%) versus 2,017 en zonas rurales (32.18%)

### Factores Causales

- **Principales causas**: Imprudencia del conductor (3597 casos), otras causas (599) y causas no determinadas (540)
- *Nota*: La alta frecuencia de la categoría "otras causas" sugiere la necesidad de ampliar la clasificación causal existente

### Consecuencias y Severidad

- Fallecidos: 94.58% de los siniestros no registran víctimas mortales
- Lesiones graves: Ausentes en 89.69% de los casos
- Lesiones menos graves: No ocurren en 94.16% de los accidentes
- Lesiones leves: No se presentan en 63.10% de los incidentes

### Optimizaciones Realizadas

**Paso a paso**

- "Fecha" se convirtió en la concatenación de "Fecha" y "Hora" y se convierte en POSIXct con formato "%d/%m/%Y %H:%M:%S"
- Se elimina la columna "Hora"
- "Región" se convierte en factor
- "Comuna" se convierte en factor
- "Tipo Accidente" se convierte en factor
- "Tipo (CONASET)" se convierte en factor
- "Zona" se convierte en factor
- "Ubicación Relativa" se convierte en factor
- "Causa (CONASET)" se convierte en factor
- "Causa Accidente" se convierte en factor

- **Unificación temporal**: Fusión de las columnas "Fecha" y "Hora" en un único campo datetime
- **Normalización de datos**: Conversión de 8 variables de texto a tipo factor para mejorar el procesamiento estadístico:
    - "Región"
    - "Comuna"
    - "Tipo Accidente"
    - "Tipo (CONASET)"
    - "Zona"
    - "Ubicación Relativa"
    - "Causa (CONASET)"
    - "Causa Accidente"

## GH026929.xlsx

```{r getData1, eval=FALSE, include=FALSE}
# GH026929.xlsx
gh026929 <- read_excel("data/GH026929.xlsx", 
    range = "A1:L1727", col_types = c("numeric", 
        "date", "text", "numeric", "numeric", 
        "numeric", "numeric", "skip", "skip", 
        "numeric", "numeric", "numeric"))

## ¿Qué es cts?
## Rangos altura
## ¿Qué es fix?
## U.M. precision

gh026929$date <- paste(gh026929$date, gh026929$hora) %>% as.POSIXct(format = "%Y-%m-%d %H:%M")
gh026929 <- gh026929 %>% select(-hora)
reduce.coords <- function(n) {
  n * 10 ^ (1 - (n %>% abs() %>% log10() %>% floor()))
}
reduce.2d.speed <- function(n, m) {
  N <- n * 10 ^ ((m %>% log10() + 1) %>% floor() - (n %>% log10() + 1) %>% floor())
  N[(N / m) %>% log10() > 0.7] <- N[(N / m) %>% log10() > 0.7] / 10
  N[(N / m) %>% log10() < -0.7] <- N[(N / m) %>% log10() < -0.7] * 10
  N
}
gh026929$`GPS (2D speed) [m/s]` <- reduce.2d.speed(gh026929$`GPS (2D speed) [m/s]`, gh026929$`GPS (3D speed) [m/s]`)
gh026929$`GPS (Lat.) [deg]` <- gh026929$`GPS (Lat.) [deg]` %>% reduce.coords()
gh026929$`GPS (Long.) [deg]` <- gh026929$`GPS (Long.) [deg]` %>% reduce.coords()
gh026929 %>% summary()
gh026929.sf <- gh026929 %>% st_as_sf(
  coords = c("GPS (Long.) [deg]", "GPS (Lat.) [deg]"),
  crs = 4326
)
gh026929.sf %>% st_write(.,
  "~/GitHub/data-sets-analysis/shapefiles/gh026929.shp",
  driver = "ESRI Shapefile",
  append = F
)
```

El dataset contiene 1726 registros de telemetría GPS capturados durante un período específico de operación vehicular.

### Características Temporales

- **Período de registro**: 29 de agosto de 2024, entre las 01:32 y 01:34 horas
- **Duración total**: Aproximadamente 2 minutos de monitoreo continuo

### Parámetros de Velocidad

- **Velocidad 3D**: Rango de 0.01 a 19.06 m/s (0.036 a 68.62 km/h)
- **Velocidad promedio**: 9.1 m/s (32.76 km/h)
- **Velocidad mediana**: 9.81 m/s (35.32 km/h), indicando una distribución sesgada hacia velocidades moderadas-altas

### Calidad de Señal GPS

- **Valor fix**: Constante en 3 para todos los registros, indicando que calculó su posición a partir de 3 satélites
- **Precisión**: Oscila entre 121 y 158 m (media: 125.9 m, mediana: 125 m)

### Aspectos Requieren Clarificación

**Variables por Definir**

- `cts`: Propósito y unidades no especificadas
- **Rango de alturas**: Valores de altitud GPS no reportados en el resumen

**Problemas de Formato Identificados**

- Coordenadas GPS (`Lat.` y `Long.`) sin formato decimal apropiado
- Velocidad 2D con inconsistencias en la ubicación del punto decimal
- Múltiples campos numéricos presentados sin separador decimal

### Procesamiento de Datos Realizado

**Paso a paso**

- "date" se convirtió en la concatenación de "date" y "hora" y se convierte en POSIXct con formato "%d/%m/%Y %H:%M"
- Se elimina la columna "hora"
- "GPS (2D speed) [m/s]" se trató de poner al mismo orden de magnitud de "GPS (3D speed) [m/s]" mediante la siguiente fórmula:

$$\text{reduce.2d.speed}(n,m)\equiv n\times10^{\lfloor\log_{10}m+1\rfloor-\lfloor\log_{10}n+1\rfloor}$$

- "GPS (Lat.) [deg]" y "GPS (Long.) [deg]" se ajustaron para tener 2 dígitos enteros mediante la siguiente fórmula:

$$\text{reduce.coords}(n)\equiv n\times10^{1-\lfloor\log_{10}|n|\rfloor}$$

**Normalización Temporal**

- Fusión de columnas `date` y `hora` en un campo datetime unificado

**Corrección de Coordenadas Geográficas**

Función aplicada:

$$\text{reduce.coords}(n)\equiv n\times10^{1-\lfloor\log_{10}|n|\rfloor}$$

*Objetivo*: Ajuste de coordenadas chilenas mediante reposicionamiento del punto decimal basado en el orden de magnitud

**Normalización de Velocidad 2D**

Función aplicada:

$$\text{reduce.2d.speed}(n,m)\equiv n\times10^{\lfloor\log_{10}m+1\rfloor-\lfloor\log_{10}n+1\rfloor}$$

*Objetivo*: Alineación de órdenes de magnitud entre velocidades 2D y 3D mediante escalado decimal dinámico

### Observaciones Técnicas

Los ajustes aplicados sugieren que el sistema de captura original podría presentar inconsistencias en el formato de salida numérico, requiriendo post-procesamiento para una interpretación correcta de las mediciones GPS.

## DTPR

```{r getData1.5, eval=FALSE, include=FALSE}
tracking.route <- "data/Tracking GPS"
tracking.cols <- c("EVT_REGISTRO_ID", "EVT_OP_TR_ID", "EVT_OP_TE_ID", "EVT_MES_INFORMACION", "EVT_SERVICIO_ID_ORACLE", "EVT_SERVICIO_ID", "EVT_SENTIDO", "EVT_IMEI", "EVT_PPU", "EVT_GPS_TIME_CHILE_STR", "EVT_GPS_TIME_UTC_0", "EVT_GPS_DIR_GEO", "Y_EVT_GPS_LAT", "X_EVT_GPS_LON", "EVT_GPS_VEL", "EVT_GPS_DOP", "EVT_DISTANCIA_RECORRIDA (Km)", "EVT_ESTADO_MOTOR_GPS", "EVT_TIPO_EVENTO", "EVT_TIPO_VIAJE", "EVT_DISTACIA_A_SERVICIO", "EVT_CARPETA")
folders <- tracking.route %>% list.dirs(recursive = F) %>% basename()
tracking.gps <- list()
tracking.read <- list()
for(folder in folders) {
  start.sys <- Sys.time()
  base.route <- paste(tracking.route, folder, "ArchivosTxt", sep = "/") %>% list.files(pattern = "^MNT_TRACKING", full.names = T)
  df <- base.route %>% read.table(header = F, sep = ";")
  df$EVT_CARPETA <- folder
  tracking.gps[[folder]] <- df
  end.sys <- Sys.time()
  dt.sys <- end.sys - start.sys
  tracking.read[[folder]] <- dt.sys
  print(folder)
  print(dt.sys)
}
# Reading time: 7 m + 8.22 s
start.sys <- Sys.time()
tracking.gps.df <- tracking.gps %>% bind_rows()
colnames(tracking.gps.df) <- tracking.cols
end.sys <- Sys.time()
binding.time <- end.sys - start.sys
# Binding time: 5 m + 0.63 s
start.sys <- Sys.time()
tracking.gps.df$EVT_SERVICIO_ID <- tracking.gps.df$EVT_SERVICIO_ID %>% as.factor()
tracking.gps.df$EVT_PPU <- tracking.gps.df$EVT_PPU %>% as.factor()
tracking.gps.df$EVT_GPS_TIME_CHILE_STR <- tracking.gps.df$EVT_GPS_TIME_CHILE_STR %>% as.POSIXct(format = "%d/%m/%Y %H:%M:%S", tz = "America/Santiago")
tracking.gps.df$EVT_GPS_TIME_UTC_0 <- tracking.gps.df$EVT_GPS_TIME_UTC_0 %>% as.POSIXct(format = "%d/%m/%Y %H:%M:%S")
tracking.gps.df$Y_EVT_GPS_LAT <- gsub(",", ".", tracking.gps.df$Y_EVT_GPS_LAT) %>% as.numeric()
tracking.gps.df$X_EVT_GPS_LON <- gsub(",", ".", tracking.gps.df$X_EVT_GPS_LON) %>% as.numeric()
tracking.gps.df$`EVT_DISTANCIA_RECORRIDA (Km)` <- gsub(",", ".", tracking.gps.df$`EVT_DISTANCIA_RECORRIDA (Km)`) %>% as.numeric()
tracking.gps.df$EVT_DISTACIA_A_SERVICIO <- gsub(",", ".", tracking.gps.df$EVT_DISTACIA_A_SERVICIO) %>% as.numeric()
tracking.gps.df$EVT_CARPETA <- tracking.gps.df$EVT_CARPETA %>% as.factor()
tracking.gps.df$EVT_SEÑAL <- NA
tracking.gps.df$EVT_SEÑAL[tracking.gps.df$EVT_GPS_DOP < 1] <- "Excelente"
tracking.gps.df$EVT_SEÑAL[tracking.gps.df$EVT_GPS_DOP >= 1 & tracking.gps.df$EVT_GPS_DOP < 2] <- "Muy Buena"
tracking.gps.df$EVT_SEÑAL[tracking.gps.df$EVT_GPS_DOP >= 2 & tracking.gps.df$EVT_GPS_DOP < 5] <- "Buena"
tracking.gps.df$EVT_SEÑAL[tracking.gps.df$EVT_GPS_DOP >= 5 & tracking.gps.df$EVT_GPS_DOP <= 10] <- "Regular"
tracking.gps.df$EVT_SEÑAL[tracking.gps.df$EVT_GPS_DOP >= 5 & tracking.gps.df$EVT_GPS_DOP > 10] <- "Mala"
tracking.gps.df$EVT_SEÑAL <- tracking.gps.df$EVT_SEÑAL %>% as.factor()
end.sys <- Sys.time()
modifying.time <- end.sys - start.sys
# Modifying time: 30 m + 7.08 s
options(future.globals.maxSize = 16 * 1024^3)
shp.time <- list()
tracking.gps.df.sf <- list()
for(folder in folders){
  start.sys <- Sys.time()
  df <- tracking.gps.df[tracking.gps.df$EVT_CARPETA == folder,]
  df.rename <- df %>%
    rename(
      SERV_ID = EVT_SERVICIO_ID,
      SERV_ID_O = EVT_SERVICIO_ID_ORACLE,
      GPS_TIME_CH = EVT_GPS_TIME_CHILE_STR,
      GPS_TIME_UTC = EVT_GPS_TIME_UTC_0,
      DIST_REC = `EVT_DISTANCIA_RECORRIDA (Km)`,
      DIST_SERV = EVT_DISTACIA_A_SERVICIO,
      CARPETA = EVT_CARPETA,
      SEÑAL = EVT_SEÑAL
    )
  sf <- df.rename %>% st_as_sf(
    coords = c("X_EVT_GPS_LON", "Y_EVT_GPS_LAT"),
    crs = 4326
  )
  file.name <- paste(folder, "shp", sep = ".")
  file.path. <- paste("~/GitHub/data-sets-analysis/shapefiles/DTPR", file.name, sep = "/")
  sf %>% st_write(.,
    file.path.,
    driver = "ESRI Shapefile",
    append = F
  )
  tracking.gps.df.sf[[folder]] <- sf
  end.sys <- Sys.time()
  dt <- end.sys - start.sys
  shp.time[[folder]] <- dt
  print(folder)
  print(dt)
}
# Shapefile time: 4m + 3.76s
shp.total.time <- shp.time %>% sum.time()
```

```{r getData1.51, eval=FALSE, include=FALSE}
tracking.gps.df %>% summary()
```

El dataset consolidado comprende 21683856 registros de telemetría GPS provenientes del sistema de monitoreo de transporte público DTPR, capturados durante el mes de agosto de 2025 a través de 31 unidades operativas diferentes.

### Metadatos de Procesamiento

- **Tiempo total de lectura**: 7 minutos 8.22 segundos
- **Tiempo de consolidación**: 5 minutos 0.63 segundos
- **Tiempo de transformación**: 30 minutos 7.08 segundos
- **Total de procesamiento**: 42 minutos 15.93 segundos

### Período de Monitoreo

- **Fecha inicial**: 1 de agosto de 2025, 00:00:00 (hora Chile)
- **Fecha final**: 1 de septiembre de 2025, 00:05:27 (hora Chile)
- **Duración**: 31 días completos + 5 minutos
- **Cobertura temporal**: Mes completo de agosto 2025

### Características Operacionales del Sistema

**Flota y Rutas Monitoreadas**

- **Rutas más frecuentes**:
  - "13GS": 617591 registros
  - "43JT": 500230 registros
  - "14HT": 481486 registros
- **Vehículos más activos**:
  - "FSLC62": 27847 registros
  - "TTHL10": 25901 registros
  - "SZDZ86": 25483 registros

**Distribución Direccional**

- **Sentido ida (0)**: 10809559 registros
- **Sentido vuelta (1)**: 10671146 registros
- **Sentido indeterminado (-1)**: 203151 registros

**Métricas de Desempeño Técnico**

_Calidad de Señal GPS_

- Muy Buena: 17924666 registros
- Buena: 966491 registros
- Regular: 592320 registros
- Mala: 2200379 registros

_Velocidades Operacionales_

- Rango: 0 - 193 km/h
- Velocidad promedio: 21.69 km/h
- Velocidad mediana: 19 km/h

```{r tracking.gps.df.density, echo=FALSE, warning=FALSE}
tracking.gps.df %>% 
  ggplot() +
  geom_histogram(aes(x = EVT_GPS_VEL), bins = 50, alpha = 0.7) +
  ggtitle("Distribución de velocidades") +
  xlab("Velocidad (km/h)") +
  ylab("Frecuencia")
```


_Estados del Sistema_

- Motor encendido (1): 21619957 registros
- Motor apagado (0): 63899 registros

### Procesamiento y Normalización de Datos

**Paso a paso**

- Se lee la carpeta
- Se crea la columna "EVT_CARPETA" con el nombre de la carpeta
- Se unifican los datasets en uno
- "EVT_SERVICIO_ID" se convierte en factor
- "EVT_PPU" se convierte en factor
- "EVT_GPS_TIME_CHILE_STR" se convierte en POSIXct con formato "%d/%m/%Y %H:%M:%S" y zona horaria "America/Santiago"
- "EVT_GPS_TIME_UTC_0" se convierte en POSIXct con formato "%d/%m/%Y %H:%M:%S"
- En "Y_EVT_GPS_LAT", se reemplaza "," por "." y se convierte en numérico
- En "X_EVT_GPS_LON", se reemplaza "," por "." y se convierte en numérico
- En "EVT_DISTANCIA_RECORRIDA (Km)", se reemplaza "," por "." y se convierte en numérico
- En "EVT_DISTACIA_A_SERVICIO", se reemplaza "," por "." y se convierte en numérico
- "EVT_CARPETA" se convierte en factor
- Se crea la columna "EVT_SEÑAL" a partir de los valores de la columna "EVT_GPS_DOP":
  - `Excelente`: $EVT_GPS_DOP < 1$
  - `Muy Buena`: $1 \leq EVT_GPS_DOP < 2$
  - `Buena`: $2 \leq EVT_GPS_DOP < 5$
  - `Regular`: $5 \leq EVT_GPS_DOP \leq 10$
  - `Mala`: $EVT_GPS_DOP > 10$

**Estructuración Multi-carpeta**

- **Estrategia**: Procesamiento paralelo de 31 unidades operativas
- **Identificación**: Incorporación de metadatos de carpeta origen
- **Consolidación**: Unificación en dataset coherente

**Transformaciones Aplicadas**

_Normalización Temporal_

- **Timestamp Chile**: Conversión a formato POSIXct
- **Timestamp UTC**: Sincronización con estándar internacional
- **Zona horaria**: Conservación de huso local (America/Santiago)

_Clasificación de Calidad de Señal_
_Escala DOP (Dilution of Precision)_:

- `Excelente`: $DOP < 1$
- `Muy Buena`: $1 \leq DOP < 2$
- `Buena`: $2 \leq DOP < 5$
- `Regular`: $5 \leq DOP \leq 10$
- `Mala`: $DOP > 10$

_Optimización de Tipos de Datos_

- **Coordenadas**: Conversión a numérico con estandarización decimal
- **Identificadores**: Transformación a factores para análisis categórico
- **Distancias**: Normalización de formatos numéricos

**Variables Críticas Procesadas**

- `EVT_GPS_TIME_CHILE_STR`, `EVT_GPS_TIME_UTC_0` -> POSIXct
- `EVT_SERVICIO_ID`, `EVT_PPU` -> Factor
- `Y_EVT_GPS_LAT`, `X_EVT_GPS_LON` -> Numérico
- `EVT_DISTANCIA_RECORRIDA` -> Numérico
- `EVT_SEÑAL` -> Factor (derivado de DOP)

### Análisis por Unidad Operativa

**Patrones de Operación por Unidad**

_Frecuencia de Reporte_

- **Típico**: 1:00-1:03 minutos entre registros por vehículo (mediana, separado por patente)
- **Variaciones**: UN52_265 muestra intervalos más irregulares (3.5s - 1min) (mediana, separado por patente)
- **Consistencia**: Mayoría mantiene intervalos estables

_Distribución por Unidad_

- **Mayor volumen**: UN80_274 (1459884 registros)
- **Menor volumen**: UN52_265 (118026 registros)
- **Promedio por unidad**: ~699479 registros

_Características Específicas Destacables_

- **UN13_247**: Operación exclusiva de ruta "13GS"
- **UN18_254**: Frecuencia muy consistente (1:03-1:03.5 min) (mediana, separado por patente)
- **UN22_257**: Mayor variabilidad en intervalos (59s - 22:31 min) (mediana, separado por patente)
- **UNB0_277**: Única unidad con datos en septiembre

```{r getData1.6, eval=FALSE, include=FALSE}
cities <- c(
  "Arica" = "arica",
  "Iquique" = "iquique",
  "Tocopilla" = "tocopilla",
  "Antofagasta" = "antofagasta",
  "Calama" = "calama",
  "Coquimbo - La Serena" = "serena",
  "Gran Valparaíso" = "valparaiso",
  "Región Metropolitana" = "rm-sur",
  "Linares" = "linares",
  "Chillán" = "chillan",
  "Gran Concepción" = "concepcion",
  "Villarrica" = "villarrica",
  "Temuco" = "temuco",
  "Valdivia" = "valdivia",
  "Osorno" = "osorno",
  "Puerto Montt" = "ptomontt",
  #"Castro" = "castro",
  #"Quellón" = "quellon",
  "Punta Arenas" = "punta-arenas"
)

get.data.gtfs.rt <- function(city = "concepcion"){
  if(!(city %in% cities)){
    stop(paste(city, "isn't a valid city code"))
  }
  url <- paste0("https://datamanager.dtpr.transapp.cl/data/gtfs-rt/", city, ".proto")
  response <- GET(url, add_headers("X-API-KEY" = token))
  if (response$status_code != 200) {
    stop(paste("Request Error:", response$status_code, "|", response))
  }
  raw.data <- content(response, "raw")
  temp.file <- tempfile(fileext = ".pb")
  writeBin(raw.data, temp.file)
  feed <- temp.file %>% readBin(what = "raw", n = file.info(temp.file)$size)
  safe.raw.to.char <- function(raw.vec){
    printable <- raw.vec[raw.vec >= 32 & raw.vec <= 126 | raw.vec == 10 | raw.vec == 13]
    printable %>% as.raw() %>% rawToChar()
  }
  visible.text <- feed %>% safe.raw.to.char()
  extract.all <- function(str){
    str_extract_all(visible.text, str)[[1]]
  }
  uuids <- extract.all("[a-f0-9]{8}-[a-f0-9]{4}-[a-f0-9]{4}-[a-f0-9]{4}-[a-f0-9]{12}")
  trip.ids <- extract.all("[0-9]{3}_[A-Z]_[A-Z]_[0-9]{4}")
  hours <- extract.all("[0-9]{2}:[0-9]{2}:[0-9]{2}")
  dates0 <- extract.all("202[0-9]{5}")
  dates <- paste(substr(dates0, 1, 4), substr(dates0, 5, 6), substr(dates0, 7, 8), sep = "-")
  datetimes <- paste(dates, hours) %>% as.POSIXct(format = "%Y-%m-%d %H:%M:%S")
  route.ids <- extract.all("P[0-9]{5}|[0-9]{4}0")
  timestamps <- extract.all("[0-9]{10}")
  datetimes.utc <- timestamps %>% as.numeric() %>% as.POSIXct(origin = "1970-01-01", tz = "UTC")
  datetimes.utc %>% summary()
  n <- min(uuids %>% length(), trip.ids %>% length(), route.ids %>% length() / 5)
  city.name <- cities[cities == city] %>% names()
  df <- data.frame(
    vehicle.uuid = if (uuids %>% length() >= n) uuids[1:n] else rep(NA, n),
    trip.id = if (trip.ids %>% length() >= n) trip.ids[1:n] else rep(NA, n),
    start.datetime = if (datetimes %>% length() >= n) datetimes[1:n] else rep(NA, n),
    sample.route.id = if (route.ids %>% length() >= n) route.ids[1:n] else rep(NA, n),
    city = city.name,
    stringsAsFactors = F
  )
  return(df)
}

get.all.data.gtfs.rt <- function(print.time = T){
  df.list <- list()
  if(print.time) dt.list <- list()
  for(city in cities){
    if(print.time) start.sys <- Sys.time()
    df <- city %>% get.data.gtfs.rt()
    if(print.time) end.sys <- Sys.time()
    city.name <- cities[cities == city] %>% names()
    df.list[[city.name]] <- df
    if(print.time){
      dt.sys <- end.sys - start.sys
      print(city.name)
      print(dt.sys)
      dt.list[[city.name]] <- dt.sys
    }
  }
  grfs.df <- df.list %>% bind_rows()
  grfs.df$city <- grfs.df$city %>% as.factor()
  grfs.df$trip.id <- grfs.df$trip.id %>% as.factor()
  grfs.df$sample.route.id <- grfs.df$sample.route.id %>% as.factor()
  if(print.time) {
    grfs.dt <- dt.list %>% sum.time()
    print("Total Reading Time:")
    print(grfs.dt)
  }
  return(grfs.df)
}

save.data.gtfs.rt <- function(city = "concepcion"){
  now <- Sys.time()
  real.time <- get.data.gtfs.rt()
  file.name <- paste(city, now %>% as.character() %>% str_replace_all(" ", "_") %>% str_replace_all(":", "."), "rds", sep = ".")
  file.path. <- paste("~/GitHub/data-sets-analysis/rds-files/DTPR API", file.name, sep = "/")
  real.time %>% saveRDS(file = file.path.)
}

run.continuously <- function(
  interval.minutes = 30,
  city = "concepcion"
) {
  while(T) {
    tryCatch({
      city %>% save.data.gtfs.rt()
      cat("GTFS data saved at", Sys.time() %>% as.character(), "\n")
    }, error = function(e) {
      cat("Error:", e$message, "at", Sys.time() %>% as.character(), "\n")
    })
    Sys.sleep(interval.minutes * 60)
  }
}
```


## Data accidentes de carabineros.xlsx

```{r getData2, eval=FALSE, include=FALSE}
# Data accidentes de carabineros.xlsx
police.accidents <- read_excel("data/Data accidentes de carabineros.xlsx", 
    col_types = c("numeric", "date", "skip", 
        "date", "text", "text", "text", "text", 
        "text", "numeric", "numeric", "numeric", 
        "numeric", "numeric", "text", "text", 
        "text", "text", "text"))
police.accidents$FECHA <- paste(police.accidents$FECHA, police.accidents$HORA %>% format(format = "%H:%M:%S")) %>% as.POSIXct(format = "%Y-%m-%d %H:%M")
police.accidents <- police.accidents %>% select(-HORA)
police.accidents$ZONA <- police.accidents$ZONA %>% as.factor()
police.accidents$COMUNA <- police.accidents$COMUNA %>% as.factor()
police.accidents$TIPO <- police.accidents$TIPO %>% as.factor()
police.accidents$CAUSA <- police.accidents$CAUSA %>% as.factor()
police.accidents$SECTOR <- police.accidents$SECTOR %>% as.factor()
police.accidents$KM <- police.accidents$KM %>% as.numeric()
police.accidents$PARTE <- police.accidents$PARTE %>% as.numeric()
police.accidents$TRIBUNAL <- police.accidents$TRIBUNAL %>% as.factor()
police.accidents$TIPO %>% summary()
police.accidents$`MACRO TIPO` <- police.accidents$TIPO %>% as.character()
police.accidents$`MACRO TIPO`[
  police.accidents$TIPO %in% c(
    "CHOQUE",
    "CHOQUE FRONTAL",
    "CHOQUE LATERAL",
    "CHOQUE POSTERIOR"
  )
] <- "CHOQUE"
police.accidents$`MACRO TIPO`[
  police.accidents$TIPO %in% c(
    "COLISION",
    "COLISION FRONTAL",
    "COLISION LATERAL",
    "COLISION PERPENDICULAR",
    "COLISION POR ALCANCE"
  )
] <- "COLISION"
police.accidents$`MACRO TIPO` <- police.accidents$`MACRO TIPO` %>% as.factor()
police.accidents %>% summary()
```

El dataset comprende 5739 registros de accidentes de tránsito documentados por Carabineros de Chile durante un período concentrado de 30 días.

### Período de Análisis

- **Cobertura temporal**: 1 al 30 de marzo de 2025 (30 días)
- **Registros diarios promedio**: aproximadamente 191 accidentes

### Distribución Geográfica

- **Regiones con mayor siniestralidad**:
    - Región Metropolitana (1513 casos)
    - Región del Biobío (699 casos)
    - Región del Maule (574 casos)
- **Comunas más afectadas**:
    - Concepción (193 accidentes)
    - Temuco (175 accidentes)
    - Arica (150 accidentes)
- **KM**:
    - **Rango**: Entre 0 y 112000 km
    - **Media**: 1629 km
    - **Mediana**: 312 km
    - **Nulos**: 3210 registros
- **PARTE**:
    - **Rango**: Entre $1 y 4157
    - **Media**: $491.4
    - **Mediana**: $282

### Clasificación de Accidentes

- **Tipos predominantes**:
    - Colisión: 2,936 casos
    - Choque: 1,801 casos
    - Atropello: 461 casos
- **Distribución por sector**:
    - Urbano: 4,432 casos
    - Rural: 1,304 casos
    - Vía férrea: 3 casos

### Procesamiento y Normalización de Datos

**Paso a paso**

- "FECHA" se convirtió en la concatenación de "FECHA" y "HORA" y se convierte en POSIXct con formato "%d/%m/%Y %H:%M"
- Se elimina la columna "HORA"
- "ZONA" se convierte en factor
- "COMUNA" se convierte en factor
- "TIPO" se convierte en factor
- "CAUSA" se convierte en factor
- "SECTOR" se convierte en factor
- "KM" se convierte en numérico
- "PARTE" se convierte en numérico
- "TRIBUNAL" se convierte en factor
- Se crea la columna "MACRO TIPO" con el valor de "TIPO", pero unificando los valores de "CHOQUE", "CHOQUE FRONTAL", "CHOQUE LATERAL"y "CHOQUE POSTERIOR" como "CHOQUE" y "COLISION", "COLISION FRONTAL", "COLISION LATERAL", "COLISION PERPENDICULAR", "COLISION POR ALCANCE" como "COLISION"
- "MACRO TIPO" se convierte en factor

**Optimizaciones Aplicadas**

- **Unificación temporal**: Fusión de campos "FECHA" y "HORA" en timestamp único
- **Normalización de tipos de datos**:
    - **Conversión a factor**: ZONA, COMUNA, TIPO, CAUSA, SECTOR, TRIBUNAL
    - **Conversión a numérico**: KM (donde aplicable) y PARTE

**Creación de Categorías Agrupadas**

- **Variable "MACRO TIPO"**:
    - **CHOQUE**: Agrupa "CHOQUE", "CHOQUE FRONTAL", "CHOQUE LATERAL", "CHOQUE POSTERIOR"
    - **COLISION**: Agrupa "COLISION", "COLISION FRONTAL", "COLISION LATERAL", "COLISION PERPENDICULAR", "COLISION POR ALCANCE"
    - **Conserva valores originales** para categorías no agrupables

### Observaciones Relevantes

La concentración temporal del dataset (solo 30 días) permite un análisis detallado de patrones de siniestralidad en un período específico, aunque limita la identificación de tendencias estacionales. La predominancia de accidentes en zonas urbanas refleja la distribución poblacional y de tráfico vehicular del país.

## Incidentes de tráfico radio.xlsx

```{r getData3, eval=FALSE, include=FALSE}
# Incidentes de tráfico radio.xlsx
file.path <- "data/Incidentes de tráfico radio.xlsx"
sheet.names <- file.path %>% excel_sheets()
date.sheets <- sheet.names[grepl("^\\d{1,2}-\\d{1,2}$", sheet.names)]
radio.accidents <- list()
cell.colors <- list()
get.cells.colors <- function(file.path, sheet.name, column.indices) {
  wb <- file.path %>% loadWorkbook()
  styles <- wb %>% getStyles()
  sheet <- wb[[sheet.name]]
  colors.list <- list()
  for(col.idx in column.indices) {
    col.letter <- col.idx %>% int2col()
    cell.refs <- paste0(col.letter, 1:(sheet$rows %>% length()))
    colors <- sapply(cell.refs, function(cell.ref) {
      cell.style <- sheet$styleObjects[[which(sapply(sheet$styleObjects, function(x) x$rows == as.numeric(gsub("\\D", "", cell.ref)) & x$cols == col.idx))]]
      if(!is.null(cell.style)) {
        cell.style$style$fill$fillFg
      } else {
        NA
      }
    })
    colors.list[[colnames(sheet)[col.idx]]] <- colors
  }
  colors.list
}
get.cell.colors.simple <- function(file.path, sheet.name) {
  wb <- file.path %>% loadWorkbook()
  all.styles <- wb %>% getStyles()
  sheet.styles <- wb$styleObjects[grepl(paste0("^", sheet.name, "\\."), wb$styleObjects %>% names())]
  sheet.data <- wb %>% read.xlsx(sheet = sheet.name)
  col.names <- sheet.data %>% names()
  tipo.cols <- (col.names %in% c("Tipo de incidente", "tipo de incidente")) %>% which()
  if(length(tipo.cols) == 0){
    list()
  } else {
    colors.df <- NA %>% matrix(nrow = sheet.data %>% nrow(), ncol = tipo.cols %>% length()) %>% data.frame()
    names(colors.df) <- col.names[tipo.cols]
    for(style.obj in wb$styleObjects) {
      if(style.obj$sheet == sheet.name && style.obj$cols %in% tipo.cols) {
        col.name <- col.names[style.obj$cols]
        for(row in style.obj$rows) {
          if(row <= colors.df %>% nrow()) {
            colors.df[row, col.name] <- style.obj$style$fill$fillFg
          }
        }
      }
    }
    colors.df
  }
}
get.cell.colors.tidyxl <- function(file.path, sheet.name) {
  cells <- file.path %>% xlsx_cells(sheets = sheet.name)
  formats <- file.path %>% xlsx_formats()
  target.cols <- c("Tipo de incidente", "tipo de incidente")
  col.indices <- cells %>%
    filter(!(character %>% is.na()) | !(numeric %>% is.na())) %>% 
    group_by(col) %>%
    summarise(
      header = character %>% first(na_rm = T),
      .groups = "drop"
    ) %>%
    filter(header %in% target.cols) %>%
    pull(col)
  if(col.indices %>% length() == 0){
    data.frame(
      row = integer(),
      col = integer(),
      color = character()
    )
  } else {
    colors.df <- cells %>%
      filter(col %in% col.indices) %>%
      select(row, col, address, character, numeric, local_format_id) %>%
      mutate(
        value = coalesce(character, numeric %>% as.character())
      ) %>%
      mutate(
        color = ifelse(
          !(local_format_id %>% is.na()),
          formats$local$fill$patternFill$fgColor$rgb[local_format_id],
          NA_character_
        )
      ) %>%
      select(row, col, value, color)
    colors.df
  }
}
for(sheet in date.sheets) {
  df <- file.path %>% read_excel(sheet = sheet)
  colors.info <- get.cell.colors.tidyxl(file.path, sheet)
  day.month <- (sheet %>% strsplit(., "-"))[[1]]
  day <- day.month[1] %>% as.numeric()
  month <- day.month[2] %>% as.numeric()
  ## ¿De qué año es?
  comp.date <- paste("2024", month, day, sep = "-") %>% as.Date()
  df$fecha <- comp.date
  df$`#ID` <- df$`#ID` %>% as.numeric()
  df$Hora <- df$Hora %>% as.numeric() %>% as.POSIXct() %>% format(format = "%H:%M")
  radio.accidents[[sheet]] <- df
  cell.colors[[sheet]] <- colors.info
}
radio.accidents.df <- radio.accidents %>% bind_rows()
all.colors.df <- cell.colors %>% bind_rows(.id = "sheet.name")
radio.accidents.df$sheet.name <- NA_character_
radio.accidents.df$original.row <- NA_integer_
row.counter <- 1
for(sheet in date.sheets) {
  n.rows <- radio.accidents[[sheet]] %>% nrow()
  if(n.rows > 0) {
    radio.accidents.df$sheet.name[row.counter:(row.counter + n.rows - 1)] <- sheet
    radio.accidents.df$original.row[row.counter:(row.counter + n.rows - 1)] <- 1:n.rows
  }
  row.counter <- row.counter + n.rows
}
radio.accidents.df <- radio.accidents.df %>%
  left_join(
    all.colors.df %>%
      select(sheet.name, row, color) %>%
      rename(original.row = row),
    by = c("sheet.name", "original.row")
  )
radio.accidents.df <- radio.accidents.df[!(radio.accidents.df$coord %>% is.na() | radio.accidents.df$`Reporte completo? (SI/NO)` %>% is.na()),]
radio.accidents.df$coord[!(radio.accidents.df$lat %>% is.na())] <- radio.accidents.df$lat[!(radio.accidents.df$lat %>% is.na())]
radio.accidents.df <- radio.accidents.df %>% select(-c(lat, `tipo de incidente`, ...7, ...13, sheet.name, original.row))
radio.accidents.df$dir[!(radio.accidents.df$...12 %>% is.na()) & (radio.accidents.df$dir %>% is.na())] <- radio.accidents.df$...12[!(radio.accidents.df$...12 %>% is.na()) & (radio.accidents.df$dir %>% is.na())]
radio.accidents.df <- radio.accidents.df %>% select(-...12)
radio.accidents.df$`Reporte completo? (SI/NO)`[(radio.accidents.df$`Reporte completo? (SI/NO)` %in% c("is", "si", "SI", "su")) %>% which()] <- "SI"
radio.accidents.df$`Reporte completo? (SI/NO)`[(radio.accidents.df$`Reporte completo? (SI/NO)` %in% c("no", "NO")) %>% which()] <- "NO"
radio.accidents.df$`Reporte completo? (SI/NO)`[(radio.accidents.df$`Reporte completo? (SI/NO)` == "-") %>% which()] <- NA
radio.accidents.df$`es incidente de tráfico? (si/no)`[(radio.accidents.df$`es incidente de tráfico? (si/no)` %in% c("si", "SI")) %>% which()] <- "SI"
radio.accidents.df$`es incidente de tráfico? (si/no)`[(radio.accidents.df$`es incidente de tráfico? (si/no)` %in% c("no", "NO")) %>% which()] <- "NO"
radio.accidents.df$dir[radio.accidents.df$dir %in% c("-", "n/a", "n/A")] <- NA
radio.accidents.df$dir[radio.accidents.df$dir %in% c("e-o", "E-O")] <- "E-O"
radio.accidents.df$dir[radio.accidents.df$dir %in% c("o-e", "O-E")] <- "O-E"
radio.accidents.df$dir[radio.accidents.df$dir %in% c("n-s", "n.s", "N-S")] <- "N-S"
radio.accidents.df$dir[radio.accidents.df$dir %in% c("s-n", "S-N")] <- "S-N"
radio.accidents.df$dir[radio.accidents.df$dir %in% c("n-s. s-n", "n-s.s-n", "N-S, S-N")] <- "N-S, S-N"
radio.accidents.df$dir[radio.accidents.df$dir %in% c("s-n.n-s", "S-N, N-S")] <- "S-N, N-S"
radio.accidents.df$`Reporte completo? (SI/NO)` <- radio.accidents.df$`Reporte completo? (SI/NO)` %>% as.factor()
radio.accidents.df$`es incidente de tráfico? (si/no)` <- radio.accidents.df$`es incidente de tráfico? (si/no)` %>% as.factor()
radio.accidents.df$dir <- radio.accidents.df$dir %>% as.factor()
radio.accidents.df$color <- radio.accidents.df$color %>% as.factor()
color_mapping <- c(
  "FF00B0F0" = "Intervenciones de Emergencia", 
  "FF00FFFF" = "Congestión",
  "FFFF0000" = "Accidente de tránsito",
  "FFFF00FF" = "Obstrucciones en la vía",
  "FFFF6600" = "Problema Infraestructura de control de tránsito",
  "FFFFC000" = "Condición de tráfico",
  "FFFFFF00" = "Congestión",
  "FF00B050" = "Otros"
)
radio.accidents.df$`Tipo de incidente` <- ifelse(
  radio.accidents.df$color %>% is.na(),
  "Congestión",
  color_mapping[radio.accidents.df$color]
) %>% as.factor()
radio.accidents.df <- radio.accidents.df %>% select(-color)
radio.accidents.df <- radio.accidents.df %>% fill(Hora, .direction = "down")
radio.accidents.df <- radio.accidents.df %>% separate(coord, into = c("lat", "lng"), sep = ",\\s*") %>% mutate(lat = lat %>% as.numeric(), lng = lng %>% as.numeric())
radio.accidents.df <- radio.accidents.df[!(radio.accidents.df$lat %>% is.na()),]
radio.accidents.df$Hora <- paste(radio.accidents.df$fecha, radio.accidents.df$Hora) %>% as.POSIXct(format = "%Y-%m-%d %H:%M")
radio.accidents.df <- radio.accidents.df %>% select(-fecha)
radio.accidents.df %>% summary()
radio.accidents.df.sf <- radio.accidents.df %>% st_as_sf(
  coords = c("lng", "lat"),
  crs = 4326
)
radio.accidents.df.sf %>% st_write(.,
  "~/GitHub/data-sets-analysis/shapefiles/radio.accidents.df.shp",
  driver = "ESRI Shapefile",
  append = F
)
```

El dataset contiene 312 registros de incidentes de tráfico reportados a través de sistemas de radio durante un período de 37 días.

### Período de Registro

- **Duración**: 15 de julio al 20 de agosto de 2024
- **Cobertura temporal**: 37 días de monitoreo continuo

### Clasificación de Incidentes

- **Naturaleza del incidente**:
    - **Incidentes de tráfico**: 263 casos
    - **No incidentes de tráfico**: 1 caso
    - **No especificado**: 48 casos
- **Completitud de reportes**:
    - **Reportes completos**: 257 casos
    - **Reportes incompletos**: 55 casos

### Tipología de Incidentes

*Distribución por categoría*:

- Congestión: 191 casos
- Obstrucciones en la vía: 38 casos
- Condición de tráfico: 26 casos
- Problema Infraestructura de control de tránsito: 25 casos
- Accidentes de tránsito: 20
- Intervenciones de emergencia: 7 casos
- Otros: 5 casos

### Direccionalidad del Tráfico Afectado

**Patrones de flujo vehicular impactado**:

- Sur a Norte (S-N): 53 casos
- Norte a Sur (N-S): 51 casos
- Bidireccional (N-S, S-N): 17 casos
- Este a Oeste (E-O): 15 casos
- Oeste a Este (O-E): 10 casos
- Ambos sentidos (a/s): 2 casos
- Bidireccional (S-N, N-S): 1 caso
- No especificado: 163 casos

### Procesamiento y Normalización de Datos

**Paso a paso**

- Se lee la hoja
- Se lee el color de la columna "tipo de incidente"
- Se crea la columna "fecha" con el nombre de la hoja
- "#ID" se convierte en numérico
- "Hora" se convierte en POSIXct con formato "%H:%M"
- Se unen los datasets en uno
- Se crea la columna "sheet.name" con el nombre de las hojas
- Se crea la columna "original.row" con el número de la fila original
- Se crea la columna "color" con el código del color de la columna "tipo de incidente"
- Se eliminan las filas en las que "coord" o "Reporte completo? (SI/NO)" es nulo
- Se eliminan las columnas "lat", "tipo de incidente", "...7", "...13", "sheet.name", "original.row"
- "dir" toma el valor de "...12" cuando "...12" no es nulo y "dir" es nulo
- Se elimina la columna "...12"
- En "Reporte completo? (SI/NO)", los valores "is", "si", "SI" y "su" se unifican como "SI", los valores "no" y "NO", como "NO" y "-" se considera nulo
- En "es incidente de tráfico? (si/no)", los valores "si" y "SI" se unifican como "SI" y los valores "no" y "NO", como "NO"
- En "dir", los valores "e-o" y "E-O" se unifican como "E-O", "o-e" y "O-E", como "O-E", "n-s", "n.s" y "N-S", como "N-S", "s-n" y "S-N" como "S-N", "n-s. s-n", "n-s.s-n" y "N-S, S-N", como "N-S, S-N", "s-n.n-s" y "S-N, N-S", como "S-N, N-S" y "-", "n/a" y "n/A" se consideran nulos
- "Reporte completo? (SI/NO)" se convierte en factor
- "es incidente de tráfico? (si/no)" se convierte en factor
- "dir" se convierte en factor
- "color" se convierte en factor
- Se crea la columna "Tipo de incidente" a partir de "color":
  - "Congestión" cuando es nulo
  - "Intervenciones de Emergencia" cuando es <font color="FF00B0F0">FF00B0F0</font>
  - "Congestión" cuando es <font color="FF00FFFF">FF00FFFF</font>
  - "Accidente de tránsito" cuando es <font color="FFFF0000">FFFF0000</font>
  - "Obstrucciones en la vía" cuando es <font color="FFFF00FF">FFFF00FF</font>
  - "Problema Infraestructura de control de tránsito" cuando es <font color="FFFF6600">FFFF6600</font>
  - "Condición de tráfico" cuando es <font color="FFFFC000">FFFFC000</font>
  - "Congestión" cuando es <font color="FFFFFF00">FFFFFF00</font>
  - "Otros" cuando es <font color="FF00B050">FF00B050</font>
- Se elimina la columna "color"
- Cuando "Hora" es nulo, toma el valor de la fila anterior
- "coord" se separa en "lat" y "lng", separado por ",\\s*" y se convierten en numéricos
- Se eliminan las filas en las que "lat" es nulo
- "Hora" se convirtió en la concatenación de "fecha" y "hora" y se convierte en POSIXct con el formato "%Y-%m-%d %H:%M"


**Extracción y Estructuración**

- **Identificación de hojas relevantes**: Filtrado por nombres con formato fecha (dd-mm)
- **Consolidación temporal**: Unificación de 37 hojas diarias en dataset único
- **Construcción de timeline**: Asignación de fechas basada en nombres de hojas

**Limpieza y Estandarización**

*Normalización de Variables Categóricas*:

- **"Reporte completo? (SI/NO)"**:
    - *Valores estandarizados*: "SI" para ["is", "si", "SI", "su"], "NO" para ["no", "NO"]
    - *Valores excluidos*: "-" convertido a NA
- **"es incidente de tráfico? (si/no)"**:
    - *Valores estandarizados*: "SI" para ["si", "SI"], "NO" para ["no", "NO"]
- *Direccionalidad ("dir")*:
    - *Normalización de notaciones*: Unificación de variantes ("e-o" -> "E-O", "n-s" -> "N-S", etc.)
    - *Patrones bidireccionales*: Estandarización de formatos compuestos
    - *Valores inválidos*: ["-", "n/a", "n/A"] convertidos a NA

**Sistema de Clasificación por Color**

*Mapeo cromático de tipos de incidente*:

- `FF00B0F0` -> Intervenciones de Emergencia
- `FF00FFFF`, `FFFFFF00`, `NA` -> Congestión
- `FFFF0000` -> Accidente de tránsito
- `FFFF00FF` -> Obstrucciones en la vía
- `FFFF6600` -> Problema Infraestructura de control
- `FFFFC000` -> Condición de tráfico
- `FF00B050` -> Otros

**Optimizaciones Geográficas y Temporales**

- **Coordenadas**: Separación de campo "coord" en latitud/longitud numéricas
- **Timestamp**: Fusión de fecha y hora en campo datetime unificado
- **Completitud**: Rellenado de horas faltantes con valores anteriores
- **Estructura de datos**: Conversión de variables clave a tipo factor

## Med velo CHIGUAYANTE.xlsx

```{r getData4, eval=FALSE, include=FALSE}
# Med velo CHIGUAYANTE.xlsx
date <- "2024-06-25"
file.path <- "data/Med velo CHIGUAYANTE.xlsx"
directions <- file.path %>% excel_sheets()
chiguayante.speed <- list()
for(sheet in directions) {
  df <- file.path %>% read_excel(sheet = sheet)
  df$dirección <- sheet
  df$`Lugar (dirección)` <- df$`Lugar (dirección)`[!(df$`Lugar (dirección)` %>% is.na())] %>% paste(collapse = ", ")
  chiguayante.speed[[sheet]] <- df
}
chiguayante.speed.df <- chiguayante.speed %>% bind_rows()
chiguayante.speed.df <- chiguayante.speed.df %>% select(-c(...5, ...6, ...7, ...8, ...9, ...10, ...11, ...12, ...13))
chiguayante.speed.df <- chiguayante.speed.df[!(chiguayante.speed.df$`Velocidad [km/hr]` %>% is.na()),]
chiguayante.speed.df <- chiguayante.speed.df %>% fill(Hora, .direction = "down")
chiguayante.speed.df$Hora <- paste(date, chiguayante.speed.df$Hora %>% as.POSIXct() %>% format(., "%H:%M:%S")) %>% as.POSIXct(format = "%Y-%m-%d %H:%M:%S")
chiguayante.speed.df$Comentario[chiguayante.speed.df$Comentario %in% c(
  "auto, doblo a Lo Plaza",
  "Auto, doblo a Lo Plaza",
  "Auto, gira a Lo Plaza"
)] <- "Auto, dobló a Lo Plaza"
chiguayante.speed.df$Comentario[chiguayante.speed.df$Comentario %in% c(
  "camion",
  "Camion"
)] <- "Camión"
chiguayante.speed.df$Comentario[chiguayante.speed.df$Comentario %in% c(
  "micro",
  "Micro"
)] <- "Micro"
chiguayante.speed.df$Comentario <- chiguayante.speed.df$Comentario %>% as.factor()
chiguayante.speed.df$dirección <- chiguayante.speed.df$dirección %>% as.factor()
chiguayante.speed.df$`Lugar (dirección)` <- chiguayante.speed.df$`Lugar (dirección)` %>% as.factor()
chiguayante.speed.df$Vehículo <- "Auto"
chiguayante.speed.df$Vehículo[chiguayante.speed.df$Comentario %in% c("Camión", "Micro", "MOTO", "retroexcavadora")] <- chiguayante.speed.df$Comentario[chiguayante.speed.df$Comentario %in% c("Camión", "Micro", "MOTO", "retroexcavadora")] %>% as.character()
chiguayante.speed.df$Vehículo <- chiguayante.speed.df$Vehículo %>% as.factor()
chiguayante.speed.df %>% summary()
```

El dataset contiene 338 mediciones de velocidad vehicular capturadas en el paradero "Bdo O'Higgins - Arauco" de Chiguayante, monitoreando el flujo entre Concepción y Hualqui.

### Contexto Operacional

- **Ubicación**: Paradero "Bdo O'Higgins - Arauco", Chiguayante
- **Corredor vial**: Concepción - Hualqui
- **Período de medición**: 26 de junio de 2024 entre las 09:06 y las 17:58 horas
- **Duración**: Aproximadamente 9 horas de monitoreo continuo

### Análisis de Velocidades

- **Rango de velocidades**: 3 a 71 km/h
- **Velocidad promedio**: 44.27 km/h
- **Velocidad mediana**: 43 km/h
- **Distribución**: Relativamente simétrica alrededor de la mediana

### Composición Vehicular

**Tipos de vehículos identificados**:

- **Automóviles**: 273 registros
- **Microbuses**: 52 registros
- **Camiones**: 9 registros
- **Motos**: 3 registros
- **Retroexcavadora**: 1 registro

### Patrones de Movimiento

**Distribución direccional**:

- **Hacia Concepción**: 163 mediciones
- **Hacia Hualqui**: 175 mediciones
- **Balance**: Ligero predominio del flujo hacia Hualqui

### Comportamientos Específicos

**Maniobras documentadas**:

- "Auto, dobló a Lo Plaza": 8 casos
- "Auto, iba a doblar a Lo Plaza": 1 caso
- "auto, se percibe cola": 1 caso

### Procesamiento y Normalización de Datos

**Paso a paso**

- Se lee la hoja
- Se crea la columna "dirección" con el nombre de la hoja
- La columna "Lugar (dirección)" se unen en un único valor que se arrastra hacia todas las filas de la hoja
- Se unen los datasets
- Se eliminan las columnas "...5", "...6", "...7", "...8", "...9", "...10", "...11", "...12" y "...13"
- Se eliminan las filas en las que "Velocidad [km/hr]" es nulo
- Las filas donde "Hora" es nulo toman el valor de la fila anterior
- La columna "Hora" se convierte en la concatenación entre "2024-06-25" y "Hora" y se convierte en un POSIXct con formato "%Y-%m-%d %H:%M:%S"
- En la columna "Comentario", los valores "auto, doblo a Lo Plaza", "Auto, doblo a Lo Plaza" y "Auto, gira a Lo Plaza" se unifican como "Auto, dobló a Lo Plaza", los valores "camion" y "Camion", como "Camión" y "micro" y "Micro", como "Micro"
- "Comentario" se convierte en factor
- "dirección" se convierte en factor
- "Lugar (dirección)" se convierte en factor
- Se crea la columna "Vehículo" que toma el valor de la columna "Comentario" si su valor es "Camión", "Micro", "MOTO" o "retroexcavadora" y "Auto" en otro caso
- "Vehículo" se convierte en factor

**Estructuración Multi-hoja**

- **Organización por dirección**: Cada hoja representa una dirección de flujo (Concepción->Hualqui / Hualqui->Concepción)
- **Consolidación**: Unificación de todas las hojas en dataset único
- **Metadatos direccionales**: Incorporación de columna "dirección" desde nombres de hojas

**Limpieza y Estandarización**

*Normalización de Localización*

- **Unificación geográfica**: Campo "Lugar (dirección)" consolidado por hoja
- **Eliminación de redundancias**: Remoción de 9 columnas vacías o duplicadas (...5 a ...13)

*Procesamiento Temporal*

- **Completitud horaria**: Rellenado de valores faltantes usando observaciones anteriores
- **Formato estandarizado**: Conversión a tipo hms para análisis temporal

*Estandarización de Categorías*

Comentarios vehiculares:

- *Maniobras*: Unificación de variantes ["auto, doblo a Lo Plaza", "Auto, doblo a Lo Plaza", "Auto, gira a Lo Plaza"] -> "Auto, dobló a Lo Plaza"
- *Tipos vehiculares*: Normalización de ["camion", "Camion"] -> "Camión" y ["micro", "Micro"] -> "Micro"

*Clasificación Vehicular Sistematizada*

Variable "Vehículo":

- *Valor por defecto*: "Auto" para registros sin comentario o con referencias a automóviles
- *Especificación*: Conservación de categorías explícitas ["Camión", "Micro", "MOTO", "retroexcavadora"]
- *Optimización*: Conversión a tipo factor para análisis categórico

**Optimizaciones Finales**

- **Estructuración**: Conversión de variables clave a tipo factor
- **Consistencia**: Validación de integridad de datos numéricos
- **Preparación analítica**: Dataset listo para análisis estadístico y temporal

## Med velo LA VEGA.xlsx

```{r getData5, eval=FALSE, include=FALSE}
#Med velo LA VEGA.xlsx
date <- "2024-06-25"
file.path <- "data/Med velo LA VEGA.xlsx"
sheets <- excel_sheets(file.path)
directions <- sheets[grepl("21", sheets) & grepl("mayo", sheets)]
vega.speed <- list()
for(sheet in directions) {
  df <- file.path %>% openxlsx::read.xlsx(sheet = sheet, colNames = T, fillMergedCells = T, detectDates = T, skipEmptyCols = F, skipEmptyRows = F)
  df <- df[, 2:5]
  df$Hora[!(df$Hora %>% is.na()) & df$Hora %>% as.numeric() > 1 & !((!(df$Hora %>% is.na()) & df$Hora %>% as.numeric() %>% is.numeric() & df$Hora %>% as.numeric() > 1) %>% is.na())] <- ((df$Hora[!(df$Hora %>% is.na()) & df$Hora %>% as.numeric() > 1 & !((!(df$Hora %>% is.na()) & df$Hora %>% as.numeric() %>% is.numeric() & df$Hora %>% as.numeric() > 1) %>% is.na())] %>% as.numeric() %>% round(digits = 2)) / 24) %>% as.character()
  df <- df %>% fill(Hora, .direction = "down")
  hour <- ((df$Hora %>% as.numeric()) * 24) %>% floor()
  minute <- (((df$Hora %>% as.numeric()) * 24 - hour) * 60) %>% floor()
  df$Hora <- sprintf("%02d:%02d:00", hour, minute)
  df$Hora <- paste(date, df$Hora) %>% as.POSIXct(format = "%Y-%m-%d %H:%M:%S")
  df$dirección <- sheet
  df$`Lugar.(dirección)` <- df$`Lugar.(dirección)`[!(df$`Lugar.(dirección)` %>% is.na())] %>% paste(collapse = ", ")
  vega.speed[[sheet]] <- df
}
vega.speed.df <- vega.speed %>% bind_rows()
vega.speed.df <- vega.speed.df[!(vega.speed.df$`Velocidad.[km/hr]` %>% is.na()),]
vega.speed.df$Comentario[vega.speed.df$Comentario %in% c(
  "cola por funeral",
  "forman cola"
)] <- "Forman cola"
vega.speed.df$Comentario[vega.speed.df$Comentario %in% c(
  "llega a cola",
  "llegan a cola",
  "llegan a cola, aprox 4 vehiculos",
  "llegan a cola formada antes de medir"
)] <- "Llega a cola"
vega.speed.df$Comentario[vega.speed.df$Comentario %in% c(
  "llegan juntos",
  "llegan juntos ",
  "llegan juntos, cola aprox 8 a 10 autos",
  "llegan juntos, generan cola"
)] <- "Llegan juntos"
vega.speed.df$Comentario[vega.speed.df$Comentario %in% c(
  "micro",
  "Micro"
)] <- "Micro"
vega.speed.df$Comentario[vega.speed.df$Comentario %in% c(
  "moto",
  "Moto"
)] <- "Moto"
vega.speed.df$Comentario <- vega.speed.df$Comentario %>% as.factor()
vega.speed.df$`Lugar.(dirección)` <- vega.speed.df$`Lugar.(dirección)` %>% as.factor()
vega.speed.df$dirección <- vega.speed.df$dirección %>% as.factor()
vega.speed.df %>% summary()
```

El dataset contiene 432 mediciones de velocidad vehicular capturadas en el cruce de Briceños con Miraflores, monitoreando el flujo entre 21 de Mayo y Avenida Costanera a través del sector Miraflores.

### Contexto Operacional

- **Ubicación**: Esquina Briceños con Miraflores, La Vega
- **Corredores viales**:
    - 21 de Mayo -> Briceños -> Miraflores
    - Av. Costanera -> Miraflores -> 21 de Mayo
- **Período de medición**: 25 de junio de 2024 entre las 08:08 y las 17:58 horas
- **Duración**: Aproximadamente 10 horas de monitoreo continuo

### Análisis de Velocidades

- **Rango de velocidades**: 5 a 53 km/h
- **Velocidad promedio**: 28.87 km/h
- **Velocidad mediana**: 29 km/h
- **Distribución**: Concentrada en velocidades bajas-medias, típicas de tráfico urbano congestionado

### Patrones de Movimiento

**Distribución direccional**:

- **Desde 21 de Mayo**: 250 mediciones
- **Hacia 21 de Mayo**: 182 mediciones
- **Balance**: Predominio del flujo desde 21 de Mayo

### Fenómenos de Congestión Documentados

**Patrones de formación de colas**:

- "Llegan juntos": 49 casos - agrupamiento vehicular sincronizado
- "Llega a cola": 22 casos - incorporación a colas existentes
- "Forman cola": 14 casos - generación de nuevas colas

**Composición vehicular adicional**:

- **Microbuses**: Registros específicamente identificados
- **Motocicletas**: Registros categorizados separadamente

### Procesamiento y Normalización de Datos

**Paso a paso**

- Se lee la hoja
- En la columna "Hora", se cambian las "," por ":" (ej: "8,15" -> "8:15")
- Las filas donde "Hora" es nulo toman el valor de la fila anterior
- La columna "Hora" se convierte en la concatenación entre "2024-06-25" y "Hora" y se convierte en un POSIXct con formato "%Y-%m-%d %H:%M:%S"
- Se crea la columna "dirección" con el nombre de la hoja
- La columna "Lugar (dirección)" se unen en un único valor que se arrastra hacia todas las filas de la hoja
- Se unen los datasets
- Se eliminan las filas en las que "Velocidad.[km/hr]" es nulo
- En la columna "Comentario", los valores "llega a cola", "llegan a cola", "llegan a cola, aprox 4 vehiculos" y "llegan a cola formada antes de medir" se unifican como "Llega a cola", los valores "llegan juntos", "llegan juntos ", "llegan juntos, cola aprox 8 a 10 autos" y "llegan juntos, generan cola", como "Llegan juntos", los valores "micro" y "Micro", como "Micro" y los valores "moto" y "Moto", como "Moto"
- "Comentario" se convierte en factor
- "Lugar (dirección)" se convierte en factor
- "dirección" se convierte en factor

**Estrategia de Extracción Multi-hoja**:

- **Filtrado inteligente**: Identificación de hojas relevantes mediante patrones "21" y "mayo"
- **Organización direccional**: Cada hoja representa un sentido de flujo específico
- **Consolidación estructurada**: Unificación de múltiples hojas en dataset coherente

**Corrección de Formatos Temporales**

*Normalización de Horarios*

- **Problema identificado**: Formato decimal incorrecto en celdas horarias (ej: "8,15" en lugar de "8:15")
- **Solución aplicada**:
    - Conversión de formato decimal a fracción diaria
    - Reconstrucción de horas y minutos mediante operaciones matemáticas
    - Formateo consistente a "HH:MM:SS"

*Completitud de Series Temporales*

- **Rellenado inteligente**: Propagación de valores horarios hacia adelante
- **Consistencia temporal**: Garantía de continuidad en las mediciones

**Estandarización de Categorías y Comentarios**

*Unificación de Términos de Congestión*

Agrupamiento por patrones:

- *Formación de colas*: ["cola por funeral", "forman cola"] -> "Forman cola"
- *Incorporación a colas*: Variantes de "llega a cola" unificadas
- *Agrupamiento vehicular*: Múltiples expresiones de "llegan juntos" estandarizadas

*Clasificación Vehicular*

- *Transporte público*: ["micro", "Micro"] -> "Micro"
- *Motocicletas*: ["moto", "Moto"] -> "Moto"

### Optimizaciones Estructurales

- **Geolocalización unificada**: Consolidación de "Lugar.(dirección)" por hoja
- **Metadatos direccionales**: Incorporación sistemática desde nombres de hojas
- **Tipificación eficiente**: Conversión a factores para análisis categórico
- **Limpieza de datos**: Eliminación de registros sin medición de velocidad

## tb_gps_historial_eventos_202509161626(1).csv

```{r getData6, eval=FALSE, include=FALSE}
# tb_gps_historial_eventos_202509161626(1).csv
gps.events <- read_file("data/tb_gps_historial_eventos_202509161626(1).csv") %>% str_replace_all(., "\";\"", " ") %>% str_replace_all(., ",", ";") %>% str_replace_all(., "\"", "") %>% read.table(text = ., sep = ";", header = T, stringsAsFactors = F)
gps.events <- gps.events %>% select(-c(ubicacion_, velocidad_))
gps.events$fecha_auto <- gps.events$fecha_auto %>% as.POSIXct(format = "%Y-%m-%d %H:%M:%S")
gps.events$fecha_gps_ <- gps.events$fecha_gps_ %>% as.POSIXct(format = "%Y-%m-%d %H:%M:%S")
gps.events$evento_ <- gps.events$evento_ %>% as.factor()
gps.events$direccion_ <- gps.events$direccion_ %>% as.factor()
gps.events %>% nrow()
gps.events %>% summary()
gps.events.sf <- gps.events %>% st_as_sf(
  coords = c("longitud_", "latitud_"),
  crs = 4326
)
gps.events.sf %>% st_write(.,
  "~/GitHub/data-sets-analysis/shapefiles/gps.events.shp",
  driver = "ESRI Shapefile",
  append = F
)
```

El dataset contiene 1000 eventos registrados por sistemas GPS vehiculares, capturando transiciones de estado en una ventana temporal específica.

### Período de Monitoreo

- **Fecha de referencia**: Transición año nuevo 2024-2025
- **Según timestamp del auto**: 1 de enero de 2025, 00:00:06 - 01:06:29 (66 minutos)
- **Según timestamp del GPS**: 31 de diciembre de 2024, 23:59:22 - 1 de enero de 2025, 01:06:49 (67 minutos)
- **Discrepancia temporal**: Diferencia de sincronización entre sistemas de aproximadamente 1 minuto

### Distribución de Estados Vehiculares

**Tipos de eventos registrados**:

- **Apagado**: 552 eventos - vehículo sin operación
- **Detenido**: 264 eventos - vehículo inmovilizado pero encendido
- **Movimiento**: 184 eventos - vehículo en desplazamiento

### Patrones de Direccionalidad

**Valores de dirección registrados**:

- `0`: 316 casos
- `-280`: 184 casos
- `-223`: 184 casos
- `-85`: 184 casos
- `235`: 132 casos

**Observación**: Los valores negativos y positivos sugieren un sistema de coordenadas o ángulos específico.

### Aspectos Requieren Investigación

**Variables Críticas por Clarificar**

- `id_evento`: Valor constante `2` en todos los registros
- `direccion_`:
    - Sistema de representación angular (grados) o coordenadas relativas
    - Significado de valores negativos vs. positivos
    - Relación con puntos cardinales o sistema de referencia

### Procesamiento y Normalización de Datos

**Paso a paso**

- Se eliminan las columnas "ubicacion_" y "velocidad_" debido a que todos sus valores son nulos
- "fecha_auto" se convierte en un POSIXct con formato "%Y-%m-%d %H:%M:%S"
- "fecha_gps_" se convierte en un POSIXct con formato "%Y-%m-%d %H:%M:%S"
- "evento_" se convierte en factor
- "direccion_" se convierte en factor

**Corrección de Formato de Archivo**

- **Problema original**: Formato CSV con delimitadores inconsistentes y caracteres de escape
- **Transformación aplicada**:
    - Reemplazo de ";" por espacio para unificación
    - Sustitución de , por ; como nuevo delimitador
    - Eliminación de comillas redundantes
- **Resultado**: Estructura tabular legible para importación

**Optimización de Estructura de Datos**

- **Eliminación de columnas vacías**: `ubicacion_` y `velocidad_` removidas por contener exclusivamente valores nulos
- **Normalización temporal**:
    - `fecha_auto` y `fecha_gps_` convertidas a formato datetime
    - Preservación de precisiones de segundos
- **Tipificación categórica**:
    - `evento_` y `direccion_` convertidas a factor para análisis estadístico

## Inventario CCTV Biobío(1).xlsx

```{r getData8, eval=FALSE, include=FALSE}
# Inventario CCTV Biobío(1).xlsx
biobio.inventary <- read_excel("data/Inventario CCTV Biobío(1).xlsx", 
    range = "A2:Q73", na = "----")
colnames(biobio.inventary) <- ifelse(
  grepl("\\...", biobio.inventary %>% colnames()),
  paste((biobio.inventary %>% colnames() %>% str_split_fixed("\\...", n = 2) %>% as.matrix() %>% {.[. == ""] <- NA; .})[, 1], ifelse((biobio.inventary %>% colnames() %>% str_split_fixed("\\...", n = 2) %>% as.matrix() %>% {.[. == ""] <- NA; .})[, 2] %>% as.numeric() <= 11, "DE LA CÁMARA", "DEL CODIFICADOR DE VIDEO")),
  biobio.inventary %>% colnames()
)
biobio.inventary$COMUNA <- biobio.inventary$COMUNA %>% as.factor()
biobio.inventary$ESTADO <- biobio.inventary$ESTADO %>% as.factor()
biobio.inventary$`TIPO DE ENLACE` <- biobio.inventary$`TIPO DE ENLACE` %>% as.factor()
biobio.inventary$PROVEEDOR <- biobio.inventary$PROVEEDOR %>% as.factor()
biobio.inventary$`MARCA DE LA CÁMARA` <- biobio.inventary$`MARCA DE LA CÁMARA` %>% as.factor()
biobio.inventary$`MODELO DE LA CÁMARA` <- biobio.inventary$`MODELO DE LA CÁMARA` %>% as.factor()
biobio.inventary$`MARCA DEL CODIFICADOR DE VIDEO` <- biobio.inventary$`MARCA DEL CODIFICADOR DE VIDEO` %>% as.factor()
biobio.inventary$`MODELO DEL CODIFICADOR DE VIDEO` <- biobio.inventary$`MODELO DEL CODIFICADOR DE VIDEO` %>% as.factor()
biobio.inventary$REGIÓN <- biobio.inventary$REGIÓN %>% as.factor()
biobio.inventary %>% summary()
biobio.inventary.sf <- biobio.inventary %>% st_as_sf(
  coords = c("LONGITUD", "LATITUD"),
  crs = 4326
)
biobio.inventary.sf %>% st_write(.,
  "~/GitHub/data-sets-analysis/shapefiles/biobio.inventary.shp",
  driver = "ESRI Shapefile",
  append = F
)
```

El inventario documenta 71 ubicaciones de cámaras de vigilancia y sus respectivos sistemas de codificación de video desplegados en la Región del Biobío, representando la infraestructura de monitoreo vial regional.

### Distribución Geográfica

- **Comunas con mayor cobertura**:
    - **Concepción**: 31 cámaras
    - **San Pedro de la Paz**: 16 cámaras
    - **Los Ángeles**: 10 cámaras
- **Cobertura regional**: Múltiples comunas del Biobío con sistemas CCTV

### Estado Operacional del Sistema

- **Cámaras online**: 32 unidades
- **Cámaras offline**: 39 unidades
- **Disponibilidad general**: Sistema operando con 45% de disponibilidad inmediata

### Características Técnicas de la Infraestructura

**Conectividad y Proveedores**

- **Tipo de enlace**: 100% digital (71/71 cámaras)
- **Proveedor de servicios**: Exclusivamente "Red Comunicaciones Propia" (71/71)

**Especificaciones de Cámaras**

*Marcas predominantes*:

- Pelco: 38 cámaras
- Avigilon: 10 cámaras
- Axis: 10 cámaras

*Modelos más frecuentes*:

- Pelco Esprit: 27 unidades
- Avigilon 2.0C-H5A-RGDPTZ-DP36: 10 unidades
- Axis AXIS Q8685-E: 10 unidades

**Sistema de Codificación de Video**

*Codificadores identificados*:

- Axis AXIS Q7401: 26 unidades
- Sin especificar: 45 unidades - posiblemente integrados en cámaras o no documentados

### Evolución Temporal del Sistema

- **Rango de integración**: 1 de noviembre de 2003 - 1 de septiembre de 2024
- **Vida útil del sistema**: Más de 20 años de despliegue progresivo
- **Actualizaciones recientes**: Integraciones hasta septiembre 2024

### Procesamiento y Normalización de Datos

**Paso a paso**

- Las columnas "MARCA", "MODELO" y "NÚMERO DE SERIE" estaban duplicadas, por lo que se les agregó "DE LA CÁMARA" y "DEL CODIFICADOR DE VIDEO" para distinguirlos
- "COMUNA" se convierte en factor
- "ESTADO" se convierte en factor
- "TIPO DE ENLACE" se convierte en factor
- "PROVEEDOR" se convierte en factor
- "MARCA DE LA CÁMARA" se convierte en factor
- "MODELO DE LA CÁMARA" se convierte en factor
- "MARCA DEL CODIFICADOR DE VIDEO" se convierte en factor
- "MODELO DEL CODIFICADOR DE VIDEO" se convierte en factor
- "REGIÓN" se convierte en factor

**Corrección de Estructura de Columnas**:

- **Problema original**: Columnas duplicadas "MARCA", "MODELO" y "NÚMERO DE SERIE" para cámara y codificador
- **Solución aplicada**:
    - Diferenciación clara mediante sufijos "DE LA CÁMARA" y "DEL CODIFICADOR DE VIDEO"
    - Asignación basada en posición original en el dataset (columnas 1-11: cámara, 12-17: codificador)

**Optimización para Análisis**:

- **Normalización categórica**: Conversión de 9 variables clave a tipo factor:
    - COMUNA
    - ESTADO
    - TIPO DE ENLACE
    - PROVEEDOR
    - MARCA DE LA CÁMARA
    - MODELO DE LA CÁMARA
    - MARCA DEL CODIFICADOR
    - MODELO DEL CODIFICADOR
    - REGIÓN
- **Manejo de valores faltantes**: Identificación explícita de valores "----" como NA

## Alertas de Tráfico.csv

```{r getData7, eval=FALSE, include=FALSE}
# Alertas de Tráfico.csv
trafic.alerts <- read_csv("data/Alertas de Tráfico.csv")
trafic.alerts <- trafic.alerts %>% mutate(
  lng = str_extract(Location, "(?<=Point\\()-?\\d+\\.?\\d*") %>% as.numeric(),
  lat = str_extract(Location, "-?\\d+\\.?\\d*(?=\\)$)") %>% as.numeric()
)
trafic.alerts <- trafic.alerts %>% select(-Location)
trafic.alerts$Date <- trafic.alerts$Date %>% str_replace_all(., setNames(
  c("jan", "feb", "mar", "apr", "may", "jun", "jul", "aug", "sep", "oct", "nov", "dec"),
  c("ene", "feb", "mar", "abr", "may", "jun", "jul", "ago", "sep", "oct", "nov", "dic")
)) %>% dmy()
trafic.alerts$Country <- trafic.alerts$Country %>% as.factor()
trafic.alerts$City <- trafic.alerts$City %>% as.factor()
trafic.alerts$Type <- trafic.alerts$Type %>% as.factor()
trafic.alerts$Subtype <- trafic.alerts$Subtype %>% as.factor()
trafic.alerts %>% summary()
trafic.alerts.sf <- trafic.alerts %>% st_as_sf(
  coords = c("lng", "lat"),
  crs = 4326
)
trafic.alerts.sf %>% st_write(.,
  "~/GitHub/data-sets-analysis/shapefiles/trafic.alerts.shp",
  driver = "ESRI Shapefile",
  append = F
)
```

El dataset comprende 281759 alertas de tráfico generadas por usuarios de Waze, representando un año completo de reportes ciudadanos sobre condiciones viales en el Gran Concepción.

### Período de Análisis

- **Cobertura temporal**: 23 de junio de 2023 - 15 de mayo de 2024
- **Duración**: Aproximadamente 11 meses de datos continuos
- **Registros diarios promedio**: \~850 alertas por día

### Contexto Geográfico

- **Distribución por ciudad**:
    - Concepción: 130747 alertas
    - San Pedro de la Paz: 51816 alertas
    - Talcahuano: 35122 alertas
    - Otras comunas: 64074 alertas

### Clasificación de Alertas

**Categorías Principales (Type)**

- **Embottellamiento (JAM)**: 178785 casos
- **Peligro (HAZARD)**: 53457 casos
- **Peligro meteorológico (WEATHERHAZARD)**: 35984 casos
- **Otras categorías**: 13533 casos

**Especificaciones por Subcategoría (Subtype)**

*Embottellamientos (JAM)*:

- Tráfico intenso (JAM_HEAVY_TRAFFIC): 77179 casos
- Tráfico paralizado (JAM_STAND_STILL_TRAFFIC): 52298 casos
- Tráfico moderado (JAM_MODERATE_TRAFFIC): 20947 casos

*Peligros (HAZARD)*:

- Vehículo detenido en franja lateral (HAZARD_ON_SHOULDER_CAR_STOPPED): 15869 casos
- Construcción en la vía (HAZARD_ON_ROAD_CONSTRUCTION): 9458 casos
- Peligro en la vía (HAZARD_ON_ROAD): 7494 casos
- Otros peligros: 20636 casos

*Peligros meteorológicos (WEATHERHAZARD)*:

- Vehículo detenido (HAZARD_ON_ROAD_CAR_STOPPED): 9467 casos
- Construcción en la vía (HAZARD_ON_ROAD_CONSTRUCTION): 6287 casos
- Vehículo detenido en franja lateral (HAZARD_ON_SHOULDER_CAR_STOPPED): 6097 casos
- Otros peligros meteorológicos: 14133 casos

### Procesamiento y Normalización de Datos

**Paso a paso**

- La columna "Location" se separa en "lng" y "lat" mediante los regex `"(?<=Point\\()-?\\d+\\.?\\d*"` y `"-?\\d+\\.?\\d*(?=\\)$)"`, respectivamente
- Se elimina la columna "Location"
- En la columna "Date", se reemplazan los valores "ene", "feb", "mar", "abr", "may", "jun", "jul", "ago", "sep", "oct", "nov" y "dic" por "jan", "feb", "mar", "apr", "may", "jun", "jul", "aug", "sep", "oct", "nov" y "dec", respectivamente
- "Country" se convierte en factor
- "City" se convierte en factor
- "Type" se convierte en factor
- "Subtype" se convierte en factor

**Transformación de Coordenadas Geográficas**

- **Problema original**: Campo "Location" en formato WKT (Well-Known Text): `Point(lng lat)`
- **Solución aplicada**:
    - Extracción de longitud (`lng`) mediante regex: `(?<=Point\\()-?\\d+\\.?\\d*`
    - Extracción de latitud (`lat`) mediante regex: `-?\\d+\\.?\\d*(?=\\)$)`
    - Conversión a tipos numéricos para análisis espacial

**Normalización de Fechas**

- **Formato original**: Día-Mes-Año con abreviaturas en español
- **Conversión aplicada**:
    - Mapeo de abreviaturas españolas a inglesas: `{"ene":"jan", "feb":"feb", ..., "dic":"dec"}`
    - Transformación a formato Date usando `dmy()`

**Optimización para Análisis**

- **Tipificación categórica**: Conversión a factor de 4 variables clave:
    - Country
    - City
    - Type
    - Subtype
- Eliminación de redundancias: Remoción de columna "Location" original
- Estructura final: Dataset con 281759 registros × 8 columnas optimizadas

## Copia de Accidentes.csv

```{r getData9, eval=FALSE, include=FALSE}
# Copia de Accidentes.csv
accidents <- read_csv("data/Copia de Accidentes.csv")
accidents <- accidents %>% mutate(
  lng = str_extract(Location, "(?<=Point\\()-?\\d+\\.?\\d*") %>% as.numeric(),
  lat = str_extract(Location, "-?\\d+\\.?\\d*(?=\\)$)") %>% as.numeric()
)
accidents <- accidents %>% select(-Location)
accidents$Date <- accidents$Date %>% str_replace_all(., setNames(
  c("jan", "feb", "mar", "apr", "may", "jun", "jul", "aug", "sep", "oct", "nov", "dec"),
  c("ene", "feb", "mar", "abr", "may", "jun", "jul", "ago", "sep", "oct", "nov", "dic")
)) %>% dmy()
accidents$Country <- accidents$Country %>% as.factor()
accidents$City <- accidents$City %>% as.factor()
accidents %>% summary()
accidents.sf <- accidents %>% st_as_sf(
  coords = c("lng", "lat"),
  crs = 4326
)
accidents.sf %>% st_write(.,
  "~/GitHub/data-sets-analysis/shapefiles/accidents.shp",
  driver = "ESRI Shapefile",
  append = F
)
```

El dataset contiene 281981 registros de accidentes de tránsito, proporcionando una visión detallada de la siniestralidad vial en el Gran Concepción durante un período de 11 meses.

### Período de Monitoreo

- **Cobertura temporal**: 23 de junio de 2023 - 15 de mayo de 2024
- **Duración**: 327 días de reportes continuos
- **Densidad de datos**: \~862 accidentes reportados por día en promedio

### Contexto Geográfico

- **Distribución por ciudad**:
    - Concepción: 130516 alertas
    - San Pedro de la Paz: 51704 alertas
    - Talcahuano: 35059 alertas
    - Otras comunas: 64702 alertas

### Métricas de Confiabilidad

- **Rango de fiabilidad**: 5 a 10 puntos (escala no especificada)
- **Fiabilidad promedio**: 5.82 puntos
- **Fiabilidad mediana**: 5 puntos
- **Distribución**: Sesgada hacia valores bajos-medios de la escala

### Procesamiento y Normalización de Datos

**Paso a paso**

- La columna "Location" se separa en "lng" y "lat" mediante los regex `"(?<=Point\\()-?\\d+\\.?\\d*"` y `"-?\\d+\\.?\\d*(?=\\)$)"`, respectivamente
- Se elimina la columna "Location"
- En la columna "Date", se reemplazan los valores "ene", "feb", "mar", "abr", "may", "jun", "jul", "ago", "sep", "oct", "nov" y "dic" por "jan", "feb", "mar", "apr", "may", "jun", "jul", "aug", "sep", "oct", "nov" y "dec", respectivamente
- "Country" se convierte en factor
- "City" se convierte en factor

**Transformación de Georreferenciación**

- **Formato original**: Campo "Location" en estándar WKT (Well-Known Text)
- **Metodología de extracción**:
    - Longitud (`lng`): Patrón regex `(?<=Point\\()-?\\d+\\.?\\d*`
    - Latitud (`lat`): Patrón regex `-?\\d+\\.?\\d*(?=\\)$)`
- **Resultado**: Coordenadas decimales para análisis geoespacial avanzado

**Estandarización de Fechas**

- **Problema identificado**: Nomenclatura de meses en español
- **Solución implementada**:
    - Mapeo sistemático: `{"ene":"jan", "feb":"feb", ..., "dic":"dec"}`
    - Conversión robusta mediante función `dmy()`
- **Output**: Timeline consistente para análisis temporal

**Optimización de Estructura de Datos**

- **Eliminación de redundancias**: Remoción de columna "Location" original
- **Normalización categórica**:
    - `Country` y `City` convertidas a tipo factor
    - Habilitación de análisis agregados por ubicación
- **Dataset final**: 281981 registros × 7 columnas optimizadas

## Waze for Cities Data Key Alerts Dashboard_Traffic Irregularities_Tabla(1).csv

```{r getData10, eval=FALSE, include=FALSE}
# Waze for Cities Data Key Alerts Dashboard_Traffic Irregularities_Tabla(1).csv
waze.data <- read_csv("data/Waze for Cities Data Key Alerts Dashboard_Traffic Irregularities_Tabla(1).csv", 
    na = "null")
waze.data$Day <- waze.data$Day %>% str_replace_all(., setNames(
  c("jan", "feb", "mar", "apr", "may", "jun", "jul", "aug", "sep", "oct", "nov", "dec"),
  c("ene", "feb", "mar", "abr", "may", "jun", "jul", "ago", "sep", "oct", "nov", "dic")
)) %>% dmy()
waze.data$Country <- waze.data$Country %>% as.factor()
waze.data$City <- waze.data$City %>% as.factor()
waze.data$Street <- waze.data$Street %>% as.factor()
waze.data$Cause <- waze.data$Cause %>% as.factor()
waze.data %>% summary()
```

El dataset contiene 13502 registros de irregularidades de tráfico documentadas a través de la plataforma Waze for Cities, proporcionando métricas detalladas sobre el impacto de incidentes viales en la Región del Biobío durante un período de 11 meses.

### Período de Análisis

- **Cobertura temporal**: 23 de junio de 2023 - 15 de mayo de 2024
- **Duración**: 327 días de monitoreo continuo
- **Frecuencia promedio**: \~41 irregularidades reportadas por día

### Distribución Geográfica

- **Concentración por ciudad**:
    - Concepción: 4236 registros
    - Los Ángeles: 3484 registros
    - San Pedro de la Paz: 2190 registros
    - Otras localidades: 3592 registros

### Clasificación por Causas Identificadas

- **Accidentes (ACCIDENT)**: 839 casos
- **Peligros en la vía (HAZARD)**: 826 casos
- **Carreteras cerradas (ROAD_CLOSED)**: 3 casos
- **Causa no especificada**: 11834 casos

### Métricas de Impacto de Tráfico

**Longitud de Afectación Vial**

- **Rango**: 500 m - 16.61 km
- **Longitud promedio**: 1.34 km
- **Mediana**: 947 m
- **Distribución**: Sesgo hacia afectaciones de mediana extensión

**Tiempos de Desfase**

- **Rango**: 1 minuto 7.33 segundos - 6 horas 27 minutos 26 segundos
- **Desfase promedio**: 11 minutos 4.97 segundos
- **Mediana**: 9 minutos 18.25 segundos
- **Significado**: Retrasos significativos en la movilidad urbana

**Impacto en Usuarios**

- **Usuarios afectados (Impacted Wazers)**: 1 - 122563 personas
- **Promedio de afectados**: 2033 usuarios por incidente
- **Mediana**: 465 usuarios
- **Distribución**: Alta variabilidad con eventos masivos ocasionales

### Procesamiento y Normalización de Datos

**Paso a paso**

- En la columna "Date", se reemplazan los valores "ene", "feb", "mar", "abr", "may", "jun", "jul", "ago", "sep", "oct", "nov" y "dic" por "jan", "feb", "mar", "apr", "may", "jun", "jul", "aug", "sep", "oct", "nov" y "dec", respectivamente
- "Country" se convierte en factor
- "City" se convierte en factor
- "Street" se convierte en factor
- "Cause" se convierte en factor

**Estandarización Temporal**

- **Formato original**: Fechas con nomenclatura de meses en español
- **Transformación aplicada**:
    - Mapeo sistemático: `{"ene":"jan", "feb":"feb", ..., "dic":"dec"}`
    - Conversión a formato Date mediante `dmy()`
- **Resultado**: Timeline consistente para análisis diario y estacional

**Optimización de Estructura de Datos**

- **Manejo de valores nulos**: Identificación explícita de "null" como NA
- **Normalización categórica**:
    - `Country`, `City`, `Street`, `Cause` convertidas a tipo factor
    - Habilitación de análisis agregados por múltiples dimensiones
- **Dataset final**: 13502 registros × 8 columnas optimizadas

## Red de Waze

```{r getData11, eval=FALSE, include=FALSE}
json.route <- "data/json"
folders <- json.route %>% list.dirs(recursive = F) %>% basename()
routes.list <- list()
folder.time.list <- list()
subfolder.time.list <- list()
file.time.list <- list()
for(folder in folders){
  folder.start.sys <- Sys.time()
  subfolders <- paste(json.route, folder, sep = "/") %>% list.dirs(recursive = F) %>% basename()
  for(subfolder in subfolders){
    subfolder.start.sys <- Sys.time()
    base.routes <- paste(json.route, folder, subfolder, sep = "/") %>% list.files(full.names = T)
    for(base.route in base.routes){
      file.start.sys <- Sys.time()
      json <- fromJSON(file = base.route)
      routes.data <- json$routes %>% lapply(., function(route) {
        new.row <- route[!names(route) %in% c("line", "bbox", "subRoutes", "leadAlert", "alternateRoute")]
        if(!(route$leadAlert %>% is.null())){
          new.row$leadAlert.numComments <- route$leadAlert$numComments
          new.row$leadAlert.city <- route$leadAlert$city
          new.row$leadAlert.externalImageId <- route$leadAlert$externalImageId
          new.row$leadAlert.numThumbsUp <- route$leadAlert$numThumbsUp
          new.row$leadAlert.street <- route$leadAlert$street
          new.row$leadAlert.subType <- route$leadAlert$subType
          new.row$leadAlert.id <- route$leadAlert$id
          new.row$leadAlert.position <- route$leadAlert$position
          new.row$leadAlert.type <- route$leadAlert$type
          new.row$leadAlert.numNotThereReports <- route$leadAlert$numNotThereReports
        } else {
          new.row$leadAlert.numComments <- NA
          new.row$leadAlert.city <- NA
          new.row$leadAlert.externalImageId <- NA
          new.row$leadAlert.numThumbsUp <- NA
          new.row$leadAlert.street <- NA
          new.row$leadAlert.subType <- NA
          new.row$leadAlert.id <- NA
          new.row$leadAlert.position <- NA
          new.row$leadAlert.type <- NA
          new.row$leadAlert.numNotThereReports <- NA
        }
        if(!(route$bbox %>% is.null())) {
          new.row$minY <- route$bbox$minY
          new.row$minX <- route$bbox$minX
          new.row$maxY <- route$bbox$maxY
          new.row$maxX <- route$bbox$maxX
        } else {
          new.row$minY <- NA
          new.row$minX <- NA
          new.row$maxY <- NA
          new.row$maxX <- NA
        }
        if(!(route$line %>% is.null()) && route$line %>% length() > 0) {
          route$line %>% seq_along() %>% lapply(., function(i) {
            row <- new.row
            row$x <- route$line[[i]]$x
            row$y <- route$line[[i]]$y
            row$point_index <- i
            row$total_points <- route$line %>% length()
            return(row %>% as.data.frame(stringsAsFactors = F))
          })
        } else {
          row <- new.row
          row$x <- NA
          row$y <- NA
          row$point_index <- NA
          row$total_points <- NA
          list(row %>% as.data.frame(stringsAsFactors = F))
        }
      })
      df.routes <- rbind %>% do.call(., routes.data %>% unlist(recursive = F))
      df.routes$speed <- df.routes$length / df.routes$time
      df.routes$broadcasterId <- json$broadcasterId
      df.routes$areaName <- json$areaName
      df.routes$isMetric <- json$isMetric
      df.routes$updateTime <- json$updateTime
      df.routes$date <- gsub("_", "-", folder)
      df.routes$subfolder <- subfolder
      file <- gsub(".json", "", (base.route %>% basename() %>% str_split(pattern = "_"))[[1]][3])
      df.routes$file <- file
      routes.list[[base.route]] <- df.routes
      file.end.sys <- Sys.time()
      file.dt.sys <- file.end.sys - file.start.sys
      file.time.list[[base.route]] <- file.dt.sys
      print("File time:")
      print(base.route %>% basename())
      print(file.dt.sys)
    }
    subfolder.end.sys <- Sys.time()
    subfolder.dt.sys <- subfolder.end.sys - subfolder.start.sys
    subfolder.time.list[[paste(folder, subfolder, sep = "/")]] <- subfolder.dt.sys
    print("Subfolder time:")
    print(subfolder)
    print(subfolder.dt.sys)
  }
  folder.end.sys <- Sys.time()
  folder.dt.sys <- folder.end.sys - folder.start.sys
  folder.time.list[[folder]] <- folder.dt.sys
  print("Folder time:")
  print(folder)
  print(folder.dt.sys)
}
total.dt <- folder.time.list %>% sum.time()
# Reading Time: 2h + 31m + 41.63s
start.sys <- Sys.time()
waze.routes.df <- routes.list %>% bind_rows()
end.sys <- Sys.time()
binding.time <- end.sys - start.sys
# Binding Time: 3.78s
start.sys <- Sys.time()
waze.routes.df$toName <- waze.routes.df$toName %>% as.factor()
waze.routes.df$name <- waze.routes.df$name %>% as.factor()
waze.routes.df$fromName <- waze.routes.df$fromName %>% as.factor()
waze.routes.df$type <- waze.routes.df$type %>% as.factor()
waze.routes.df$leadAlert.city <- waze.routes.df$leadAlert.city %>% as.factor()
waze.routes.df$leadAlert.externalImageId <- waze.routes.df$leadAlert.externalImageId %>% as.factor()
waze.routes.df$leadAlert.street <- waze.routes.df$leadAlert.street %>% as.factor()
waze.routes.df$leadAlert.subType <- waze.routes.df$leadAlert.subType %>% as.factor()
waze.routes.df$leadAlert.id <- waze.routes.df$leadAlert.id %>% as.factor()
lat.lng <- function(n = 1){
  waze.routes.df$leadAlert.position %>% sapply(., function(p){
    if(p %>% is.na()) {
      return(NA)
    }
    str_split(p, " ")[[1]][n] %>% as.numeric()
  })
}
waze.routes.df$leadAlert.position.lat <- lat.lng(1)
waze.routes.df$leadAlert.position.lng <- lat.lng(2)
waze.routes.df <- waze.routes.df %>% select(-leadAlert.position)
waze.routes.df$leadAlert.type <- waze.routes.df$leadAlert.type %>% as.factor()
waze.routes.df$broadcasterId <- waze.routes.df$broadcasterId %>% as.factor()
waze.routes.df$areaName <- waze.routes.df$areaName %>% as.factor()
waze.routes.df$date <- waze.routes.df$date %>% as.POSIXct(format = "%d-%m-%Y")
waze.routes.df$subfolder <- waze.routes.df$subfolder %>% as.factor()
waze.routes.df$file <- waze.routes.df$file %>% as.factor()
waze.routes.df$updateTime <- (waze.routes.df$updateTime / 1000) %>% as.POSIXct(origin = "1970-01-01", tz = "UTC")
waze.routes.df$weekday <- waze.routes.df$updateTime %>% weekdays() %>% as.factor()
end.sys <- Sys.time()
modifying.time <- end.sys - start.sys
# Modifying Time: 2m + 41.69s
waze.routes.df %>% summary()
waze.routes <- waze.routes.df %>% distinct(id, date, file, .keep_all = T) %>% select(-x, -y, -point_index)
waze.routes %>% summary()
waze.routes.df.short <- waze.routes.df %>%
  rename(
    alert_lat = leadAlert.position.lat,
    alert_lng = leadAlert.position.lng,
    alert_city = leadAlert.city,
    alert_img = leadAlert.externalImageId,
    alert_strt = leadAlert.street,
    alert_sub = leadAlert.subType,
    alert_id = leadAlert.id,
    alert_type = leadAlert.type,
    alert_com = leadAlert.numComments,
    alert_thumbs = leadAlert.numThumbsUp,
    alert_notthere = leadAlert.numNotThereReports,
    date_str = date
  )
waze.routes.df.short$date_str <- waze.routes.df.short$date_str %>% as.character()
waze.routes.df.sf <- waze.routes.df.short %>% st_as_sf(
  coords = c("x", "y"),
  crs = 4326
)
waze.routes.df.sf %>% st_write(.,
  "~/GitHub/data-sets-analysis/shapefiles/waze.routes.df.shp",
  driver = "ESRI Shapefile",
  append = F,
  delete_dsn = T
)
create.bbox.polygons <- function(df){
  polygons.list <- list()
  for (i in df %>% nrow() %>% seq_len()) {
    minX <- df$minX[i]
    minY <- df$minY[i]
    maxX <- df$maxX[i]
    maxY <- df$maxY[i]
    if (c(minX, minY, maxX, maxY) %>% is.na() %>% any()) {
      next
    }
    polygon.coords <- matrix(c(
      minX, minY,
      minX, maxY,
      maxX, maxY,
      maxX, minY,
      minX, minY
    ), ncol = 2, byrow = TRUE)
    polygon <- polygon.coords %>% list() %>% st_polygon()
    polygons.list[[i]] <- polygon
  }
  valid.rows <- !sapply(polygons.list, is.null)
  df.valid <- df[valid.rows, ]
  df.sf <- df.valid %>% st_sf(geometry = polygons.list[valid.rows] %>% st_sfc(crs = 4326)) %>% select(-minX, -minY, -maxX, -maxY)
  return(df.sf)
}
waze.routes.polygons <- waze.routes %>% create.bbox.polygons() %>%
  rename(
    alert_lat = leadAlert.position.lat,
    alert_lng = leadAlert.position.lng,
    alert_city = leadAlert.city,
    alert_img = leadAlert.externalImageId,
    alert_strt = leadAlert.street,
    alert_sub = leadAlert.subType,
    alert_id = leadAlert.id,
    alert_type = leadAlert.type,
    alert_com = leadAlert.numComments,
    alert_thumbs = leadAlert.numThumbsUp,
    alert_notthere = leadAlert.numNotThereReports,
    date_str = date
  )
waze.routes.polygons %>% st_write(
  dsn = "~/GitHub/data-sets-analysis/shapefiles",
  layer = "waze.routes",
  driver = "ESRI Shapefile",
  append = F,
  delete_dsn = T
)

# Mapa de calor (Velocidad, tramo x hora)
## Datos de Carrera y Pedro Aguirre Cerda
## Martes y miércoles, respectivamente
waze.routes.df %>% summary()
waze.routes.heatmap <- waze.routes.df[
  waze.routes.df$weekday %in% c("martes", "miércoles") &
  (
    grepl("Av. Los Carrera", waze.routes.df$name) |
    grepl("Av. Pedro Aguirre Cerda", waze.routes.df$name)
  ),
]
waze.routes.heatmap$hour <- waze.routes.heatmap$updateTime %>% hour()
waze.routes.heatmap$placeName <- NA
for(n in c(waze.routes.heatmap$toName %>% levels(), waze.routes.heatmap$fromName %>% levels())){
  waze.routes.heatmap$placeName[grepl(n, waze.routes.heatmap$name)] <- n
}
waze.routes.heatmap$placeName <- waze.routes.heatmap$placeName %>% as.factor()
waze.routes.heatmap$dirName <- NA
for(n in c("O.P", "P.O")){
  waze.routes.heatmap$dirName[grepl(n, waze.routes.heatmap$name)] <- n
}
waze.routes.heatmap$dirName <- waze.routes.heatmap$dirName %>% as.factor()
waze.routes.heatmap$placeName %>% summary()

display.heat.map = function(placeName = "Av. Los Carrera", dirName = "O.P") {
  waze.routes.heatmap[waze.routes.heatmap$placeName == placeName & waze.routes.heatmap$dirName == dirName,] %>%
    group_by(name, hour) %>%
    summarise(speed = mean(speed, na.rm = T)) %>%
    ungroup() %>% 
    ggplot() +
    geom_tile(aes(
      x = name,
      y = hour,
      fill = speed
    )) +
    scale_fill_gradientn(
      colors = c(
        "red",
        "orange",
        "yellow",
        "lightgreen",
        "darkgreen"
      )
    ) +
    labs(title = paste("Mapa de calor en", placeName, "en dirección", dirName))
}

for(placeName in waze.routes.heatmap$placeName %>% levels()){
  for(dirName in waze.routes.heatmap$dirName %>% levels()){
    display.heat.map(placeName, dirName) %>% print()
  }
}
```

El sistema procesó 491736 registros de datos de rutas provenientes de la API de Waze, consolidando información de navegación y alertas de tráfico durante un período de 21 días.

### Metadatos de Procesamiento

- **Tiempo de lectura**: 2 horas, 31 minutos, 41.63 segundos 2h + 31m + 41.63s
- **Tiempo de unión**: 3.78 segundos 3.78s
- **Tiempo de transformación**: 2 minuto, 41.69 segundos 2m + 41.69s
- **Total de procesamiento**: 2 horas, 34 minutos, 27.10 segundos

### Período de Monitoreo

- **Fecha inicial**: 24 de noviembre de 2025 a las 15:31:51
- **Fecha final**: 15 de diciembre de 2025 a las 20:12:08
- **Duración**: 21 días completos
- **Estructura temporal**: Datos organizados por fecha en estructura de carpetas

### Características del Dataset Consolidado

**Volumen y Estructura**

- **Registros totales**: 2821625 puntos de ruta
- **Rutas únicas (agrupadas)**: 491736 rutas
- **Nivel de detalle**: Desagregación punto por punto de trayectos

**Análisis de Orígenes y Destinos**

*Principales Destinos* (`toName`)

- "Av. Los Carrera": 316116 referencias
- "Av. Pedro Aguirre Cerda": 70248 referencias
- "Ruta 160": 35124 referencias

*Principales Orígenes* (`fromName`)

- "Av. Los Carrera": 327824 referencias
- "Av. Pedro Aguirre Cerda": 76102 referencias
- "Ruta 160": 29270 referencias

**Métricas de Desempeño de Rutas**

*Tiempos de Viaje*

- **Tiempo histórico** (`historicTime`): 1-344 unidades (media: 20.74, mediana: 13)
- **Tiempo estimado** (`time`): 0-952 unidades (media: 26.96, mediana: 16)
- **Unidades por confirmar**: Minutos o segundos (requiere validación)

*Distancias y Velocidades*
- **Longitud de ruta** (`length`): 0-1257 unidades (media: 175.4, mediana: 126)
- **Velocidad calculada** (`speed`): 0.52-24 unidades (media: 8.06, mediana: 7.89)
- **Relación distancia/tiempo**: Consistente con tráfico urbano congestionado

**Sistema de Alertas Waze**

*Distribución de Alertas*

- **Total de alertas registradas**: 209

*Tipología de Alertas* (`leadAlert.type`)

**Peligros (HAZARD) - 107 casos**:

- `HAZARD_ON_ROAD`: 58 casos
- `HAZARD_ON_ROAD_OBJECT`: 29 casos
- `HAZARD_ON_ROAD_TRAFFIC_LIGHT_FAULT`: 9 casos
- `HAZARD_ON_ROAD_CONSTRUCTION`: 6 casos
- `HAZARD_ON_ROAD_CAR_STOPPED`: 4 casos

**Accidentes (ACCIDENT) - 94 casos**:

- `NO_SUBTYPE`: 88 casos
- `ACCIDENT_MAJOR`: 6 casos

*Interacción de Usuarios con Alertas*

- **Comentarios** (`numComments`): 0-48 (media: 8.0, mediana: 3)
- **Me gusta** (`numThumbsUp`): 0-46 (media: 7.5, mediana: 3)
- **Reportes de inexistencia** (`numNotThereReports`): 0 (120 casos)  y 1 (89 casos)

*Contexto Geográfico de Alertas*

- **Calles más reportadas**:
  - "Ruta 160": 132 alertas
  - "Av. Pedro Aguirre Cerda": 65 alertas
  - "Av. Los Carrera Poniente": 8 alertas
  - "Av. Los Carrera": 4 alertas
- **Ciudades involucradas**:
  - "San Pedro de la Paz": 65 alertas
  - "Concepción": 12 alertas
  - Sin especificar: 132 alertas

### Procesamiento y Normalización de Datos

**Paso a paso**

- Se leen las carpetas
- En cada carpeta, se leen las sub-carpetas
- En cada sub-capreta, se leen los archivos .json
- En cada archivo, se leen las rutas
- Por cada ruta, se crea la fila con todos sus valores, excepto "line", "bbox", "subRoutes", "leadAlert" y "alternateRoute"
- Si "leadAlert" no es nulo, las columnas "leadAlert.numComments", "leadAlert.city", "leadAlert.externalImageId", "leadAlert.numThumbsUp", "leadAlert.street", "leadAlert.subType", "leadAlert.id", "leadAlert.position", "leadAlert.type" y "leadAlert.numNotThereReports" toman los valores de "numComments", "city", "externalImageId", "numThumbsUp", "street", "subType", "id", "position", "type" y "numNotThereReports", respectivamente de "leadAlert"
- Si "bbox" no es nulo, las columnas "minY", "minX", "maxY" y "maxX" toman los valores de "minY", "minX", "maxY" y "maxX" de "bbox", respectivamente
- Si "line" no es nulo, se clona la fila una vez por cada elemento en "line", por cada punto, "x" e "y" toman el valor de "x" e "y", respectivamente del elemento de "line", "point_index", la posición del punto en "line" y "total_points", la cantidad de puntos en "line"
- Se unen las filas en un data.frame
- Se crea la columna "speed" con el valor de "lenght" / "time"
- Se crea la columna "broadcasterId" con el valor de "broadcasterId" del archivo
- Se crea la columna "areaName" con el valor de "areaName" del archivo
- Se crea la columna "isMetric" con el valor de "isMetric" del archivo
- Se crea la columna "updateTime" con el valor de "updateTime" del archivo
- Se crea la columna "date" con el nombre de la carpeta
- Se crea la columna "subfolder" con el nombre de la sub-carpeta
- Se crea la columna "file" con el nombre del archivo quitando la cadena ".json", separándolo en una lista de cadenas con el caracter "_" y tomando en último elemento (ej: "1763409379301_2025-12-01_000004.267298.json" -> "000004.267298")
- Se unen las filas en un solo data.frame
- "toName" se convierte en factor
- "name" se convierte en factor
- "fromName" se convierte en factor
- "type" se convierte en factor
- "leadAlert.city" se convierte en factor
- "leadAlert.externalImageId" se convierte en factor
- "leadAlert.street" se convierte en factor
- "leadAlert.subType" se convierte en factor
- "leadAlert.position" se divide en "leadAlert.position.lat" y "leadAlert.position.lng" separándolo por el caracter " "
- Se elimina la columna "leadAlert.position"
- "leadAlert.type" se convierte en factor
- "broadcasterId" se convierte en factor
- "areaName" se convierte en factor
- "date" se convierte en POSIXct con formato "%d-%m-%Y"
- "subfolder" se convierte en factor
- "file" se convierte en factor
- "updateTime" se divide por 1000 y se convierte en POSIXct con origen en "1970-01-01" y zona horaria "UTC"
- Se crea la columna "weekday" siendo el día de la semana de "updateTime" y se convierte en factor

**Estrategia de Extracción Multi-nivel**

- **Estructura anidada**: Carpeta -> Subcarpeta -> Archivo JSON
- **Procesamiento recursivo**: Manejo jerárquico de directorios
- **Metadatos embebidos**: Preservación de contexto organizacional

**Transformaciones Aplicadas**

*Desagregación de Geometrías de Ruta*

- **Problema original**: Arrays de coordenadas en campo `line`
- **Solución**: Expansión punto por punto con índices secuenciales
- **Campos creados**: `x`, `y`, `point_index`, `total_points`

*Normalización de Alertas*

- **Estructura compleja**: Objetos anidados en `leadAlert`
- **Aplanamiento**: Extracción de 10 subcampos críticos
- **Manejo de nulos**: Preservación de estructura para rutas sin alertas

*Metadatos de Procedencia*

- **Variables contextuales**:
  - `date`: Extraído de nombre de carpeta (formato dd-mm-aaaa)
  - `subfolder`: Categoría intermedia
  - `file`: Identificador específico del archivo

*Optimización de Tipos de Datos*

- **Factores categóricos**: 14 variables convertidas
- **Coordenadas numéricas**: Separación de latitud/longitud
- **Fechas estandarizadas**: Conversión a POSIXct

**Variables Críticas Procesadas**

- `toName`, `fromName`, `name`, `type` -> Factor
- `leadAlert.*` (10 campos) -> Normalizados
- `broadcasterId`, `areaName` -> Factor
- `date` -> POSIXct
- `speed` -> Calculada (`length`/`time`)

# Discretización de datos

```{r quantum.data, eval=FALSE, include=FALSE}
meters.per.degree.lat <- 111320

meters.per.degree.lng <- function(lat.d) {
  meters.per.degree.lat * cos(lat.d * pi / 180)
}

calculate.street.heading <- function(lng.data, lat.data) {
  n <- length(lng.data)
  headings <- numeric(n)
  for(i in 2:(n-1)) {
    dx_meters <- (lng.data[i+1] - lng.data[i-1]) * meters.per.degree.lng(lat.data[i])
    dy_meters <- (lat.data[i+1] - lat.data[i-1]) * meters.per.degree.lat
    headings[i] <- atan2(dy_meters, dx_meters)
  }
  headings[1] <- headings[2]
  headings[n] <- headings[n-1]
  
  return(headings)
}

quantum.data <- function(
  time.data = c(),
  lng.data = c(),
  lat.data = c(),
  field.data = c(),
  time.gap = 5,
  space.gap = 50,
  street.aligned = T,
  street.angle.tolerance = 30,
  compile.function = mean
) {
  if (length(unique(c(length(time.data), length(lng.data), length(lat.data), length(field.data)))) != 1) {
    stop("All vectors must have the same length")
  }
  data.df <- data.frame(
    time = time.data,
    lng = lng.data,
    lat = lat.data,
    field = field.data,
    stringsAsFactors = F
  )
  data.df <- data.df[order(data.df$time), ]
  if (street.aligned) {
    data.df$heading <- calculate.street.heading(data.df$lng, data.df$lat)
  }
  if (time.gap > 0) {
    min.time <- min(data.df$time)
    max.time <- max(data.df$time)
    time.bins <- seq(from = min.time, to = max.time, by = time.gap)
    data.df$time.bin <- cut(data.df$time, breaks = time.bins, include.lowest = T, labels = F)
    data.df$time.bin[is.na(data.df$time.bin)] <- max(data.df$time.bin, na.rm = T) + 1
  } else {
    data.df$time.bin <- 1:nrow(data.df)
  }
  if (space.gap > 0) {
    if (street.aligned) {
      lat_meters <- data.df$lat * meters.per.degree.lat
      lng_meters <- data.df$lng * meters.per.degree.lng(data.df$lat)
      data.df$x_along_street <- numeric(nrow(data.df))
      data.df$y_across_street <- numeric(nrow(data.df))
      for(i in 1:nrow(data.df)) {
        angle <- data.df$heading[i]
        rot_matrix <- matrix(c(cos(angle), sin(angle), -sin(angle), cos(angle)), nrow = 2)
        coords <- rot_matrix %*% c(lng_meters[i], lat_meters[i])
        data.df$x_along_street[i] <- coords[1]
        data.df$y_across_street[i] <- coords[2]
      }
      x_range <- range(data.df$x_along_street)
      x_bins <- seq(from = x_range[1], to = x_range[2], by = space.gap)
      data.df$x_bin <- cut(data.df$x_along_street, breaks = x_bins, include.lowest = T, labels = F)
      data.df$x_bin[is.na(data.df$x_bin)] <- max(data.df$x_bin, na.rm = T) + 1
      cross_gap <- space.gap * sin(street.angle.tolerance * pi / 180)
      y_range <- range(data.df$y_across_street)
      y_bins <- seq(from = y_range[1], to = y_range[2], by = cross_gap)
      data.df$y_bin <- cut(data.df$y_across_street, breaks = y_bins, include.lowest = T, labels = F)
      data.df$y_bin[is.na(data.df$y_bin)] <- max(data.df$y_bin, na.rm = T) + 1
      result <- data.df %>% 
        group_by(time.bin, x_bin, y_bin) %>% 
        summarise(
          time = mean(time, na.rm = T),
          lng = mean(lng, na.rm = T),
          lat = mean(lat, na.rm = T),
          field = compile.function(field, na.rm = T),
          n.points = n(),
          mean_heading = mean(heading, na.rm = T),
          .groups = 'drop'
        )
    } else {
      lat.range.meters <- range(data.df$lat) * meters.per.degree.lat
      lng_meters_temp <- data.df$lng * meters.per.degree.lng(mean(data.df$lat))
      lng.range.meters <- range(lng_meters_temp)
      lat.bins.meters <- seq(from = lat.range.meters[1], to = lat.range.meters[2], by = space.gap)
      lng.bins.meters <- seq(from = lng.range.meters[1], to = lng.range.meters[2], by = space.gap)
      lat.bins <- lat.bins.meters / meters.per.degree.lat
      lng.bins <- lng.bins.meters / meters.per.degree.lng(mean(data.df$lat))
      data.df$lat.group <- cut(data.df$lat, breaks = lat.bins, include.lowest = T)
      data.df$lng.group <- cut(data.df$lng, breaks = lng.bins, include.lowest = T)
      data.df$lat.group[is.na(data.df$lat.group)] <- max(as.numeric(data.df$lat.group), na.rm = T) + 1
      data.df$lng.group[is.na(data.df$lng.group)] <- max(as.numeric(data.df$lng.group), na.rm = T) + 1
      result <- data.df %>% 
        group_by(time.bin, lat.group, lng.group) %>% 
        summarise(
          time = mean(time, na.rm = T),
          lng = mean(lng, na.rm = T),
          lat = mean(lat, na.rm = T),
          field = compile.function(field, na.rm = T),
          n.points = n(),
          .groups = 'drop'
        )
    }
  } else {
    data.df$lat.group <- 1:nrow(data.df)
    data.df$lng.group <- 1:nrow(data.df)
    result <- data.df %>% 
      group_by(time.bin, lat.group, lng.group) %>% 
      summarise(
        time = mean(time, na.rm = T),
        lng = mean(lng, na.rm = T),
        lat = mean(lat, na.rm = T),
        field = compile.function(field, na.rm = T),
        n.points = n(),
        .groups = 'drop'
      )
  }
  if (street.aligned && space.gap > 0) {
    final.result <- data.frame(
      time = result$time,
      lng = result$lng,
      lat = result$lat,
      field = result$field,
      n.points = result$n.points,
      street_heading = result$mean_heading
    )
  } else {
    final.result <- data.frame(
      time = result$time,
      lng = result$lng,
      lat = result$lat,
      field = result$field,
      n.points = result$n.points
    )
  }
  final.result <- final.result[order(final.result$time), ]
  return(final.result)
}
```

## Descripción Matemática

La función implementa un proceso de cuantización vectorial adaptativa para datos espacio-temporales, donde la discretización espacial se alinea con la dirección de las calles. Formalmente:

$$quantum.data: \mathbb{R}^{4\times n}\times\mathbb{R}^2\times(\mathcal{P}(\mathbb{R})\to\mathbb{R})\to\mathbb{R}^{6\times m}$$

Donde:

- **Dominio**: 4 vectores de dimensión $n$ (tiempo, longitud, latitud y campo), parámetros de discretización y función de agregación
- **Codominio**: Matriz de datos discretizados con 6 atributos y $m \leq n$ puntos

## Parámetros de Entrada

- $\text{time.data} \in \mathbb{R}^n$: Vector de tiempos en segundos
- $\text{lng.data} \in \mathbb{R}^n$: Vector de longitudes en grados decimales
- $\text{lat.data} \in \mathbb{R}^n$: Vector de latitudes en grados decimales
- $\text{field.data} \in \mathbb{R}^n$: Vector de valores del campo de interés
- $\text{time.gap} \in \mathbb{R}^+$: Intervalo temporal de discretización en segundos
- $\text{space.gap} \in \mathbb{R}^+$: Intervalo espacial a lo largo de la calle en metros
- $\text{street.aligned} = \text{TRUE}$: Activa discretización alineada a calles
- $\text{street.angle.tolerance} = 30$: Tolerancia angular para agrupación transversal en grados
- $\text{compile.function}: \mathcal{P}(\mathbb{R}) \to \mathbb{R}$: Función de agregación (media, mediana, moda, máximo, mínimo, etc.)

## Proceso de Discretización

### 1. Constantes de Conversión Geográfica

Para convertir coordenadas geográficas a distancias métricas:

$$C_{lat}\equiv 111320 m/°$$

$$C_{lng}(\phi)\equiv C_{lat} \times \cos\left(\phi \times \frac{\pi}{180}\right)$$

Donde $\phi$ es la latitud en grados.

### 2. Cálculo de la Dirección de la Calle (Heading)

Para cada punto $P_i = (t_i, \lambda_i, \phi_i, v_i)$ donde:

- $t_i$: tiempo
- $\lambda_i$: longitud
- $\phi_i$: latitud
- $v_i$: valor del campo

Calculamos el ángulo de dirección $\theta_i$ usando diferencias centrales:

$$\Delta x_i^m = (\lambda_{i+1} - \lambda_{i-1}) \times C_{lng}(\phi_i)$$

$$\Delta y_i^m = (\phi_{i+1} - \phi_{i-1}) \times C_{lat}$$

$$\theta_i = \text{atan2}(\Delta y_i^m, \Delta x_i^m)$$

Donde $\text{atan2}(y, x)$ es la función arcotangente de dos argumentos que devuelve el ángulo en radianes entre el eje X positivo y el vector $(x, y)$.

### 3. Transformación al Sistema de Coordenadas de la Calle

Para cada punto $P_i = (\lambda_i, \phi_i, \theta_i)$, donde:

- $\lambda_i$: longitud en grados
- $\phi_i$: latitud en grados
- $\theta_i$: ángulo de dirección de la calle en radianes (calculado en el paso anterior)

Realizamos una transformación de coordenadas afín que alinea el sistema de referencia local con la dirección de la calle:

**3.1 Conversión a Coordenadas Métricas Cartesianas**

Primero, convertimos las coordenadas geográficas a un sistema métrico local:

$$x_i^G = \lambda_i \times C_{lng}(\phi_i)$$
$$y_i^G = \phi_i \times C_{lat}$$

Donde:

- $x_i^G$: coordenada este-oeste en metros
- $y_i^G$: coordenada norte-sur en metros
- $C_{lng}(\phi_i) = 111320 \times \cos(\phi_i \times \frac{\pi}{180})$: metros por grado de longitud a latitud $\phi_i$
- $C_{lat} = 111320$: metros por grado de latitud

**3.2 Construcción del Sistema de Coordenadas Local**

Definimos una base ortonormal $\mathcal{B}i = {\vec{e}{\parallel}, \vec{e}_{\perp}}$ donde:

- $\vec{e}_{\parallel} = (\cos\theta_i, \sin\theta_i)$: vector unitario paralelo a la calle
- $\vec{e}_{\perp} = (-\sin\theta_i, \cos\theta_i)$: vector unitario perpendicular a la calle

Esta base satisface:

- $|\vec{e}{\parallel}| = |\vec{e}{\perp}| = 1$
- $\vec{e}{\parallel} \cdot \vec{e}{\perp} = 0$ (ortogonalidad)
- $\det(\vec{e}{\parallel}, \vec{e}{\perp}) = 1$ (orientación positiva)

**3.3 Transformación de Coordenadas**

La transformación del sistema global de coordenadas geográficas al sistema local alineado con la calle se realiza mediante una rotación ortogonal que depende del ángulo de dirección $\theta_i$.

*Definición Formal*

Dado un punto $P_i$ con:

- Coordenadas geográficas originales: $(\lambda_i, \phi_i)$ en grados
- Coordenadas métricas globales: $(x_i^G, y_i^G)$ en metros
- Ángulo de dirección de la calle: $\theta_i$ en radianes

La transformación al sistema local es:

$$
\begin{bmatrix}
x_i' \\
y_i'
\end{bmatrix} = R(\theta_i)^\top \cdot 
\begin{bmatrix}
x_i^G \\
y_i^G
\end{bmatrix}
$$

donde $R(\theta_i)$ es la matriz de rotación:

$$
R(\theta_i) = \begin{bmatrix} 
\cos\theta_i & \sin\theta_i \\ 
-\sin\theta_i & \cos\theta_i 
\end{bmatrix}
$$

y por lo tanto:

$$
R(\theta_i)^\top = R(-\theta_i) = \begin{bmatrix} \cos\theta_i & \sin\theta_i \\ -\sin\theta_i & \cos\theta_i \end{bmatrix}
$$

*Desarrollo Paso a Paso*

1. Vector de posición en sistema global:
  $$
  \mathbf{r}_i^G = \begin{bmatrix} x_i^G \\ y_i^G \end{bmatrix}
  $$
2. Bases de los sistemas de coordenadas:
  Sistema global $\mathcal{G}$:
  $$
  \begin{bmatrix}
  \mathcal{G} = \left\{ \vec{e}_x^G = \begin{bmatrix} 1 \\ 0 \end{bmatrix}, \ \vec{e}_y^G = \begin{bmatrix} 0 \\ 1 \end{bmatrix} \right\}
  \end{bmatrix}
  $$
  Sistema local $\mathcal{L}_i$:
  $$
  \mathcal{L}_i = \left\{ 
  \vec{e}_{\parallel} = \begin{bmatrix} \cos\theta_i \\ \sin\theta_i \end{bmatrix}, 
  \quad 
  \vec{e}_{\perp} = \begin{bmatrix} -\sin\theta_i \\ \cos\theta_i \end{bmatrix} 
  \right\}
  $$
3. Cambio de base:
  Las coordenadas $(x_i', y_i')$ en el sistema local satisfacen:
  $$
  \vec{r}_i^G = x_i' \vec{e}_{\parallel} + y_i' \vec{e}_{\perp}
  $$
  En forma matricial:
  $$
  \begin{bmatrix}
  x_i^G \\
  y_i^G
  \end{bmatrix} =
  \begin{bmatrix}
  \cos\theta_i & -\sin\theta_i \\
  \sin\theta_i & \cos\theta_i
  \end{bmatrix}
  \begin{bmatrix}
  x_i' \\
  y_i'
  \end{bmatrix}
  $$
4. Solución para coordenadas locales:
  Despejando $(x_i', y_i')$:
  $$
  \begin{bmatrix}
  x_i' \\
  y_i'
  \end{bmatrix}
  =
  \begin{bmatrix}
  \cos\theta_i & -\sin\theta_i \\
  \sin\theta_i & \cos\theta_i
  \end{bmatrix}
  \begin{bmatrix}
  x_i^G \\
  y_i^G
  \end{bmatrix}
  $$

*Interpretación Geométrica*

1. Sistema global:
  - Eje X: dirección este (positivo hacia el este)
  - Eje Y: dirección norte (positivo hacia el norte)
2. Sistema local:
  - Eje $x'$ (longitudinal): paralelo a la dirección de la calle $\theta_i$
  - Eje $y'$ (transversal): perpendicular a la calle ($\theta_i + \frac{\pi}{2}$)
3. Transformación como rotación activa vs. pasiva:
  Esta transformación puede interpretarse de dos formas equivalentes:
  a) Rotación pasiva del sistema de referencia: Rotamos los ejes de coordenadas en un ángulo $-\theta_i$, manteniendo fijo el vector $\vec{r}_i^G$.
  b) Rotación activa del vector: Rotamos el vector $\vec{r}_i^G$ en un ángulo $\theta_i$ en sentido contrario a las agujas del reloj, manteniendo fijos los ejes.

### 4. Discretización Temporal

Sea $T = {t_1, t_2, \dots, t_n}$ el conjunto ordenado de tiempos, con $t_1 < t_2 < \dots < t_n$.

**4.1 Construcción de Bins Temporales**

Definimos el ancho de bin temporal como $\Delta t = \text{time.gap}$. Los límites temporales son:

- $t_{\min} = \min(T)$
- $t_{\max} = \max(T)$

El número de bins temporales $N_t$ se calcula como:

$$
N_t = \left\lceil \frac{t_{\max} - t_{\min}}{\Delta t} \right\rceil + 1
$$

Los bins temporales son intervalos semiabiertos:

$$
B_t[k] = [t_{\min} + (k-1)\Delta t,\ t_{\min} + k\Delta t),\quad k = 1, 2, \dots, N_t-1
$$

El último bin es cerrado para incluir $t_{\max}$:

$$
B_t[N_t] = [t_{\min} + (N_t-1)\Delta t,\ t_{\max}]
$$

**4.2 Asignación de Puntos a Bins Temporales**

Para cada tiempo $t_i$, determinamos su bin temporal:

$$
b_t(i) = \left\lfloor \frac{t_i - t_{\min}}{\Delta t} \right\rfloor + 1
$$

Con la restricción: $1 \leq b_t(i) \leq N_t$

### 5. Discretización Espacial Orientada a Calles

**5.1 Discretización Longitudinal (a lo largo de $x'$)**

Sea $X' = \{x_1', x_2', \dots, x_n'\}$ el conjunto de coordenadas longitudinales transformadas.

*Paso 1*: Determinación del rango:

$$
x_{\min}' = \min(X'), \quad x_{\max}' = \max(X')
$$

*Paso 2*: Construcción de bins longitudinales con ancho $\Delta s = \text{space.gap}$:

$$
N_x = \left\lceil \frac{x_{\max}' - x_{\min}'}{\Delta s} \right\rceil + 1
$$

Los bins longitudinales son:

$$
B_x[\ell] = [x_{\min}' + (\ell-1)\Delta s,\ x_{\min}' + \ell\Delta s),\quad \ell = 1, 2, \dots, N_x-1
$$

El último bin incluye el límite superior:

$$
B_x[N_x] = [x_{\min}' + (N_x-1)\Delta s,\ x_{\max}']
$$

*Paso 3*: Asignación de puntos a bins:

$$
b_x(i) = \left\lfloor \frac{x_i' - x_{\min}'}{\Delta s} \right\rfloor + 1
$$

**5.2 Discretización Transversal (a lo largo de $y'$)**

*Paso 1*: Cálculo del ancho de bin transversal:

$$
\Delta s_y = \Delta s \times \sin\left(\alpha \times \frac{\pi}{180}\right)
$$

donde $\alpha = \text{street.angle.tolerance} = 30°$.

Para $\alpha = 30°$:

$$
\sin(30°) = \frac{1}{2} \Rightarrow \Delta s_y = \frac{\Delta s}{2}
$$

**Interpretación**: Esta elección crea bins con relación de aspecto 2:1, lo que significa que los bins son el doble de largos que de anchos. Esto refleja la intuición de que la variación a lo largo de una calle es más importante que la variación transversal para análisis de tráfico.

*Paso 2*: Determinación del rango transversal:

$$
y_{\min}' = \min(Y'), \quad y_{\max}' = \max(Y')
$$

donde $Y' = \{y_1', y_2', \dots, y_n'\}$ es el conjunto de coordenadas transversales transformadas.

*Paso 3*: Construcción de bins transversales:

$$
N_y = \left\lceil \frac{y_{\max}' - y_{\min}'}{\Delta s_y} \right\rceil + 1
$$

Los bins transversales son:

$$
B_y[m] = [y_{\min}' + (m-1)\Delta s_y,\ y_{\min}' + m\Delta s_y),\quad m = 1, 2, \dots, N_y-1
$$

El último bin incluye el límite superior:

$$
B_y[N_y] = [y_{\min}' + (N_y-1)\Delta s_y,\ y_{\max}']
$$

*Paso 4*: Asignación de puntos a bins:

$$
b_y(i) = \left\lfloor \frac{y_i' - y_{\min}'}{\Delta s_y} \right\rfloor + 1
$$

### 6. Agregación por Celdas 3D

**6.1 Definición de Celdas**

Una **celda** $C_{k,\ell,m}$ se define como la intersección de:
- Bin temporal $B_t[k]$
- Bin longitudinal $B_x[\ell]$
- Bin transversal $B_y[m]$

Formalmente:

$$
C_{k,\ell,m} = \{i \in \{1,\dots,n\} : b_t(i) = k,\ b_x(i) = \ell,\ b_y(i) = m\}
$$

**6.2 Estadísticos por Celda**

Para cada celda no vacía ($|C_{k,\ell,m}| > 0$):

1. **Tiempo representativo** (promedio temporal):
   $$
   \bar{t}_{k,\ell,m} = \frac{1}{|C|} \sum_{i \in C} t_i
   $$
2. **Posición representativa** (centroide en coordenadas originales):
   - Longitud promedio: $\bar{\lambda}_{k,\ell,m} = \frac{1}{|C|} \sum_{i \in C} \lambda_i$
   - Latitud promedio: $\bar{\phi}_{k,\ell,m} = \frac{1}{|C|} \sum_{i \in C} \phi_i$
3. **Valor del campo agregado**:
   $$
   \bar{v}_{k,\ell,m} = \text{compile.function}(\{v_i : i \in C\})
   $$
   Donde $\text{compile.function}$ puede ser:
   - Media: $\frac{1}{|C|} \sum_{i \in C} v_i$
   - Máximo: $\max\{v_i : i \in C\}$
   - Mínimo: $\min\{v_i : i \in C\}$
   - Suma: $\sum_{i \in C} v_i$
4. **Número de puntos**:
   $$
   n_{k,\ell,m} = |C| = \text{cardinalidad de } C
   $$
5. **Dirección promedio de la calle** (promedio circular):
   Para ángulos $\theta_i$, el promedio circular se calcula como:
   
   - Componente coseno: $C_{\theta} = \frac{1}{|C|} \sum_{i \in C} \cos\theta_i$
   - Componente seno: $S_{\theta} = \frac{1}{|C|} \sum_{i \in C} \sin\theta_i$
   - Dirección promedio: $\bar{\theta}_{k,\ell,m} = \text{atan2}(S_{\theta}, C_{\theta})$

   **Nota**: Este método evita problemas en el promedio de ángulos cerca de $0°/360°$.

**6.3 Propiedades de la Agregación**

1. **Conservación de masa** (para funciones de suma):
   $$
   \sum_{k,\ell,m} \bar{v}_{k,\ell,m} = \sum_{i=1}^n v_i
   $$
2. **Monotonicidad**: Si $\text{compile.function}$ es monótona, el orden se preserva.
3. **Idempotencia**: Si todos los puntos caen en la misma celda y $\text{compile.function} = \text{identidad}$, entonces $\bar{v} = v_i$ para todo $i$.

### 7. Construcción de la Salida

La función retorna un conjunto de $m$ puntos discretizados:

$$
D = \{(\bar{t}_j, \bar{\lambda}_j, \bar{\phi}_j, \bar{v}_j, n_j, \bar{\theta}_j)\}_{j=1}^m
$$

donde $j$ indexa las celdas no vacías ordenadas por:

1. Tiempo $\bar{t}_j$ (creciente)
2. Coordenada longitudinal transformada $x_j'$ (creciente)
3. Coordenada transversal transformada $y_j'$ (creciente)

**7.1 Transformación Inversa para Visualización**

Para visualizar o analizar los resultados en coordenadas originales, cada punto discretizado representa una **celda rectangular** en el sistema de coordenadas de la calle:

- Centro: $(\bar{\lambda}_j, \bar{\phi}_j)$
- Dimensiones: $\Delta s$ (largo) × $\Delta s_y$ (ancho)
- Orientación: $\bar{\theta}_j$

Los vértices de la celda en coordenadas globales son:

$$
\begin{bmatrix}
\lambda_{\text{vértice}} \\
\phi_{\text{vértice}}
\end{bmatrix} = 
\begin{bmatrix}
\bar{\lambda}_j \\
\bar{\phi}_j
\end{bmatrix} + \frac{1}{C_{lng}(\bar{\phi}_j)} R(\bar{\theta}_j) 
\begin{bmatrix}
\pm\frac{\Delta s}{2} \\
\pm\frac{\Delta s_y}{2}
\end{bmatrix}
$$

### 8. Propiedades Matemáticas Globales

**8.1 Reducción Dimensional**

El número de puntos de salida $m$ satisface:

$$
m \leq \min(n,\ N_t \times N_x \times N_y)
$$

En la práctica, típicamente:

$$
m \approx \frac{n}{\left\lfloor \frac{\Delta t}{\Delta t_{\text{original}}} \right\rfloor \times \left\lfloor \frac{\Delta s}{\Delta s_{\text{original}}} \right\rfloor}
$$

donde $\Delta t_{\text{original}}$ y $\Delta s_{\text{original}}$ son las resoluciones originales de los datos.

**8.2 Error de Discretización**

Definimos el **error de representación** para una celda $C$:
$$
\epsilon_C = \frac{1}{|C|} \sum_{i \in C} \|P_i - \bar{P}_C\|
$$

donde $P_i = (\lambda_i, \phi_i)$ y $\bar{P}_C = (\bar{\lambda}_C, \bar{\phi}_C)$.

Bajo condiciones suaves:

$$
\mathbb{E}[\epsilon_C] \approx \frac{\Delta s}{2\sqrt{3}} \ \text{(longitudinal)} + \frac{\Delta s_y}{2\sqrt{3}} \ \text{(transversal)}
$$

**8.3 Conservación de Información**

La transformación preserva:
1. **Orden temporal**: Si $t_i < t_j$, entonces $\bar{t}_{C(i)} \leq \bar{t}_{C(j)}$
2. **Vecindad espacial**: Puntos cercanos en la misma dirección se mantienen cercanos
3. **Propiedades estadísticas**: Dependiendo de $\text{compile.function}$

### 9. Ventajas sobre Discretización Cartesiana Tradicional

1. **Adaptabilidad direccional**: Se ajusta a la geometría de la red vial
2. **Mejor agrupación semántica**: Agrupa puntos que están en la misma calle
3. **Reducción de error en curvas**: Menor distorsión en tramos curvos
4. **Separación natural de direcciones**: Diferentes sentidos de circulación se discretizan por separado
5. **Interpretabilidad física**: Las dimensiones de las celdas tienen significado físico (largo/ancho de calle)
