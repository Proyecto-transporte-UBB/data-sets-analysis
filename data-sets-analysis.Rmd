---
title: "Análisis de los Sets de Datos"
author: "Luciano Hernández"
date: "`r Sys.Date()`"
output:
  pdf_document:
    toc: true
    toc_depth: 3
    keep_tex: true
  html_document:
    toc: true
    toc_depth: 3
    toc_float: true
    number_sections: true
---

```{r setup, include=FALSE}
if (Sys.getenv("JAVA_HOME")=="") {
  Sys.setenv(JAVA_HOME="C:/Program Files/Java/jre1.8.0_361")
}
knitr::opts_chunk$set(echo = TRUE)
options(future.globals.maxSize = 8000 * 1024^2)
options(java.parameters = "-Xmx2048m")
library(ggspatial)
library(OpenStreetMap)
library(cowplot)
library(crosstalk)
library(data.table)
library(dplyr)
library(furrr)
library(future.apply)
library(ggcorrplot)
library(ggmap)
library(ggplot2)
library(googlesheets4)
library(grid)
library(gridExtra)
library(gtfsio)
library(httr)
library(kableExtra)
library(knitr)
library(leaflet)
library(lubridate)
library(maps)
library(openxlsx)
library(osmdata)
library(prettymapr)
library(progressr)
library(protolite)
library(purrr)
library(RANN)
library(readr)
library(readxl)
library(rjson)
library(rnaturalearth)
library(rnaturalearthdata)
library(sf)
library(shiny)
library(stringr)
library(tidygeocoder)
library(tidyr)
library(tidytransit)
library(tidyverse)
library(tidyxl)
library(viridis)
library(chilemapas)
```

```{r key.objects, include=FALSE}
key.objects <- c("interurban.bus.accidents", "gh026929", "police.accidents", "radio.accidents.df", "chiguayante.speed.df", "vega.speed.df", "gps.events", "biobio.inventary", "trafic.alerts", "accidents", "waze.data", "meters.per.degree.lat", "meters.per.degree.lng", "tracking.gps.df", "tracking.gps.df.cor", "waze.routes", "waze.routes.df")

sum.time <- function(dt.list){
  dt.list %>% sapply(., function(t){
    (t %>% as.numeric()) * switch (t %>% units(),
      "secs" = 1,
      "mins" = 60,
      "hours" = 3600
    )
  }) %>% sum()
}

haversine.dist <- function(lat1, lng1, lat2, lng2) {
  R <- 6371000
  dlat <- (lat2 - lat1) * pi / 180
  dlon <- (lng2 - lng1) * pi / 180
  a <- sin(dlat / 2)^2 + cos(lat1 * pi / 180) * cos(lat2 * pi / 180) * sin(dlon / 2)^2
  c <- 2 * atan2(sqrt(a), sqrt(1 - a))
  return(R * c)
}

min.haversine.dist <- function(lat, lng, p.lat, p.lng) {
  dist <- haversine.dist(lat, lng, p.lat, p.lng)
  dist[dist > 0] %>% min()
}

min.haversine.distances <- function(lat, lng) {
  n <- min(lat %>% length(), lng %>% length())
  1:n %>% sapply(., function(i) min.haversine.dist(lat[i], lng[i], lat[-i], lng[-i]))
}

haversine.distances <- function(lat, lng) {
  if(lat %>% length() <= 1 | lng %>% length() <= 1) return(0)
  lat.rad <- lat * pi / 180
  lng.rad <- lng * pi / 180
  x <- cos(lat.rad) * cos(lng.rad)
  y <- cos(lat.rad) * sin(lng.rad)
  z <- sin(lat.rad)
  points <- cbind(x, y, z)
  nn <- points %>% nn2(k = 2, treetype = "kd", searchtype = "standard")
  R <- 6371000
  distances <- sapply(1:(points %>% nrow()), function(i){
    dot.product <- (points[i,] * points[nn$nn.idx[i, 2],]) %>% sum()
    dot.product <- max(-1, min(1, dot.product))
    ang.dist <- acos(dot.product)
    R * ang.dist
  })
  return(distances)
}

replace.na <- function(lst, r = 0) {
  lst.1 <- lst
  lst.1[lst.1 %>% is.na()] <- r
  lst.1
}

cities.map <- mapa_comunas %>%
  st_as_sf() %>%
  st_transform(crs = 4326) %>%
  mutate(
    nombre_comuna = codigos_territoriales$nombre_comuna[codigo_comuna %>% match(., codigos_territoriales$codigo_comuna)]
  ) %>% st_make_valid()

weekdays <- c("lunes", "martes", "miércoles", "jueves", "viernes", "sábado", "domingo")
months <- c("jan", "feb", "mar", "apr", "may", "jun", "jul", "aug", "sep", "oct", "nov", "dec")
```

```{r save, eval=FALSE, include=FALSE}
deleting.objects <- setdiff(ls(), key.objects)
rm(list = deleting.objects)
gc()
memory.limit()
memory.size()
save.image("~/GitHub/data-sets-analysis/.RData")
save.time.sys <- list()
for(ko in key.objects[key.objects != "tracking.gps.df"]) {
  start.sys <- Sys.time()
  file.name <- paste(ko, "rds", sep = ".")
  file.path. <- paste("~/GitHub/data-sets-analysis/rds-files", file.name, sep = "/")
  ko %>% get() %>% saveRDS(file = file.path.)
  end.sys <- Sys.time()
  dt.sys <- end.sys - start.sys
  print(ko)
  print(dt.sys)
  save.time.sys[[ko]] <- dt.sys
}
total.save.dt <- save.time.sys %>% sum.time()
```

```{r load, include=FALSE}
load.time.sys <- list()
for(ko in key.objects[key.objects != "tracking.gps.df"]) {
  start.sys <- Sys.time()
  file.name <- paste(ko, "rds", sep = ".")
  file.path. <- paste("~/GitHub/data-sets-analysis/rds-files", file.name, sep = "/")
  assign(ko, ko %>% readRDS(file = file.path.))
  end.sys <- Sys.time()
  dt.sys <- end.sys - start.sys
  print(ko)
  print(dt.sys)
  load.time.sys[[ko]] <- dt.sys
}
total.load.dt <- load.time.sys %>% sum.time()
```

```{r load.tracking.gps.df, include=FALSE}
ml <- 8 * 1024^3
ms <- 6 * 1024^3
R_MAX_VSIZE <- 8
Sys.setenv("R_MAX_VSIZE" = paste0(R_MAX_VSIZE, "Gb"))
memory.limit(size = ml)
options(future.globals.maxSize = ms)
gc()
loaded <- F
ko <- "tracking.gps.df"
start.sys <- Sys.time()
file.name <- paste(ko, "rds", sep = ".")
file.path. <- paste("~/GitHub/data-sets-analysis/rds-files", file.name, sep = "/")
tryCatch({
  assign(ko, ko %>% readRDS(file = file.path.))
  loaded <- T
}, error = function(e){
  print(paste("Error al cargar:", e$message))
  ml <- 2 * ml
  ms <- 2 * ms
  R_MAX_VSIZE <- 2 * R_MAX_VSIZE
  memory.limit(size = ml)
  options(future.globals.maxSize = ms)
  Sys.setenv("R_MAX_VSIZE" = paste0(R_MAX_VSIZE, "Gb"))
  gc()
})
while(!loaded){
  tryCatch({
    assign(ko, ko %>% readRDS(file = file.path.))
    loaded <- T
  }, error = function(e){
    print(paste("Error al cargar:", e$message))
    ml <- 2 * ml
    ms <- 2 * ms
    R_MAX_VSIZE <- 2 * R_MAX_VSIZE
    memory.limit(size = ml)
    options(future.globals.maxSize = ms)
    Sys.setenv("R_MAX_VSIZE" = paste0(R_MAX_VSIZE, "Gb"))
    gc()
  })
}
end.sys <- Sys.time()
dt.sys <- end.sys - start.sys
print(ko)
print(dt.sys)
load.time.sys[[ko]] <- dt.sys
```

# Detección de outliers

```{r is.outlier.f, include=FALSE}
is.outlier.m.n.sd <- function(x, dev = 2, func = function(n) n){
  new.x <- x %>% func()
  mean.x <- new.x %>% mean(na.rm = T)
  sd.x <- new.x %>% sd(na.rm = T)
  new.x < mean.x - dev * sd.x | new.x > mean.x + dev * sd.x
}

is.outlier.q <- function(x, dev = 1.5, func = function(n) n){
  new.x <- x %>% func()
  q1 <- new.x %>% quantile(1 / 4, na.rm = T)
  q3 <- new.x %>% quantile(3 / 4, na.rm = T)
  r.iq <- q3 - q1
  new.x < q1 - dev * r.iq | new.x > q3 + dev * r.iq
}
```

$$
\Theta = \left\{ x \in X \mid f(x) \notin R\left(f(X)\right) \right\}
$$

Donde:
- $\Theta \subseteq \mathbb{R}$: Conjunto de valores atípicos
- $X \subseteq \mathbb{R}$: Conjunto de datos observados
- $f: \mathbb{R} \to \mathbb{R}$: Función de transformación (puede ser la identidad $f(x) = x$ o transformaciones como $f(x) = \ln(x)$)
- $R: \mathcal{P}(\mathbb{R}) \to \mathcal{P}(\mathbb{R})$: Función que define el intervalo de valores considerados normales

## Métodos de Detección

### 1. Método de Media y Desviación Standard

Este método considera atípicos aquellos valores que se encuentran a más de cierta cantidad de desviaciones estándar de la media:

$$
R(K) = \left[ \mu_K - n \times \sigma_K,\ \mu_K + n \times \sigma_K \right]
$$

Donde:
- $\mu_K$: Media aritmética del conjunto de datos $K$
- $\sigma_K$: Desviación standard de $K$
- $n \in \mathbb{R}$: Número de desviaciones standard que definen el límite (valor por defecto: $n = 2$)

**Características**:
- Adecuado para distribuciones aproximadamente normales
- Sensible a la presencia de outliers en el cálculo de la media y desviación standard
- El parámetro $n$ controla la sensibilidad del método

### 2. Método de Cuartiles (Rango Intercuartílico)

Este método utiliza estadísticos robustos basados en cuartiles:

$$
R(K) = \left[ Q_1(K) - n \times \text{IQR}(K),\ Q_3(K) + n \times \text{IQR}(K) \right]
$$

Donde:
- $Q_1(K)$: Primer cuartil (percentil 25)
- $Q_3(K)$: Tercer cuartil (percentil 75)
- $\text{IQR}(K) = Q_3(K) - Q_1(K)$: Rango intercuartílico
- $n \in \mathbb{R}$: Multiplicador del IQR (valor por defecto: $n = 1.5$)

**Ventajas**:
- Robusto ante la presencia de valores atípicos
- No asume normalidad en la distribución
- Ampliamente utilizado en diagramas de caja (*boxplots*)

# Extracción y caracterización de datos

## Siniestros buses interurbanos(1).xlsx

```{r getData0, eval=FALSE, include=FALSE}
# Siniestros buses interurbanos(1).xlsx
interurban.bus.accidents <- read_excel("data/Siniestros buses interurbanos(1).xlsx", 
    col_types = c("numeric", "numeric", "date", 
        "date", "numeric", "text", "text", 
        "text", "text", "text", "text", "text", 
        "text", "text", "text", "text", "numeric", 
        "text", "numeric", "numeric", "numeric", 
        "numeric", "numeric", "numeric", 
        "numeric", "numeric", "numeric"))
interurban.bus.accidents$Fecha <- paste(interurban.bus.accidents$Fecha, interurban.bus.accidents$Hora %>% format(format = "%H:%M:%S")) %>% as.POSIXct(format = "%Y-%m-%d %H:%M")
interurban.bus.accidents <- interurban.bus.accidents %>% select(-Hora)
interurban.bus.accidents$Región <- interurban.bus.accidents$Región %>% as.factor()
interurban.bus.accidents$Comuna <- interurban.bus.accidents$Comuna %>% as.factor()
interurban.bus.accidents$`Tipo Accidente` <- interurban.bus.accidents$`Tipo Accidente` %>% as.factor()
interurban.bus.accidents$`Tipo (CONASET)` <- interurban.bus.accidents$`Tipo (CONASET)` %>% as.factor()
interurban.bus.accidents$Zona <- interurban.bus.accidents$Zona %>% as.factor()
interurban.bus.accidents$`Ubicación Relativa` <- interurban.bus.accidents$`Ubicación Relativa` %>% as.factor()
interurban.bus.accidents$`Causa (CONASET)` <- interurban.bus.accidents$`Causa (CONASET)` %>% as.factor()
interurban.bus.accidents$`Causa Accidente` <- interurban.bus.accidents$`Causa Accidente` %>% as.factor()
interurban.bus.accidents$Ruta <- interurban.bus.accidents$Ruta %>% as.factor()
interurban.bus.accidents %>% summary()
difference <- interurban.bus.accidents$Fecha %>% max() - interurban.bus.accidents$Fecha %>% min()
interurban.bus.accidents %>% nrow() / difference %>% as.numeric()
```

El análisis comprende 6268 registros de siniestros de buses interurbanos ocurridos entre el 1 de enero de 2014 y el 29 de diciembre de 2023.

### Matriz de correlación

```{r interurban.bus.accidents.corr, echo=FALSE, message=FALSE, warning=FALSE}
interurban.bus.accidents.cor <- interurban.bus.accidents %>% mutate(
  Fecha = Fecha %>% as.numeric(),
  Región = `Cód-Región`,
  Comuna = Comuna %>% as.numeric(),
  `Tipo (CONASET)` = `Tipo (CONASET)` %>% as.numeric() %>% replace.na(),
  Zona = Zona %>% as.numeric() %>% replace.na(),
  `Causa (CONASET)` = `Causa (CONASET)` %>% as.numeric() %>% replace.na(),
  Ruta = Ruta %>% as.numeric() %>% replace.na(),
  `Ubicación Relativa` = `Ubicación Relativa` %>% as.numeric() %>% replace.na()
) %>%
  select(-Año, -`Cód-Región`, -`Tipo Accidente`, -`Causa Accidente`, -`Calle Uno`, -`Calle Dos`, -Intersección) %>%
  cor(use = "pairwise.complete.obs")
interurban.bus.accidents.cor %>%
  ggcorrplot() +
  theme(axis.text.x = element_text(angle = 90, hjust = 1, vjust = 0.5, size = 8), axis.text.y = element_text(size = 8))
interurban.bus.accidents.cor %>%
  round(digits = 3) %>%
  kable() %>%
  kable_styling(full_width = F) %>%
  column_spec(1, bold = T, border_right = T) %>%
  add_header_above(c(" " = 1, "Variables" = ncol(interurban.bus.accidents.cor))) %>%
  pack_rows("Variables", 1, nrow(interurban.bus.accidents.cor)) %>%
  row_spec(0, angle = 90, extra_css = "vertical-align: bottom;") %>%
  column_spec(2:ncol(interurban.bus.accidents.cor), width = "0.5cm")
```


```{r interurban.bus.accidents.corr.export, eval=FALSE, include=FALSE}
interurban.bus.accidents.cor %>% write.csv(file = "corr/interurban.bus.accidents.csv")
```


### Granularidad temporal

- Diferencia Mínima: 2 minutos
- Diferencia Máxima: 10 días, 22 horas y 5 minutos
- Diferencia Media: 14 horas, 7 minutos y 6 segundos (lineal); 6 horas, 46 minutos, 10.17 segundos (logarítmico)
- Diferencia Mediana: 8 horas y 25 minutos
- Desviación Standard: 18 horas y 56.73 segundos (lineal); 4.01 segundos (logarítmico)

```{r interurban.bus.accidents.time, echo=FALSE, message=FALSE, warning=FALSE}
differences <- (interurban.bus.accidents$Fecha - c(NA, interurban.bus.accidents$Fecha[1:(interurban.bus.accidents %>% nrow() - 1)])) %>% as.numeric()
positive.diff <- differences[differences > 0]
#positive.diff %>% summary()
ggplot() +
  geom_histogram(aes(x = positive.diff)) +
  scale_x_log10()
```

**Outliers**: Media y desviación standard (logarítmico)

```{r interurban.bus.accidents.time.ol, echo=FALSE, message=FALSE, warning=FALSE}
is.outlier <- positive.diff %>% is.outlier.m.n.sd(func = log)
ggplot() +
  geom_histogram(aes(x = positive.diff, fill = is.outlier)) +
  scale_x_log10()
```

Hay 264 outliers inferiores y 33 outliers superiores, dando un total de 297 outliers

### Distribución Temporal

```{r interurban.bus.accidents.month.time, echo=FALSE, message=FALSE, warning=FALSE}
interurban.bus.accidents.dates <- data.frame(
  Hora = interurban.bus.accidents$Fecha %>% hour(),
  Mes = months[interurban.bus.accidents$Fecha %>% month()] %>% factor(levels = months)
)
interurban.bus.accidents.dates %>%
  count(Hora, Mes, .drop = F) %>%
  ggplot() +
  geom_tile(aes(y = Hora, x = Mes, fill = n)) +
  scale_fill_gradientn(
    name = "Cantidad",
    colors = c(
      "red",
      "orange",
      "yellow",
      "lightgreen",
      "darkgreen"
    )
  ) +
  labs(y = "Hora", x = "Mes")
interurban.bus.accidents.dates %>%
  count(Hora, Mes, .drop = F) %>%
  spread(key = Mes, value = n, fill = 0) %>%
  as.data.frame() %>%
  column_to_rownames("Hora") %>%
  as.matrix() %>%
  kable()
```

### Distribución Geográfica

- **Regiones más afectadas**: Región Metropolitana (1285 casos), Región del Maule (835 casos) y Región del Biobío (767 casos)
- **Comunas con mayor incidencia**: Curicó (244 siniestros), Valdivia (227) y Estación Central (186)

```{r interurban.bus.accidents.geografic, echo=FALSE, message=FALSE, warning=FALSE}
interurban.bus.accidents[interurban.bus.accidents$Comuna %in% (interurban.bus.accidents %>%
  count(Comuna) %>%
  slice_max(n, n = 10) %>%
  pull(Comuna)),] %>%
  ggplot() +
  geom_bar(aes(
    y = Comuna %>% fct_infreq() %>% fct_rev(),
    fill = Región
  )) +
  labs(y = "Comuna", fill = "Región", title = "10 comunas más frecuentes")
```

### Distribución Espacio-Temporal

**Región y Año**

```{r interurban.bus.accidents.spacetime.0, echo=FALSE, message=FALSE, warning=FALSE}
interurban.bus.accidents.spacetime <- data.frame(
  Año = interurban.bus.accidents$Fecha %>% year(),
  Mes = months[interurban.bus.accidents$Fecha %>% month()] %>% factor(levels = months),
  Región = interurban.bus.accidents$Región,
  Comuna = interurban.bus.accidents$Comuna
)
interurban.bus.accidents.spacetime %>%
  count(Año, Región, .drop = F) %>%
  ggplot() +
  geom_tile(aes(y = Región, x = Año, fill = n)) +
  scale_fill_gradientn(
    name = "Cantidad",
    colors = c(
      "red",
      "orange",
      "yellow",
      "lightgreen",
      "darkgreen"
    )
  ) +
  labs(y = "Región", x = "Año") +
  scale_y_discrete(labels = label_wrap_gen(width = 20))
interurban.bus.accidents.spacetime %>%
  count(Año, Región, .drop = F) %>%
  spread(key = Año, value = n, fill = 0) %>%
  as.data.frame() %>%
  column_to_rownames("Región") %>%
  as.matrix() %>%
  kable()
```

**Región y Mes**

```{r interurban.bus.accidents.spacetime.1, echo=FALSE, message=FALSE, warning=FALSE}
interurban.bus.accidents.spacetime %>%
  count(Mes, Región, .drop = F) %>%
  ggplot() +
  geom_tile(aes(y = Región, x = Mes, fill = n)) +
  scale_fill_gradientn(
    name = "Cantidad",
    colors = c(
      "red",
      "orange",
      "yellow",
      "lightgreen",
      "darkgreen"
    )
  ) +
  labs(y = "Región", x = "Mes") +
  scale_y_discrete(labels = label_wrap_gen(width = 20))
interurban.bus.accidents.spacetime %>%
  count(Mes, Región, .drop = F) %>%
  spread(key = Mes, value = n, fill = 0) %>%
  as.data.frame() %>%
  column_to_rownames("Región") %>%
  as.matrix() %>%
  kable()
```

**Comuna y Año**

```{r interurban.bus.accidents.spacetime.2, echo=FALSE, message=FALSE, warning=FALSE}
interurban.bus.accidents.spacetime[interurban.bus.accidents.spacetime$Comuna %in% (interurban.bus.accidents.spacetime %>%
  count(Comuna) %>%
  slice_max(n, n = 10) %>%
  pull(Comuna)),] %>% mutate(
    Comuna = Comuna %>% factor(levels = interurban.bus.accidents.spacetime %>%
      count(Comuna) %>%
        slice_max(n, n = 10) %>%
        arrange(n %>% desc()) %>%
        pull(Comuna) %>% rev()
    )
  ) %>%
  count(Año, Comuna, .drop = F) %>%
  ggplot() +
  geom_tile(aes(y = Comuna, x = Año, fill = n)) +
  scale_fill_gradientn(
    name = "Cantidad",
    colors = c(
      "red",
      "orange",
      "yellow",
      "lightgreen",
      "darkgreen"
    )
  ) +
  labs(y = "Comuna", x = "Año")
interurban.bus.accidents.spacetime %>% mutate(
    Comuna = Comuna %>% factor(levels = interurban.bus.accidents.spacetime %>%
      count(Comuna) %>%
        slice_max(n, n = interurban.bus.accidents.spacetime$Comuna %>%
            levels() %>%
            length()) %>%
        arrange(n %>% desc()) %>%
        pull(Comuna)
    )
  ) %>%
  count(Año, Comuna, .drop = F) %>%
  spread(key = Año, value = n, fill = 0) %>%
  as.data.frame() %>%
  column_to_rownames("Comuna") %>%
  as.matrix() %>%
  kable()
```

**Comuna y Mes**

```{r interurban.bus.accidents.spacetime.3, echo=FALSE, message=FALSE, warning=FALSE}
interurban.bus.accidents.spacetime[interurban.bus.accidents.spacetime$Comuna %in% (interurban.bus.accidents.spacetime %>%
  count(Comuna) %>%
  slice_max(n, n = 10) %>%
  pull(Comuna)),] %>% mutate(
    Comuna = Comuna %>% factor(levels = interurban.bus.accidents.spacetime %>%
      count(Comuna) %>%
        slice_max(n, n = 10) %>%
        arrange(n %>% desc()) %>%
        pull(Comuna) %>% rev()
    )
  ) %>%
  count(Mes, Comuna, .drop = F) %>%
  ggplot() +
  geom_tile(aes(y = Comuna, x = Mes, fill = n)) +
  scale_fill_gradientn(
    name = "Cantidad",
    colors = c(
      "red",
      "orange",
      "yellow",
      "lightgreen",
      "darkgreen"
    )
  ) +
  labs(y = "Comuna", x = "Mes")
interurban.bus.accidents.spacetime %>% mutate(
    Comuna = Comuna %>% factor(levels = interurban.bus.accidents.spacetime %>%
      count(Comuna) %>%
        slice_max(n, n = interurban.bus.accidents.spacetime$Comuna %>%
            levels() %>%
            length()) %>%
        arrange(n %>% desc()) %>%
        pull(Comuna)
    )
  ) %>%
  count(Mes, Comuna, .drop = F) %>%
  spread(key = Mes, value = n, fill = 0) %>%
  as.data.frame() %>%
  column_to_rownames("Comuna") %>%
  as.matrix() %>%
  kable()
```

### Características de los Siniestros

- **Tipos predominantes**: Colisión (3655 casos), choque (1464) y atropello (448)
- **Distribución por zona**: 4251 accidentes en zonas urbanas versus 2,017 en zonas rurales

```{r interurban.bus.accidents.features, echo=FALSE, message=FALSE, warning=FALSE}
interurban.bus.accidents %>%
  ggplot() +
  geom_bar(aes(
    y = `Tipo (CONASET)` %>% fct_infreq() %>% fct_rev(),
    fill = Zona
  )) +
  labs(y = "Tipo (CONASET)", fill = "Zona", title = "Tipos predominantes") +
  scale_x_log10()
```

### Factores Causales

- **Principales causas**: Imprudencia del conductor (3597 casos), otras causas (599) y causas no determinadas (540)
- *Nota*: La alta frecuencia de la categoría "otras causas" sugiere la necesidad de ampliar la clasificación causal existente

```{r interurban.bus.accidents.causal, echo=FALSE, message=FALSE, warning=FALSE}
interurban.bus.accidents.n.top.causes <- interurban.bus.accidents[interurban.bus.accidents$`Causa (CONASET)` %in% (interurban.bus.accidents %>%
  count(`Causa (CONASET)`) %>%
  slice_max(n, n = 5) %>%
  pull(`Causa (CONASET)`)),]
interurban.bus.accidents.causes <- data.frame(
  `Causa (CONASET)` = interurban.bus.accidents.n.top.causes$`Causa (CONASET)` %>% as.character() %>% as.factor(),
  Región = interurban.bus.accidents.n.top.causes$Región
)
interurban.bus.accidents.n.top.causes %>%
  ggplot() +
  geom_bar(aes(
    y = `Causa (CONASET)` %>% fct_infreq() %>% fct_rev(),
    fill = Región %>% fct_infreq()
  )) +
  labs(y = "Causa (CONASET)", fill = "Región", title = "5 causas principales") +
  scale_fill_discrete(labels = label_wrap_gen(width = 20)) +
  scale_x_log10()
cause.freq <- interurban.bus.accidents.causes %>%
  count(Causa..CONASET.) %>%
  arrange(n %>% desc())
region.freq <- interurban.bus.accidents.causes %>% 
  count(Región) %>%
  arrange(n)
interurban.bus.accidents.causes %>%
  count(Causa..CONASET., Región, .drop = F) %>%
  ggplot() +
  geom_tile(aes(
    x = Causa..CONASET. %>% factor(levels = cause.freq$Causa..CONASET.),
    y = Región %>% factor(levels = region.freq$Región),
    fill = n
  )) +
  scale_fill_gradientn(
    name = "Cantidad",
    colors = c(
      "red",
      "orange",
      "yellow",
      "lightgreen",
      "darkgreen"
    )
  ) +
  labs(title = "5 causas principales", y = "Región", x = "Causa (CONASET)") +
  scale_x_discrete(labels = label_wrap_gen(width = 20)) +
  theme(axis.text.x = element_text(angle = 90, hjust = 0, vjust = 0.5))
interurban.bus.accidents.causes %>% mutate(
    Causa..CONASET. = Causa..CONASET. %>% factor(levels = interurban.bus.accidents.causes %>%
      count(Causa..CONASET.) %>%
        slice_max(n, n = interurban.bus.accidents.causes$Causa..CONASET. %>%
            levels() %>%
            length()) %>%
        arrange(n %>% desc()) %>%
        pull(Causa..CONASET.)
    ),
    Región = Región %>% factor(levels = interurban.bus.accidents.causes %>%
      count(Región) %>%
        slice_max(n, n = interurban.bus.accidents.causes$Región %>%
            levels() %>%
            length()) %>%
        arrange(n %>% desc()) %>%
        pull(Región)
    )
  ) %>%
  count(Causa..CONASET., Región, .drop = F) %>%
  spread(key = Causa..CONASET., value = n, fill = 0) %>%
  as.data.frame() %>%
  column_to_rownames("Región") %>%
  as.matrix() %>%
  kable()
```

### Consecuencias y Severidad

- Fallecidos: 94.58% de los siniestros no registran víctimas mortales
- Lesiones graves: Ausentes en 89.69% de los casos
- Lesiones menos graves: No ocurren en 94.16% de los accidentes
- Lesiones leves: No se presentan en 63.10% de los incidentes

```{r interurban.bus.accidents.severity, echo=FALSE, message=FALSE, warning=FALSE}
total <- interurban.bus.accidents %>% nrow()
severity <- data.frame(
  severity = c(
    rep("Fallecidos", total),
    rep("Lesiones graves", total),
    rep("Lesiones menos graves", total),
    rep("Lesiones leves", total)
  ) %>% factor(levels = c(
    "Fallecidos",
    "Lesiones graves",
    "Lesiones menos graves",
    "Lesiones leves")
  ),
  quantity = c(
    interurban.bus.accidents$`Fallecidos total siniestro`,
    interurban.bus.accidents$`Graves total siniestro`,
    interurban.bus.accidents$`Menos Graves  total siniestro`,
    interurban.bus.accidents$`Leves total siniestro`
  )
)
for(sev in severity$severity %>% levels()){
  (severity[severity$severity == sev,] %>%
    ggplot() +
    geom_bar(aes(
      x = quantity
    )) +
    labs(x = paste("Cantidad de", sev), title = paste("Distribución de cantidad de", sev, "por accidente")) +
    scale_y_log10()) %>% print()
}
```

### Procesamiento y Normalización de Datos

**Paso a paso**

- "Fecha" se convirtió en la concatenación de "Fecha" y "Hora" y se convierte en POSIXct con formato "%d/%m/%Y %H:%M:%S"
- Se elimina la columna "Hora"
- "Región" se convierte en factor
- "Comuna" se convierte en factor
- "Tipo Accidente" se convierte en factor
- "Tipo (CONASET)" se convierte en factor
- "Zona" se convierte en factor
- "Ubicación Relativa" se convierte en factor
- "Causa (CONASET)" se convierte en factor
- "Causa Accidente" se convierte en factor
- "Ruta" se convierte en factor

## GH026929.xlsx

```{r getData1, eval=FALSE, include=FALSE}
# GH026929.xlsx
gh026929 <- read_excel("data/GH026929.xlsx", 
    range = "A1:L1727", col_types = c("numeric", 
        "date", "text", "numeric", "numeric", 
        "numeric", "numeric", "skip", "skip", 
        "numeric", "numeric", "numeric"))

## ¿Qué es cts?
## Rangos altura
## ¿Qué es fix?
## U.M. precision

gh026929$date <- paste(gh026929$date, gh026929$hora) %>% as.POSIXct(format = "%Y-%m-%d %H:%M")
gh026929 <- gh026929 %>% select(-hora)
reduce.coords <- function(n) {
  n * 10 ^ (1 - (n %>% abs() %>% log10() %>% floor()))
}
reduce.2d.speed <- function(n, m) {
  N <- n * 10 ^ ((m %>% log10() + 1) %>% floor() - (n %>% log10() + 1) %>% floor())
  N[(N / m) %>% log10() > 0.7] <- N[(N / m) %>% log10() > 0.7] / 10
  N[(N / m) %>% log10() < -0.7] <- N[(N / m) %>% log10() < -0.7] * 10
  N
}
gh026929$`GPS (2D speed) [m/s]` <- reduce.2d.speed(gh026929$`GPS (2D speed) [m/s]`, gh026929$`GPS (3D speed) [m/s]`)
gh026929$`GPS (Lat.) [deg]` <- gh026929$`GPS (Lat.) [deg]` %>% reduce.coords()
gh026929$`GPS (Long.) [deg]` <- gh026929$`GPS (Long.) [deg]` %>% reduce.coords()
gh026929 %>% summary()
gh026929.sf <- gh026929 %>% st_as_sf(
  coords = c("GPS (Long.) [deg]", "GPS (Lat.) [deg]"),
  crs = 4326
)
gh026929.sf %>% st_write(.,
  "~/GitHub/data-sets-analysis/shapefiles/gh026929.shp",
  driver = "ESRI Shapefile",
  append = F
)
```

El dataset contiene 1726 registros de telemetría GPS capturados durante un período específico de operación vehicular.

### Matriz de correlación

```{r gh026929.corr, echo=FALSE, message=FALSE, warning=FALSE}
gh026929.cor <- gh026929 %>% mutate(
  date = date %>% as.numeric()
) %>%
  select(-cts) %>%
  cor(use = "pairwise.complete.obs")
gh026929.cor %>%
  ggcorrplot() +
  theme(axis.text.x = element_text(angle = 90, hjust = 1, vjust = 0.5))
gh026929.cor %>% kable()
```


```{r gh026929.corr.export, eval=FALSE, include=FALSE}
gh026929.cor %>% write.csv(file = "corr/gh026929.csv")
```

### Características Temporales

- **Período de registro**: 29 de agosto de 2024, entre las 01:32 y 01:34 horas
- **Duración total**: Aproximadamente 2 minutos de monitoreo continuo

### Granularidad temporal

- Diferencia Mínima: 0.055 segundos
- Diferencia Máxima: 0.059 segundos
- Diferencia Media: 0.055 segundos
- Diferencia Mediana: 0.055 segundos
- Desviación Standard: 0.000542 segundos

```{r gh026929.time, echo=FALSE, message=FALSE, warning=FALSE}
differences <- (gh026929$date - c(NA, gh026929$date[1:(gh026929 %>% nrow() - 1)])) %>% as.numeric()
#differences %>% summary()
ggplot() +
  geom_histogram(aes(x = differences))
```

**Outliers**: Cuartiles (lineal)

```{r gh026929.time.ol, echo=FALSE, message=FALSE, warning=FALSE}
is.outlier <- differences %>% is.outlier.q()
ggplot() +
  geom_histogram(aes(x = differences, fill = is.outlier))
```

Hay 53 outliers superiores

### Granularidad Espacial

- Distancia Mínima: 8.9 milímetros
- Distancia Máxima: 1.06 metros
- Distancia Media: 50.1 centímetros
- Distancia Mediana: 53.34 centímetros
- Desviación Standard: 34.55 centímetros

```{r gh026929.space, echo=FALSE, message=FALSE, warning=FALSE}
distances <- min.haversine.distances(
  gh026929$`GPS (Lat.) [deg]`,
  gh026929$`GPS (Long.) [deg]`
)
#(distances * 100) %>% summary()
ggplot() +
  geom_histogram(aes(x = distances))
```

**Outliers**: Cuartiles (lineal)

```{r gh026929.space.ol, echo=FALSE, message=FALSE, warning=FALSE}
is.outlier <- distances %>% is.outlier.q()
ggplot() +
  geom_histogram(aes(x = distances, fill = is.outlier))
```

No hay outliers

### Parámetros de Velocidad

- **Velocidad 3D**:
  - Mínimo: 0.01 m/s = 0.036 km/h
  - Máximo: 19.06 m/s = 68.62 km/h
  - Media: 9.1 m/s = 32.76 km/h
  - Mediana: 9.81 m/s = 35.32 km/h
  - Desviación Standard: 6.3 m/s = 22.69 Km/h

```{r gh026929.speed, echo=FALSE, message=FALSE, warning=FALSE}
gh026929 %>%
  ggplot() +
  geom_histogram(aes(x = `GPS (3D speed) [m/s]`)) +
  labs(title = "Distribución de velocidades")
```

**Outliers**: Cuartiles (lineal)

```{r gh026929.speed.ol, echo=FALSE, message=FALSE, warning=FALSE}
is.outlier <- gh026929$`GPS (3D speed) [m/s]` %>% is.outlier.q()
gh026929 %>% ggplot() +
  geom_histogram(aes(x = `GPS (3D speed) [m/s]`, fill = is.outlier))
```

No hay outliers

### Calidad de Señal GPS

- **Valor fix**: Constante en 3 para todos los registros, indicando que calculó su posición a partir de 3 satélites
- **Precisión**:
  - Mínimo: 121 m
  - Máximo: 158 m
  - Media: 125.9 m
  - Mediana: 125 m

```{r gh026929.precision, echo=FALSE, message=FALSE, warning=FALSE}
gh026929 %>%
  ggplot() +
  geom_histogram(aes(x = precision)) +
  labs(title = "Distribución de precisiones")
```

**Outliers**: Cuartiles (lineal)

```{r gh026929.precision.ol, echo=FALSE, message=FALSE, warning=FALSE}
is.outlier <- gh026929$precision %>% is.outlier.q()
gh026929 %>%
  ggplot() +
  geom_histogram(aes(x = precision, fill = is.outlier))
```

Hay 91 outliers superiores

### Aspectos Requieren Clarificación

**Variables por Definir**

- `cts`: Propósito y unidades no especificadas
- **Rango de alturas**: Valores de altitud GPS no reportados en el resumen

**Problemas de Formato Identificados**

- Coordenadas GPS (`Lat.` y `Long.`) sin formato decimal apropiado
- Velocidad 2D con inconsistencias en la ubicación del punto decimal
- Múltiples campos numéricos presentados sin separador decimal

### Procesamiento y Normalización de Datos

**Paso a paso**

- "date" se convirtió en la concatenación de "date" y "hora" y se convierte en POSIXct con formato "%d/%m/%Y %H:%M"
- Se elimina la columna "hora"
- "GPS (2D speed) [m/s]" se trató de poner al mismo orden de magnitud de "GPS (3D speed) [m/s]" mediante la siguiente fórmula:

$$\text{reduce.2d.speed}(n,m)\equiv n\times10^{\lfloor\log_{10}m+1\rfloor-\lfloor\log_{10}n+1\rfloor}$$

- "GPS (Lat.) [deg]" y "GPS (Long.) [deg]" se ajustaron para tener 2 dígitos enteros mediante la siguiente fórmula:

$$\text{reduce.coords}(n)\equiv n\times10^{1-\lfloor\log_{10}|n|\rfloor}$$

## DTPR

```{r getData1.5, eval=FALSE, include=FALSE}
tracking.route <- "data/Tracking GPS"
tracking.cols <- c("EVT_REGISTRO_ID", "EVT_OP_TR_ID", "EVT_OP_TE_ID", "EVT_MES_INFORMACION", "EVT_SERVICIO_ID_ORACLE", "EVT_SERVICIO_ID", "EVT_SENTIDO", "EVT_IMEI", "EVT_PPU", "EVT_GPS_TIME_CHILE_STR", "EVT_GPS_TIME_UTC_0", "EVT_GPS_DIR_GEO", "Y_EVT_GPS_LAT", "X_EVT_GPS_LON", "EVT_GPS_VEL", "EVT_GPS_DOP", "EVT_DISTANCIA_RECORRIDA (Km)", "EVT_ESTADO_MOTOR_GPS", "EVT_TIPO_EVENTO", "EVT_TIPO_VIAJE", "EVT_DISTACIA_A_SERVICIO", "EVT_CARPETA")
folders <- tracking.route %>% list.dirs(recursive = F) %>% basename()
tracking.gps <- list()
tracking.read <- list()
for(folder in folders) {
  start.sys <- Sys.time()
  base.route <- paste(tracking.route, folder, "ArchivosTxt", sep = "/") %>% list.files(pattern = "^MNT_TRACKING", full.names = T)
  df <- base.route %>% read.table(header = F, sep = ";")
  df$EVT_CARPETA <- folder
  tracking.gps[[folder]] <- df
  end.sys <- Sys.time()
  dt.sys <- end.sys - start.sys
  tracking.read[[folder]] <- dt.sys
  print(folder)
  print(dt.sys)
}
# Reading time: 7 m + 8.22 s
start.sys <- Sys.time()
tracking.gps.df <- tracking.gps %>% bind_rows()
colnames(tracking.gps.df) <- tracking.cols
end.sys <- Sys.time()
binding.time <- end.sys - start.sys
# Binding time: 5 m + 0.63 s
start.sys <- Sys.time()
tracking.gps.df$EVT_SERVICIO_ID <- tracking.gps.df$EVT_SERVICIO_ID %>% as.factor()
tracking.gps.df$EVT_PPU <- tracking.gps.df$EVT_PPU %>% as.factor()
tracking.gps.df$EVT_GPS_TIME_CHILE_STR <- tracking.gps.df$EVT_GPS_TIME_CHILE_STR %>% as.POSIXct(format = "%d/%m/%Y %H:%M:%S", tz = "America/Santiago")
tracking.gps.df$EVT_GPS_TIME_UTC_0 <- tracking.gps.df$EVT_GPS_TIME_UTC_0 %>% as.POSIXct(format = "%d/%m/%Y %H:%M:%S")
tracking.gps.df$Y_EVT_GPS_LAT <- gsub(",", ".", tracking.gps.df$Y_EVT_GPS_LAT) %>% as.numeric()
tracking.gps.df$X_EVT_GPS_LON <- gsub(",", ".", tracking.gps.df$X_EVT_GPS_LON) %>% as.numeric()
tracking.gps.df$`EVT_DISTANCIA_RECORRIDA (Km)` <- gsub(",", ".", tracking.gps.df$`EVT_DISTANCIA_RECORRIDA (Km)`) %>% as.numeric()
tracking.gps.df$EVT_DISTACIA_A_SERVICIO <- gsub(",", ".", tracking.gps.df$EVT_DISTACIA_A_SERVICIO) %>% as.numeric()
tracking.gps.df$EVT_CARPETA <- tracking.gps.df$EVT_CARPETA %>% as.factor()
tracking.gps.df$EVT_SEÑAL <- NA
tracking.gps.df$EVT_SEÑAL[tracking.gps.df$EVT_GPS_DOP < 1] <- "Excelente"
tracking.gps.df$EVT_SEÑAL[tracking.gps.df$EVT_GPS_DOP >= 1 & tracking.gps.df$EVT_GPS_DOP < 2] <- "Muy Buena"
tracking.gps.df$EVT_SEÑAL[tracking.gps.df$EVT_GPS_DOP >= 2 & tracking.gps.df$EVT_GPS_DOP < 5] <- "Buena"
tracking.gps.df$EVT_SEÑAL[tracking.gps.df$EVT_GPS_DOP >= 5 & tracking.gps.df$EVT_GPS_DOP <= 10] <- "Regular"
tracking.gps.df$EVT_SEÑAL[tracking.gps.df$EVT_GPS_DOP >= 5 & tracking.gps.df$EVT_GPS_DOP > 10] <- "Mala"
tracking.gps.df$EVT_SEÑAL <- tracking.gps.df$EVT_SEÑAL %>% as.factor()
end.sys <- Sys.time()
modifying.time <- end.sys - start.sys
# Modifying time: 30 m + 7.08 s
options(future.globals.maxSize = 16 * 1024^3)
shp.time <- list()
tracking.gps.df.sf <- list()
for(folder in folders){
  start.sys <- Sys.time()
  df <- tracking.gps.df[tracking.gps.df$EVT_CARPETA == folder,]
  df.rename <- df %>%
    rename(
      SERV_ID = EVT_SERVICIO_ID,
      SERV_ID_O = EVT_SERVICIO_ID_ORACLE,
      GPS_TIME_CH = EVT_GPS_TIME_CHILE_STR,
      GPS_TIME_UTC = EVT_GPS_TIME_UTC_0,
      DIST_REC = `EVT_DISTANCIA_RECORRIDA (Km)`,
      DIST_SERV = EVT_DISTACIA_A_SERVICIO,
      CARPETA = EVT_CARPETA,
      SEÑAL = EVT_SEÑAL
    )
  sf <- df.rename %>% st_as_sf(
    coords = c("X_EVT_GPS_LON", "Y_EVT_GPS_LAT"),
    crs = 4326
  )
  file.name <- paste(folder, "shp", sep = ".")
  file.path. <- paste("~/GitHub/data-sets-analysis/shapefiles/DTPR", file.name, sep = "/")
  sf %>% st_write(.,
    file.path.,
    driver = "ESRI Shapefile",
    append = F
  )
  tracking.gps.df.sf[[folder]] <- sf
  end.sys <- Sys.time()
  dt <- end.sys - start.sys
  shp.time[[folder]] <- dt
  print(folder)
  print(dt)
}
# Shapefile time: 4m + 3.76s
shp.total.time <- shp.time %>% sum.time()
```

```{r getData1.51, eval=FALSE, include=FALSE}
tracking.gps.df %>% summary()
tracking.gps.df %>% head()
```

El dataset consolidado comprende 21683856 registros de telemetría GPS provenientes del sistema de monitoreo de transporte público DTPR, capturados durante el mes de agosto de 2025 a través de 31 unidades operativas diferentes.

### Matriz de correlación

```{r tracking.gps.df.corr.0, eval=FALSE, include=FALSE}
tracking.gps.df.cor <- tracking.gps.df %>% mutate(
  EVT_SERVICIO_ID = EVT_SERVICIO_ID %>% as.numeric() %>% replace.na(),
  EVT_PPU = EVT_PPU %>% as.numeric() %>% replace.na(),
  EVT_GPS_TIME_CHILE_STR = EVT_GPS_TIME_CHILE_STR %>% as.numeric(),
  EVT_GPS_TIME_UTC_0 = EVT_GPS_TIME_UTC_0 %>% as.numeric(),
  EVT_CARPETA = EVT_CARPETA %>% as.numeric() %>% replace.na()
) %>%
  select(-EVT_REGISTRO_ID, -EVT_SEÑAL) %>%
  cor(use = "pairwise.complete.obs")
```


```{r tracking.gps.df.corr, echo=FALSE, message=FALSE, warning=FALSE}
tracking.gps.df.cor %>%
  ggcorrplot() +
  theme(axis.text.x = element_text(angle = 90, hjust = 1, vjust = 0.5, size = 8), axis.text.y = element_text(size = 8))
tracking.gps.df.cor %>%
  round(digits = 3) %>%
  kable() %>%
  kable_styling(full_width = F) %>%
  column_spec(1, bold = T, border_right = T) %>%
  add_header_above(c(" " = 1, "Variables" = ncol(tracking.gps.df.cor))) %>%
  pack_rows("Variables", 1, nrow(tracking.gps.df.cor)) %>%
  row_spec(0, angle = 90, extra_css = "vertical-align: bottom;") %>%
  column_spec(2:ncol(tracking.gps.df.cor), width = "0.25cm")
```


```{r tracking.gps.df.corr.export, eval=FALSE, include=FALSE}
tracking.gps.df.cor %>% write.csv(file = "corr/tracking.gps.df.csv")
```

### Metadatos de Procesamiento

- **Tiempo total de lectura**: 7 minutos 8.22 segundos
- **Tiempo de consolidación**: 5 minutos 0.63 segundos
- **Tiempo de transformación**: 30 minutos 7.08 segundos
- **Total de procesamiento**: 42 minutos 15.93 segundos

### Período de Monitoreo

- **Fecha inicial**: 1 de agosto de 2025, 00:00:00 (hora Chile)
- **Fecha final**: 1 de septiembre de 2025, 00:05:27 (hora Chile)
- **Duración**: 31 días completos + 5 minutos
- **Cobertura temporal**: Mes completo de agosto 2025

### Granularidad temporal (separado por EVT_PPU)

- Diferencia Mínima: 1 segundo
- Diferencia Máxima: 25 días, 22 horas, 42 minutos, 36 segundos
- Diferencia Media: 6 minutos, 51 segundos (lineal); 50.44 segundos (logarítmico)
- Diferencia Mediana: 1 minuto, 1 segundo
- Desviación Standard: 2 horas, 24 minutos, 17.9 segundos (lineal); 2.11 segundos (logarítmico)

```{r tracking.gps.df.time, echo=FALSE, message=FALSE, warning=FALSE}
differences <- tracking.gps.df %>%
  mutate(
    prev.time = EVT_GPS_TIME_CHILE_STR %>% lag(),
    same.ppu = (EVT_PPU == (EVT_PPU %>% lag(default = EVT_PPU %>% first() - 1)))
  ) %>%
  mutate(
    diff = if_else(same.ppu, (EVT_GPS_TIME_CHILE_STR - prev.time) %>% as.numeric(), NA_real_)
  ) %>%
  pull(diff)
positive.diff <- differences[differences > 0]
#positive.diff %>% summary()
ggplot() +
  geom_histogram(aes(x = positive.diff)) +
  scale_x_log10()
```

**Outliers**: Media y desviación standard (logarítmico)

```{r tracking.gps.df.time.ol, echo=FALSE, message=FALSE, warning=FALSE}
is.outlier <- positive.diff %>% is.outlier.m.n.sd(func = log)
ggplot() +
  geom_histogram(aes(x = positive.diff, fill = is.outlier)) +
  scale_x_log10()
```

Hay 495364 outliers inferiores y 195594 outliers superiores, dando un total de 680053 outliers

### Distribución Temporal

```{r tracking.gps.df.month.time, echo=FALSE, message=FALSE, warning=FALSE}
tracking.gps.df.dates <- data.frame(
  Hora = tracking.gps.df$EVT_GPS_TIME_CHILE_STR %>% hour(),
  `Día de la Semana` = tracking.gps.df$EVT_GPS_TIME_CHILE_STR %>% weekdays() %>% factor(levels = weekdays)
)
tracking.gps.df.dates %>%
  count(Hora, Día.de.la.Semana, .drop = F) %>%
  ggplot() +
  geom_tile(aes(y = Hora, x = Día.de.la.Semana, fill = n)) +
  scale_fill_gradientn(
    name = "Cantidad",
    colors = c(
      "red",
      "orange",
      "yellow",
      "lightgreen",
      "darkgreen"
    )
  ) +
  labs(y = "Hora", x = "Día de la Semana")
tracking.gps.df.dates %>%
  count(Día.de.la.Semana, Hora, .drop = F) %>%
  spread(key = Día.de.la.Semana, value = n, fill = 0) %>%
  as.data.frame() %>%
  column_to_rownames("Hora") %>%
  as.matrix() %>%
  kable()
```

### Granularidad Espacial

- Distancia Mínima: 0
- Distancia Máxima: 35.27 kilómetros
- Distancia Media: 334 metros (lineal); 214.26 metros (logarítmico)
- Distancia Mediana: 240.1 metros
- Desviación Standard: 919.54 metros (lineal); 3.04 metros (logarítmico)

```{r tracking.gps.df.space, echo=FALSE, message=FALSE, warning=FALSE}
tracking.gps.df.distances <- tracking.gps.df %>%
  mutate(
    prev.x = X_EVT_GPS_LON %>% lag(),
    prev.y = Y_EVT_GPS_LAT %>% lag(),
    same.ppu = (EVT_PPU == (EVT_PPU %>% lag(default = EVT_PPU %>% first() - 1)))
  ) %>%
  mutate(
    dist = if_else(same.ppu, haversine.dist(Y_EVT_GPS_LAT, X_EVT_GPS_LON, prev.y, prev.x), NA_real_)
  ) %>%
  pull(dist)
#tracking.gps.df.distances %>% summary()
ggplot() +
  geom_histogram(aes(x = tracking.gps.df.distances)) +
  scale_x_log10()
```

**Outliers**: Media y desviación standard (logarítmico)

```{r tracking.gps.df.space.ol, echo=FALSE, message=FALSE, warning=FALSE}
is.outlier <- tracking.gps.df.distances %>% is.outlier.m.n.sd(func = function(n) ifelse(n > 0, n %>% log(), NA))
ggplot() +
  geom_histogram(aes(x = tracking.gps.df.distances, fill = is.outlier)) +
  scale_x_log10()
```

Hay 1929562 outliers inferiores y 40637 outliers superiores, dando un total de 1970199 outliers

### Distribución Espacio-Temporal

*Pendiente*

```{r tracking.gps.df.spacetime.0, eval=FALSE, echo=FALSE, message=FALSE, warning=FALSE}
plan(multisession, workers = availableCores() - 1)
tracking.gps.df.points <- tracking.gps.df %>%
  st_as_sf(
    coords = c("X_EVT_GPS_LON", "Y_EVT_GPS_LAT"),
    crs = 4326
  ) %>% st_make_valid()
cities.map.optimized <- mapa_comunas %>%
  st_as_sf() %>%
  st_transform(crs = 4326) %>%
  st_make_valid()
comuna_names <- setNames(
  codigos_territoriales$nombre_comuna,
  codigos_territoriales$codigo_comuna
)
cities.map.optimized <- cities.map.optimized %>%
  mutate(
    nombre_comuna = comuna_names[codigo_comuna %>% as.character()]
  )
cities.map.index <- cities.map.optimized %>%
  mutate(geometry_idx = geometry) %>%
  st_as_sf()
available.cores <- availableCores()
n.chunks <- 10000
chunk.size <- (tracking.gps.df.points %>% nrow() / n.chunks) %>% ceiling()
tracking.gps.df.cities <- tracking.gps.df.points %>%
  mutate(chunk.id = (row_number() - 1) %% chunk.size) %>%
  group_by(chunk.id) %>%
  group_split() %>%
  future_map_dfr(function(.x, idx = NULL) {
    if (idx %>% is.null()) {
      message(Sys.time(), " - Procesando un chunk...")
    } else {
      message(Sys.time(), " - Procesando chunk ", idx, " de ", n.chunks)
    }
    st_join(.x, cities.map.optimized, join = st_intersects)
  }, .options = furrr_options(seed = T))
tracking.gps.df.spacetime <- data.frame(
  Semana = tracking.gps.df$EVT_GPS_TIME_CHILE_STR %>% floor_date(unit = "week", week_start = 1),
  Día = tracking.gps.df$EVT_GPS_TIME_CHILE_STR %>% weekday() %>% factor(levels = weekdays)
)
```


```{r tracking.gps.df.spacetime.1, eval=FALSE, echo=FALSE, message=FALSE, warning=FALSE}
tracking.gps.df.spacetime %>%
  count(Año, Región, .drop = F) %>%
  ggplot() +
  geom_tile(aes(y = Región, x = Año, fill = n)) +
  scale_fill_gradientn(
    name = "Cantidad",
    colors = c(
      "red",
      "orange",
      "yellow",
      "lightgreen",
      "darkgreen"
    )
  ) +
  labs(y = "Región", x = "Año") +
  scale_y_discrete(labels = label_wrap_gen(width = 20))
```

### Características Operacionales del Sistema

**Flota y Rutas Monitoreadas**

- **Rutas más frecuentes**:
  - "13GS": 617591 registros
  - "43JT": 500230 registros
  - "14HT": 481486 registros
- **Vehículos más activos**:
  - "FSLC62": 27847 registros
  - "TTHL10": 25901 registros
  - "SZDZ86": 25483 registros
  
```{r tracking.gps.df.routes, echo=FALSE, message=FALSE, warning=FALSE}
tracking.gps.df[tracking.gps.df$EVT_SERVICIO_ID %in% (tracking.gps.df %>%
  count(EVT_SERVICIO_ID) %>%
  slice_max(n, n = 10) %>%
  pull(EVT_SERVICIO_ID)),] %>%
  ggplot() +
  geom_bar(aes(
    y = EVT_SERVICIO_ID %>% fct_infreq() %>% fct_rev(),
    fill = EVT_SERVICIO_ID
  ),
  show.legend = F) +
  labs(y = "Ruta", title = "10 rutas más frecuentes")
```

**Distribución Direccional**

- **Sentido ida (0)**: 10809559 registros
- **Sentido vuelta (1)**: 10671146 registros
- **Sentido indeterminado (-1)**: 203151 registros

```{r tracking.gps.df.direction, echo=FALSE, message=FALSE, warning=FALSE}
tracking.gps.df[tracking.gps.df$EVT_SERVICIO_ID %in% (tracking.gps.df %>%
  count(EVT_SERVICIO_ID) %>%
  slice_max(n, n = 10) %>%
  pull(EVT_SERVICIO_ID)),] %>%
  ggplot() +
  geom_bar(aes(
    y = EVT_SERVICIO_ID %>% fct_infreq() %>% fct_rev(),
    fill = EVT_SENTIDO %>% as.factor()
  )) +
  labs(y = "Ruta", fill = "Sentido", title = "10 rutas más frecuentes")
```

**Métricas de Desempeño Técnico**

_Calidad de Señal GPS_

- Muy Buena: 17924666 registros
- Buena: 966491 registros
- Regular: 592320 registros
- Mala: 2200379 registros

_EVT GPS DOP_

- Mínimo: 1
- Máximo: 498
- Media: 2.57 (lineal); 1.43 (logarítmico)
- Mediana: 1
- Desviación Standard: 4.1 (lineal); 2.57 (logarítmico)

```{r tracking.gps.df.signal, echo=FALSE, message=FALSE, warning=FALSE}
tracking.gps.df %>% ggplot() +
  geom_histogram(aes(x = EVT_GPS_DOP, fill = EVT_SEÑAL)) +
  scale_x_log10()
```

**Outliers**: Cuartiles (logarítmico)

```{r tracking.gps.df.signal.ol, echo=FALSE, message=FALSE, warning=FALSE}
is.outlier <- tracking.gps.df$EVT_GPS_DOP %>% is.outlier.q(func = log)
tracking.gps.df %>% ggplot() +
  geom_histogram(aes(x = EVT_GPS_DOP, fill = is.outlier)) +
  scale_x_log10()
```

Hay 3759190 outliers superiores

_Velocidades Operacionales_

- Mínimo: 0 km/h
- Máxmimo: 193 km/h
- Media: 21.69 km/h (lineal); 22.32 km/h (logarítmico)
- Mediana: 19 km/h
- Desviación Standard: 19.27 km/h (lineal); 2.12 km/h (logarítmico)

```{r tracking.gps.df.speed, echo=FALSE, message=FALSE, warning=FALSE}
tracking.gps.df %>% 
  ggplot() +
  geom_histogram(aes(x = EVT_GPS_VEL)) +
  scale_x_log10()
```

**Outliers**: Media y desviación standard (logarítmico)

```{r tracking.gps.df.speed.ol, echo=FALSE, message=FALSE, warning=FALSE}
is.outlier <- tracking.gps.df$EVT_GPS_VEL %>% is.outlier.m.n.sd(func = function(n) ifelse(n > 0, n %>% log(), NA))
tracking.gps.df %>% ggplot() +
  geom_histogram(aes(x = EVT_GPS_VEL, fill = is.outlier)) +
  scale_x_log10()
```

Hay 5446945 outliers inferiores y 2068 outliers superiores, dando un total de 5449013 outliers

_Estados del Sistema_

- Motor encendido (1): 21619957 registros
- Motor apagado (0): 63899 registros

```{r tracking.gps.df.states, echo=FALSE, message=FALSE, warning=FALSE}
tracking.gps.df[tracking.gps.df$EVT_ESTADO_MOTOR_GPS == 0,] %>%
  ggplot() +
  geom_bar(aes(
    y = EVT_CARPETA %>% fct_infreq() %>% fct_rev()
  )) +
  labs(y = "Carpeta", title = "Registros con motor apagado")
```

### Procesamiento y Normalización de Datos

**Paso a paso**

- Se lee la carpeta
- Se crea la columna "EVT_CARPETA" con el nombre de la carpeta
- Se unifican los datasets en uno
- "EVT_SERVICIO_ID" se convierte en factor
- "EVT_PPU" se convierte en factor
- "EVT_GPS_TIME_CHILE_STR" se convierte en POSIXct con formato "%d/%m/%Y %H:%M:%S" y zona horaria "America/Santiago"
- "EVT_GPS_TIME_UTC_0" se convierte en POSIXct con formato "%d/%m/%Y %H:%M:%S"
- En "Y_EVT_GPS_LAT", se reemplaza "," por "." y se convierte en numérico
- En "X_EVT_GPS_LON", se reemplaza "," por "." y se convierte en numérico
- En "EVT_DISTANCIA_RECORRIDA (Km)", se reemplaza "," por "." y se convierte en numérico
- En "EVT_DISTACIA_A_SERVICIO", se reemplaza "," por "." y se convierte en numérico
- "EVT_CARPETA" se convierte en factor
- Se crea la columna "EVT_SEÑAL" a partir de los valores de la columna "EVT_GPS_DOP":
  - `Excelente`: $EVT GPS DOP < 1$
  - `Muy Buena`: $1 \leq EVT GPS DOP < 2$
  - `Buena`: $2 \leq EVT GPS DOP < 5$
  - `Regular`: $5 \leq EVT GPS DOP \leq 10$
  - `Mala`: $EVT GPS DOP > 10$

### Análisis por Unidad Operativa

**Patrones de Operación por Unidad**

_Frecuencia de Reporte_

- **Típico**: 1:00-1:03 minutos entre registros por vehículo (mediana, separado por patente)
- **Variaciones**: UN52_265 muestra intervalos más irregulares (3.5s - 1min) (mediana, separado por patente)
- **Consistencia**: Mayoría mantiene intervalos estables

_Distribución por Unidad_

- **Mayor volumen**: UN80_274 (1459884 registros)
- **Menor volumen**: UN52_265 (118026 registros)
- **Promedio por unidad**: ~699479 registros

_Características Específicas Destacables_

- **UN13_247**: Operación exclusiva de ruta "13GS"
- **UN18_254**: Frecuencia muy consistente (1:03-1:03.5 min) (mediana, separado por patente)
- **UN22_257**: Mayor variabilidad en intervalos (59s - 22:31 min) (mediana, separado por patente)
- **UNB0_277**: Única unidad con datos en septiembre

```{r getData1.6, eval=FALSE, include=FALSE}
cities <- c(
  "Arica" = "arica",
  "Iquique" = "iquique",
  "Tocopilla" = "tocopilla",
  "Antofagasta" = "antofagasta",
  "Calama" = "calama",
  "Coquimbo - La Serena" = "serena",
  "Gran Valparaíso" = "valparaiso",
  "Región Metropolitana" = "rm-sur",
  "Linares" = "linares",
  "Chillán" = "chillan",
  "Gran Concepción" = "concepcion",
  "Villarrica" = "villarrica",
  "Temuco" = "temuco",
  "Valdivia" = "valdivia",
  "Osorno" = "osorno",
  "Puerto Montt" = "ptomontt",
  #"Castro" = "castro",
  #"Quellón" = "quellon",
  "Punta Arenas" = "punta-arenas"
)

get.data.gtfs.rt <- function(city = "concepcion"){
  if(!(city %in% cities)){
    stop(paste(city, "isn't a valid city code"))
  }
  url <- paste0("https://datamanager.dtpr.transapp.cl/data/gtfs-rt/", city, ".proto")
  response <- GET(url, add_headers("X-API-KEY" = token))
  if (response$status_code != 200) {
    stop(paste("Request Error:", response$status_code, "|", response))
  }
  raw.data <- content(response, "raw")
  temp.file <- tempfile(fileext = ".pb")
  writeBin(raw.data, temp.file)
  feed <- temp.file %>% readBin(what = "raw", n = file.info(temp.file)$size)
  safe.raw.to.char <- function(raw.vec){
    printable <- raw.vec[raw.vec >= 32 & raw.vec <= 126 | raw.vec == 10 | raw.vec == 13]
    printable %>% as.raw() %>% rawToChar()
  }
  visible.text <- feed %>% safe.raw.to.char()
  extract.all <- function(str){
    str_extract_all(visible.text, str)[[1]]
  }
  uuids <- extract.all("[a-f0-9]{8}-[a-f0-9]{4}-[a-f0-9]{4}-[a-f0-9]{4}-[a-f0-9]{12}")
  trip.ids <- extract.all("[0-9]{3}_[A-Z]_[A-Z]_[0-9]{4}")
  hours <- extract.all("[0-9]{2}:[0-9]{2}:[0-9]{2}")
  dates0 <- extract.all("202[0-9]{5}")
  dates <- paste(substr(dates0, 1, 4), substr(dates0, 5, 6), substr(dates0, 7, 8), sep = "-")
  datetimes <- paste(dates, hours) %>% as.POSIXct(format = "%Y-%m-%d %H:%M:%S")
  route.ids <- extract.all("P[0-9]{5}|[0-9]{4}0")
  timestamps <- extract.all("[0-9]{10}")
  datetimes.utc <- timestamps %>% as.numeric() %>% as.POSIXct(origin = "1970-01-01", tz = "UTC")
  datetimes.utc %>% summary()
  n <- min(uuids %>% length(), trip.ids %>% length(), route.ids %>% length() / 5)
  city.name <- cities[cities == city] %>% names()
  df <- data.frame(
    vehicle.uuid = if (uuids %>% length() >= n) uuids[1:n] else rep(NA, n),
    trip.id = if (trip.ids %>% length() >= n) trip.ids[1:n] else rep(NA, n),
    start.datetime = if (datetimes %>% length() >= n) datetimes[1:n] else rep(NA, n),
    sample.route.id = if (route.ids %>% length() >= n) route.ids[1:n] else rep(NA, n),
    city = city.name,
    stringsAsFactors = F
  )
  return(df)
}

get.all.data.gtfs.rt <- function(print.time = T){
  df.list <- list()
  if(print.time) dt.list <- list()
  for(city in cities){
    if(print.time) start.sys <- Sys.time()
    df <- city %>% get.data.gtfs.rt()
    if(print.time) end.sys <- Sys.time()
    city.name <- cities[cities == city] %>% names()
    df.list[[city.name]] <- df
    if(print.time){
      dt.sys <- end.sys - start.sys
      print(city.name)
      print(dt.sys)
      dt.list[[city.name]] <- dt.sys
    }
  }
  grfs.df <- df.list %>% bind_rows()
  grfs.df$city <- grfs.df$city %>% as.factor()
  grfs.df$trip.id <- grfs.df$trip.id %>% as.factor()
  grfs.df$sample.route.id <- grfs.df$sample.route.id %>% as.factor()
  if(print.time) {
    grfs.dt <- dt.list %>% sum.time()
    print("Total Reading Time:")
    print(grfs.dt)
  }
  return(grfs.df)
}

save.data.gtfs.rt <- function(city = "concepcion"){
  now <- Sys.time()
  real.time <- get.data.gtfs.rt()
  file.name <- paste(city, now %>% as.character() %>% str_replace_all(" ", "_") %>% str_replace_all(":", "."), "rds", sep = ".")
  file.path. <- paste("~/GitHub/data-sets-analysis/rds-files/DTPR API", file.name, sep = "/")
  real.time %>% saveRDS(file = file.path.)
}

run.continuously <- function(
  interval.minutes = 30,
  city = "concepcion"
) {
  while(T) {
    tryCatch({
      city %>% save.data.gtfs.rt()
      cat("GTFS data saved at", Sys.time() %>% as.character(), "\n")
    }, error = function(e) {
      cat("Error:", e$message, "at", Sys.time() %>% as.character(), "\n")
    })
    Sys.sleep(interval.minutes * 60)
  }
}
```


## Data accidentes de carabineros.xlsx

```{r getData2, eval=FALSE, include=FALSE}
# Data accidentes de carabineros.xlsx
police.accidents <- read_excel("data/Data accidentes de carabineros.xlsx", 
    col_types = c("numeric", "date", "skip", 
        "date", "text", "text", "text", "text", 
        "text", "numeric", "numeric", "numeric", 
        "numeric", "numeric", "text", "text", 
        "text", "text", "text"))
police.accidents$FECHA <- paste(police.accidents$FECHA, police.accidents$HORA %>% format(format = "%H:%M:%S")) %>% as.POSIXct(format = "%Y-%m-%d %H:%M")
police.accidents <- police.accidents %>% select(-HORA)
police.accidents$ZONA <- police.accidents$ZONA %>% as.factor()
police.accidents$COMUNA <- police.accidents$COMUNA %>% as.factor()
police.accidents$TIPO <- police.accidents$TIPO %>% as.factor()
police.accidents$CAUSA <- police.accidents$CAUSA %>% as.factor()
police.accidents$SECTOR <- police.accidents$SECTOR %>% as.factor()
police.accidents$KM <- police.accidents$KM %>% as.numeric()
police.accidents$PARTE <- police.accidents$PARTE %>% as.numeric()
police.accidents$TRIBUNAL <- police.accidents$TRIBUNAL %>% as.factor()
police.accidents$TIPO %>% summary()
police.accidents$`MACRO TIPO` <- police.accidents$TIPO %>% as.character()
police.accidents$`MACRO TIPO`[
  police.accidents$TIPO %in% c(
    "CHOQUE",
    "CHOQUE FRONTAL",
    "CHOQUE LATERAL",
    "CHOQUE POSTERIOR"
  )
] <- "CHOQUE"
police.accidents$`MACRO TIPO`[
  police.accidents$TIPO %in% c(
    "COLISION",
    "COLISION FRONTAL",
    "COLISION LATERAL",
    "COLISION PERPENDICULAR",
    "COLISION POR ALCANCE"
  )
] <- "COLISION"
police.accidents$`MACRO TIPO` <- police.accidents$`MACRO TIPO` %>% as.factor()
police.accidents %>% summary()
```

El dataset comprende 5739 registros de accidentes de tránsito documentados por Carabineros de Chile durante un período concentrado de 30 días.

### Matriz de correlación

```{r police.accidents.corr, echo=FALSE, message=FALSE, warning=FALSE}
police.accidents.cor <- police.accidents %>% mutate(
  FECHA = FECHA %>% as.numeric(),
  ZONA = ZONA %>% as.numeric() %>% replace.na(),
  COMUNA = COMUNA %>% as.numeric() %>% replace.na(),
  TIPO = TIPO %>% as.numeric() %>% replace.na(),
  CAUSA = CAUSA %>% as.numeric() %>% replace.na(),
  SECTOR = SECTOR %>% as.numeric() %>% replace.na(),
  CALLE_1 = CALLE_1 %>% as.factor() %>% as.numeric() %>% replace.na(),
  CALLE_2 = CALLE_2 %>% as.factor() %>% as.numeric() %>% replace.na(),
  TRIBUNAL = TRIBUNAL %>% as.numeric() %>% replace.na(),
  `MACRO TIPO` = `MACRO TIPO` %>% as.numeric() %>% replace.na()
) %>%
  cor(use = "pairwise.complete.obs")
police.accidents.cor %>%
  ggcorrplot() +
  theme(axis.text.x = element_text(angle = 90, hjust = 1, vjust = 0.5, size = 8), axis.text.y = element_text(size = 8))
police.accidents.cor %>%
  round(digits = 3) %>%
  kable() %>%
  kable_styling(full_width = F) %>%
  column_spec(1, bold = T, border_right = T) %>%
  add_header_above(c(" " = 1, "Variables" = ncol(police.accidents.cor))) %>%
  pack_rows("Variables", 1, nrow(police.accidents.cor)) %>%
  row_spec(0, angle = 90, extra_css = "vertical-align: bottom;") %>%
  column_spec(2:ncol(police.accidents.cor), width = "0.5cm")
```


```{r police.accidents.corr.export, eval=FALSE, include=FALSE}
police.accidents.cor %>% write.csv(file = "corr/police.accidents.csv")
```

### Período de Análisis

- **Cobertura temporal**: 1 al 30 de marzo de 2025 (30 días)
- **Registros diarios promedio**: aproximadamente 191 accidentes

### Granularidad Temporal

- Diferencia Mínima: 1 hora
- Diferencia Máxima: 4 horas
- Diferencia Media: 1 hora, 3 minutos, 10 segundos
- Diferencia Mediana: 1 hora
- Desviación Standard: 17 minutos, 12.53 segundos

```{r police.accidents.time, echo=FALSE, message=FALSE, warning=FALSE}
differences <- (police.accidents$FECHA - c(NA, police.accidents$FECHA[1:(police.accidents %>% nrow() - 1)])) %>% as.numeric()
positive.diff <- differences[differences > 0]
#positive.diff %>% summary()
ggplot() +
  geom_bar(aes(x = differences / 3600)) +
  scale_y_log10() +
  labs(x = "Diferencia de tiempo entre registros (horas)")
```

### Distribución Temporal

```{r police.accidents.month.time, echo=FALSE, message=FALSE, warning=FALSE}
police.accidents.dates <- data.frame(
  Hora = police.accidents$FECHA %>% hour(),
  `Día de la Semana` = police.accidents$FECHA %>% weekdays() %>% factor(levels = weekdays)
)
police.accidents.dates %>%
  count(Hora, Día.de.la.Semana, .drop = F) %>%
  ggplot() +
  geom_tile(aes(y = Hora, x = Día.de.la.Semana, fill = n)) +
  scale_fill_gradientn(
    name = "Cantidad",
    colors = c(
      "red",
      "orange",
      "yellow",
      "lightgreen",
      "darkgreen"
    )
  ) +
  labs(y = "Hora", x = "Día de la Semana")
police.accidents.dates %>%
  count(Día.de.la.Semana, Hora, .drop = F) %>%
  spread(key = Día.de.la.Semana, value = n, fill = 0) %>%
  as.data.frame() %>%
  column_to_rownames("Hora") %>%
  as.matrix() %>%
  kable()
```

### Distribución Geográfica

- **Regiones con mayor siniestralidad**:
    - Región Metropolitana (1513 casos)
    - Región del Biobío (699 casos)
    - Región del Maule (574 casos)

```{r police.accidents.regions, echo=FALSE, message=FALSE, warning=FALSE}
police.accidents %>% ggplot() +
  geom_bar(aes(y = ZONA %>% fct_infreq() %>% fct_rev())) +
  labs(y = "ZONA")
```

- **Comunas más afectadas**:
    - Concepción (193 accidentes)
    - Temuco (175 accidentes)
    - Arica (150 accidentes)

```{r police.accidents.cities, echo=FALSE, message=FALSE, warning=FALSE}
police.accidents[police.accidents$COMUNA %in% (police.accidents %>%
  count(COMUNA) %>%
  slice_max(n, n = 10) %>%
  pull(COMUNA)),] %>% ggplot() +
  geom_bar(aes(y = COMUNA %>% fct_infreq() %>% fct_rev(), fill = ZONA)) +
  labs(y = "COMUNA")
```

- **KM**:
    - **Rango**: Entre 0 y 112000 km
    - **Media**: 1629 km
    - **Mediana**: 312 km
    - **Nulos**: 3210 registros

```{r police.accidents.km, echo=FALSE, message=FALSE, warning=FALSE}
police.accidents %>% ggplot() +
  geom_density(aes(x = KM, colour = `MACRO TIPO`)) +
  scale_x_log10()
```

- **PARTE**:
    - **Rango**: Entre $1 y 4157
    - **Media**: $491.4
    - **Mediana**: $282

```{r police.accidents.pay, echo=FALSE, message=FALSE, warning=FALSE}
police.accidents %>% ggplot() +
  geom_density(aes(x = PARTE, colour = `MACRO TIPO`)) +
  scale_x_log10()
```

### Distribución Espacio-Temporal

**Región y Semana**

```{r police.accidents.spacetime.0, echo=FALSE, message=FALSE, warning=FALSE}
police.accidents.spacetime <- data.frame(
  Semana = police.accidents$FECHA %>% floor_date(unit = "week", week_start = 1),
  Día = police.accidents$FECHA %>% weekdays() %>% factor(levels = weekdays),
  Región = police.accidents$ZONA,
  Comuna = police.accidents$COMUNA
)
police.accidents.spacetime %>%
  count(Semana, Región, .drop = F) %>%
  ggplot() +
  geom_tile(aes(y = Región, x = Semana, fill = n)) +
  scale_fill_gradientn(
    name = "Cantidad",
    colors = c(
      "red",
      "orange",
      "yellow",
      "lightgreen",
      "darkgreen"
    )
  ) +
  labs(y = "Región", x = "Semana") +
  scale_y_discrete(labels = label_wrap_gen(width = 20))
police.accidents.spacetime %>% mutate(
    Región = Región %>% factor(levels = police.accidents.spacetime %>%
      count(Región) %>%
        slice_max(n, n = police.accidents.spacetime$Región %>%
            levels() %>%
            length()) %>%
        arrange(n %>% desc()) %>%
        pull(Región)
    )
  ) %>%
  count(Semana, Región, .drop = F) %>%
  spread(key = Semana, value = n, fill = 0) %>%
  as.data.frame() %>%
  column_to_rownames("Región") %>%
  as.matrix() %>%
  kable()
```

**Región y Día de la Semana**

```{r police.accidents.spacetime.1, echo=FALSE, message=FALSE, warning=FALSE}
police.accidents.spacetime %>%
  count(Día, Región, .drop = F) %>%
  ggplot() +
  geom_tile(aes(y = Región, x = Día, fill = n)) +
  scale_fill_gradientn(
    name = "Cantidad",
    colors = c(
      "red",
      "orange",
      "yellow",
      "lightgreen",
      "darkgreen"
    )
  ) +
  labs(y = "Región", x = "Día de la Semana") +
  scale_y_discrete(labels = label_wrap_gen(width = 20))
police.accidents.spacetime %>% mutate(
    Región = Región %>% factor(levels = police.accidents.spacetime %>%
      count(Región) %>%
        slice_max(n, n = police.accidents.spacetime$Región %>%
            levels() %>%
            length()) %>%
        arrange(n %>% desc()) %>%
        pull(Región)
    )
  ) %>%
  count(Día, Región, .drop = F) %>%
  spread(key = Día, value = n, fill = 0) %>%
  as.data.frame() %>%
  column_to_rownames("Región") %>%
  as.matrix() %>%
  kable()
```

**Comuna y Semana**

```{r police.accidents.spacetime.2, echo=FALSE, message=FALSE, warning=FALSE}
police.accidents.spacetime[police.accidents.spacetime$Comuna %in% (police.accidents.spacetime %>%
  count(Comuna) %>%
  slice_max(n, n = 10) %>%
  pull(Comuna)),] %>% mutate(
    Comuna = Comuna %>% factor(levels = police.accidents.spacetime %>%
      count(Comuna) %>%
        slice_max(n, n = 10) %>%
        arrange(n %>% desc()) %>%
        pull(Comuna) %>% rev()
    )
  ) %>%
  count(Semana, Comuna, .drop = F) %>%
  ggplot() +
  geom_tile(aes(y = Comuna, x = Semana, fill = n)) +
  scale_fill_gradientn(
    name = "Cantidad",
    colors = c(
      "red",
      "orange",
      "yellow",
      "lightgreen",
      "darkgreen"
    )
  ) +
  labs(y = "Comuna", x = "Semana") +
  scale_y_discrete(labels = label_wrap_gen(width = 20))
police.accidents.spacetime %>% mutate(
    Comuna = Comuna %>% factor(levels = police.accidents.spacetime %>%
      count(Comuna) %>%
        slice_max(n, n = police.accidents.spacetime$Comuna %>%
            levels() %>%
            length()) %>%
        arrange(n %>% desc()) %>%
        pull(Comuna)
    )
  ) %>%
  count(Semana, Comuna, .drop = F) %>%
  spread(key = Semana, value = n, fill = 0) %>%
  as.data.frame() %>%
  column_to_rownames("Comuna") %>%
  as.matrix() %>%
  kable()
```

**Comuna y Día de la Semana**

```{r police.accidents.spacetime.3, echo=FALSE, message=FALSE, warning=FALSE}
police.accidents.spacetime[police.accidents.spacetime$Comuna %in% (police.accidents.spacetime %>%
  count(Comuna) %>%
  slice_max(n, n = 10) %>%
  pull(Comuna)),] %>% mutate(
    Comuna = Comuna %>% factor(levels = police.accidents.spacetime %>%
      count(Comuna) %>%
        slice_max(n, n = 10) %>%
        arrange(n %>% desc()) %>%
        pull(Comuna) %>% rev()
    )
  ) %>%
  count(Día, Comuna, .drop = F) %>%
  ggplot() +
  geom_tile(aes(y = Comuna, x = Día, fill = n)) +
  scale_fill_gradientn(
    name = "Cantidad",
    colors = c(
      "red",
      "orange",
      "yellow",
      "lightgreen",
      "darkgreen"
    )
  ) +
  labs(y = "Comuna", x = "Día de la Semana") +
  scale_y_discrete(labels = label_wrap_gen(width = 20))
police.accidents.spacetime %>% mutate(
    Comuna = Comuna %>% factor(levels = police.accidents.spacetime %>%
      count(Comuna) %>%
        slice_max(n, n = police.accidents.spacetime$Comuna %>%
            levels() %>%
            length()) %>%
        arrange(n %>% desc()) %>%
        pull(Comuna)
    )
  ) %>%
  count(Día, Comuna, .drop = F) %>%
  spread(key = Día, value = n, fill = 0) %>%
  as.data.frame() %>%
  column_to_rownames("Comuna") %>%
  as.matrix() %>%
  kable()
```

### Clasificación de Accidentes

- **Tipos predominantes**:
    - Colisión: 2,936 casos
    - Choque: 1,801 casos
    - Atropello: 461 casos

```{r police.accidents.types, echo=FALSE, message=FALSE, warning=FALSE}
police.accidents %>% ggplot() +
  geom_bar(aes(y = `MACRO TIPO` %>% fct_infreq() %>% fct_rev(), fill = ZONA %>% fct_infreq())) +
  labs(y = "MACRO TIPO", fill = "ZONA")
```

- **Distribución por sector**:
    - Urbano: 4,432 casos
    - Rural: 1,304 casos
    - Vía férrea: 3 casos

```{r police.accidents.sectors, echo=FALSE, message=FALSE, warning=FALSE}
police.accidents %>% ggplot() +
  geom_bar(aes(y = SECTOR %>% fct_infreq() %>% fct_rev(), fill = ZONA %>% fct_infreq())) +
  labs(y = "SECTOR", fill = "ZONA")
```

### Procesamiento y Normalización de Datos

**Paso a paso**

- "FECHA" se convirtió en la concatenación de "FECHA" y "HORA" y se convierte en POSIXct con formato "%d/%m/%Y %H:%M"
- Se elimina la columna "HORA"
- "ZONA" se convierte en factor
- "COMUNA" se convierte en factor
- "TIPO" se convierte en factor
- "CAUSA" se convierte en factor
- "SECTOR" se convierte en factor
- "KM" se convierte en numérico
- "PARTE" se convierte en numérico
- "TRIBUNAL" se convierte en factor
- Se crea la columna "MACRO TIPO" con el valor de "TIPO", pero unificando los valores de "CHOQUE", "CHOQUE FRONTAL", "CHOQUE LATERAL"y "CHOQUE POSTERIOR" como "CHOQUE" y "COLISION", "COLISION FRONTAL", "COLISION LATERAL", "COLISION PERPENDICULAR", "COLISION POR ALCANCE" como "COLISION"
- "MACRO TIPO" se convierte en factor

## Incidentes de tráfico radio.xlsx

```{r getData3, eval=FALSE, include=FALSE}
# Incidentes de tráfico radio.xlsx
file.path <- "data/Incidentes de tráfico radio.xlsx"
sheet.names <- file.path %>% excel_sheets()
date.sheets <- sheet.names[grepl("^\\d{1,2}-\\d{1,2}$", sheet.names)]
radio.accidents <- list()
cell.colors <- list()
get.cells.colors <- function(file.path, sheet.name, column.indices) {
  wb <- file.path %>% loadWorkbook()
  styles <- wb %>% getStyles()
  sheet <- wb[[sheet.name]]
  colors.list <- list()
  for(col.idx in column.indices) {
    col.letter <- col.idx %>% int2col()
    cell.refs <- paste0(col.letter, 1:(sheet$rows %>% length()))
    colors <- sapply(cell.refs, function(cell.ref) {
      cell.style <- sheet$styleObjects[[which(sapply(sheet$styleObjects, function(x) x$rows == as.numeric(gsub("\\D", "", cell.ref)) & x$cols == col.idx))]]
      if(!is.null(cell.style)) {
        cell.style$style$fill$fillFg
      } else {
        NA
      }
    })
    colors.list[[colnames(sheet)[col.idx]]] <- colors
  }
  colors.list
}
get.cell.colors.simple <- function(file.path, sheet.name) {
  wb <- file.path %>% loadWorkbook()
  all.styles <- wb %>% getStyles()
  sheet.styles <- wb$styleObjects[grepl(paste0("^", sheet.name, "\\."), wb$styleObjects %>% names())]
  sheet.data <- wb %>% read.xlsx(sheet = sheet.name)
  col.names <- sheet.data %>% names()
  tipo.cols <- (col.names %in% c("Tipo de incidente", "tipo de incidente")) %>% which()
  if(length(tipo.cols) == 0){
    list()
  } else {
    colors.df <- NA %>% matrix(nrow = sheet.data %>% nrow(), ncol = tipo.cols %>% length()) %>% data.frame()
    names(colors.df) <- col.names[tipo.cols]
    for(style.obj in wb$styleObjects) {
      if(style.obj$sheet == sheet.name && style.obj$cols %in% tipo.cols) {
        col.name <- col.names[style.obj$cols]
        for(row in style.obj$rows) {
          if(row <= colors.df %>% nrow()) {
            colors.df[row, col.name] <- style.obj$style$fill$fillFg
          }
        }
      }
    }
    colors.df
  }
}
get.cell.colors.tidyxl <- function(file.path, sheet.name) {
  cells <- file.path %>% xlsx_cells(sheets = sheet.name)
  formats <- file.path %>% xlsx_formats()
  target.cols <- c("Tipo de incidente", "tipo de incidente")
  col.indices <- cells %>%
    filter(!(character %>% is.na()) | !(numeric %>% is.na())) %>% 
    group_by(col) %>%
    summarise(
      header = character %>% first(na_rm = T),
      .groups = "drop"
    ) %>%
    filter(header %in% target.cols) %>%
    pull(col)
  if(col.indices %>% length() == 0){
    data.frame(
      row = integer(),
      col = integer(),
      color = character()
    )
  } else {
    colors.df <- cells %>%
      filter(col %in% col.indices) %>%
      select(row, col, address, character, numeric, local_format_id) %>%
      mutate(
        value = coalesce(character, numeric %>% as.character())
      ) %>%
      mutate(
        color = ifelse(
          !(local_format_id %>% is.na()),
          formats$local$fill$patternFill$fgColor$rgb[local_format_id],
          NA_character_
        )
      ) %>%
      select(row, col, value, color)
    colors.df
  }
}
for(sheet in date.sheets) {
  df <- file.path %>% read_excel(sheet = sheet)
  colors.info <- get.cell.colors.tidyxl(file.path, sheet)
  day.month <- (sheet %>% strsplit(., "-"))[[1]]
  day <- day.month[1] %>% as.numeric()
  month <- day.month[2] %>% as.numeric()
  ## ¿De qué año es?
  comp.date <- paste("2024", month, day, sep = "-") %>% as.Date()
  df$fecha <- comp.date
  df$`#ID` <- df$`#ID` %>% as.numeric()
  df$Hora <- df$Hora %>% as.numeric() %>% as.POSIXct() %>% format(format = "%H:%M")
  radio.accidents[[sheet]] <- df
  cell.colors[[sheet]] <- colors.info
}
radio.accidents.df <- radio.accidents %>% bind_rows()
all.colors.df <- cell.colors %>% bind_rows(.id = "sheet.name")
radio.accidents.df$sheet.name <- NA_character_
radio.accidents.df$original.row <- NA_integer_
row.counter <- 1
for(sheet in date.sheets) {
  n.rows <- radio.accidents[[sheet]] %>% nrow()
  if(n.rows > 0) {
    radio.accidents.df$sheet.name[row.counter:(row.counter + n.rows - 1)] <- sheet
    radio.accidents.df$original.row[row.counter:(row.counter + n.rows - 1)] <- 1:n.rows
  }
  row.counter <- row.counter + n.rows
}
radio.accidents.df <- radio.accidents.df %>%
  left_join(
    all.colors.df %>%
      select(sheet.name, row, color) %>%
      rename(original.row = row),
    by = c("sheet.name", "original.row")
  )
radio.accidents.df <- radio.accidents.df[!(radio.accidents.df$coord %>% is.na() | radio.accidents.df$`Reporte completo? (SI/NO)` %>% is.na()),]
radio.accidents.df$coord[!(radio.accidents.df$lat %>% is.na())] <- radio.accidents.df$lat[!(radio.accidents.df$lat %>% is.na())]
radio.accidents.df <- radio.accidents.df %>% select(-c(lat, `tipo de incidente`, ...7, ...13, sheet.name, original.row))
radio.accidents.df$dir[!(radio.accidents.df$...12 %>% is.na()) & (radio.accidents.df$dir %>% is.na())] <- radio.accidents.df$...12[!(radio.accidents.df$...12 %>% is.na()) & (radio.accidents.df$dir %>% is.na())]
radio.accidents.df <- radio.accidents.df %>% select(-...12)
radio.accidents.df$`Reporte completo? (SI/NO)`[(radio.accidents.df$`Reporte completo? (SI/NO)` %in% c("is", "si", "SI", "su")) %>% which()] <- "SI"
radio.accidents.df$`Reporte completo? (SI/NO)`[(radio.accidents.df$`Reporte completo? (SI/NO)` %in% c("no", "NO")) %>% which()] <- "NO"
radio.accidents.df$`Reporte completo? (SI/NO)`[(radio.accidents.df$`Reporte completo? (SI/NO)` == "-") %>% which()] <- NA
radio.accidents.df$`es incidente de tráfico? (si/no)`[(radio.accidents.df$`es incidente de tráfico? (si/no)` %in% c("si", "SI")) %>% which()] <- "SI"
radio.accidents.df$`es incidente de tráfico? (si/no)`[(radio.accidents.df$`es incidente de tráfico? (si/no)` %in% c("no", "NO")) %>% which()] <- "NO"
radio.accidents.df$dir[radio.accidents.df$dir %in% c("-", "n/a", "n/A")] <- NA
radio.accidents.df$dir[radio.accidents.df$dir %in% c("e-o", "E-O")] <- "E-O"
radio.accidents.df$dir[radio.accidents.df$dir %in% c("o-e", "O-E")] <- "O-E"
radio.accidents.df$dir[radio.accidents.df$dir %in% c("n-s", "n.s", "N-S")] <- "N-S"
radio.accidents.df$dir[radio.accidents.df$dir %in% c("s-n", "S-N")] <- "S-N"
radio.accidents.df$dir[radio.accidents.df$dir %in% c("n-s. s-n", "n-s.s-n", "N-S, S-N")] <- "N-S, S-N"
radio.accidents.df$dir[radio.accidents.df$dir %in% c("s-n.n-s", "S-N, N-S")] <- "S-N, N-S"
radio.accidents.df$`Reporte completo? (SI/NO)` <- radio.accidents.df$`Reporte completo? (SI/NO)` %>% as.factor()
radio.accidents.df$`es incidente de tráfico? (si/no)` <- radio.accidents.df$`es incidente de tráfico? (si/no)` %>% as.factor()
radio.accidents.df$dir <- radio.accidents.df$dir %>% as.factor()
radio.accidents.df$color <- radio.accidents.df$color %>% as.factor()
color_mapping <- c(
  "FF00B0F0" = "Intervenciones de Emergencia", 
  "FF00FFFF" = "Congestión",
  "FFFF0000" = "Accidente de tránsito",
  "FFFF00FF" = "Obstrucciones en la vía",
  "FFFF6600" = "Problema Infraestructura de control de tránsito",
  "FFFFC000" = "Condición de tráfico",
  "FFFFFF00" = "Congestión",
  "FF00B050" = "Otros"
)
radio.accidents.df$`Tipo de incidente` <- ifelse(
  radio.accidents.df$color %>% is.na(),
  "Congestión",
  color_mapping[radio.accidents.df$color]
) %>% as.factor()
radio.accidents.df <- radio.accidents.df %>% select(-color)
radio.accidents.df <- radio.accidents.df %>% fill(Hora, .direction = "down")
radio.accidents.df <- radio.accidents.df %>% separate(coord, into = c("lat", "lng"), sep = ",\\s*") %>% mutate(lat = lat %>% as.numeric(), lng = lng %>% as.numeric())
radio.accidents.df <- radio.accidents.df[!(radio.accidents.df$lat %>% is.na()),]
radio.accidents.df$Hora <- paste(radio.accidents.df$fecha, radio.accidents.df$Hora) %>% as.POSIXct(format = "%Y-%m-%d %H:%M")
radio.accidents.df <- radio.accidents.df %>% select(-fecha)
radio.accidents.df %>% summary()
radio.accidents.df.sf <- radio.accidents.df %>% st_as_sf(
  coords = c("lng", "lat"),
  crs = 4326
)
radio.accidents.df.sf %>% st_write(.,
  "~/GitHub/data-sets-analysis/shapefiles/radio.accidents.df.shp",
  driver = "ESRI Shapefile",
  append = F
)
```

El dataset contiene 312 registros de incidentes de tráfico reportados a través de sistemas de radio durante un período de 37 días.

### Matriz de correlación

```{r radio.accidents.df.corr, echo=FALSE, message=FALSE, warning=FALSE}
radio.accidents.df.cor <- radio.accidents.df %>% mutate(
  Hora = Hora %>% as.numeric(),
  `es incidente de tráfico? (si/no)` = `es incidente de tráfico? (si/no)` %>% as.numeric() %>% replace.na(),
  `Reporte completo? (SI/NO)` = `Reporte completo? (SI/NO)` %>% as.numeric() %>% replace.na(),
  dir = dir %>% as.numeric() %>% replace.na(),
  `Tipo de incidente` = `Tipo de incidente` %>% as.numeric() %>% replace.na()
) %>%
  select(-`Detalle (inicio/fin incidente, etc)`, -Localización, -Dirección, -Extra) %>%
  cor(use = "pairwise.complete.obs")
radio.accidents.df.cor %>%
  ggcorrplot() +
  theme(axis.text.x = element_text(angle = 90, hjust = 1, vjust = 0.5))
radio.accidents.df.cor %>% round(digits = 4) %>% kable()
```


```{r radio.accidents.df.corr.export, eval=FALSE, include=FALSE}
radio.accidents.df.cor %>% write.csv(file = "corr/radio.accidents.df.csv")
```

### Período de Registro

- **Duración**: 15 de julio al 20 de agosto de 2024
- **Cobertura temporal**: 37 días de monitoreo continuo

### Granularidad Temporal

- Diferencia Mínima: 1 minuto
- Diferencia Máxima: 9 días, 13 horas, 50 minutos
- Diferencia Media: 5 horas, 44 minutos, 36 segundos (lineal); 1 hora, 4 minutos, 36.08 segundos (logarítmico)
- Diferencia Mediana: 1 hora, 5 minutos, 30 segundos
- Desviación Standard: 20 horas, 32 minutos, 52.93 segundos (lineal); 6.31 segundos (logarítmico)

```{r radio.accidents.df.time, echo=FALSE, message=FALSE, warning=FALSE}
radio.accidents.df.sorted <- radio.accidents.df[radio.accidents.df$Hora %>% order(),]
differences <- (radio.accidents.df.sorted$Hora - c(NA, radio.accidents.df.sorted$Hora[1:(radio.accidents.df.sorted %>% nrow() - 1)])) %>% as.numeric()
positive.diff <- differences[differences > 0]
#positive.diff %>% summary()
ggplot() +
  geom_histogram(aes(x = positive.diff)) +
  scale_x_log10()
```

**Outliers**: Media y desviación standard (logarítmico)

```{r radio.accidents.df.time.ol, echo=FALSE, message=FALSE, warning=FALSE}
is.outlier <- positive.diff %>% is.outlier.m.n.sd(func = log)
ggplot() +
  geom_histogram(aes(x = positive.diff, fill = is.outlier)) +
  scale_x_log10()
```

Hay 1929562 outliers inferiores y 40637 outliers superiores, dando un total de 1970199 outliers

### Distribución Temporal

```{r radio.accidents.df.month.time, echo=FALSE, message=FALSE, warning=FALSE}
radio.accidents.df.dates <- data.frame(
  Hora = radio.accidents.df$Hora %>% hour(),
  `Día de la Semana` = radio.accidents.df$Hora %>% weekdays() %>% factor(levels = weekdays)
)
radio.accidents.df.dates %>%
  count(Hora, Día.de.la.Semana, .drop = F) %>%
  ggplot() +
  geom_tile(aes(y = Hora, x = Día.de.la.Semana, fill = n)) +
  scale_fill_gradientn(
    name = "Cantidad",
    colors = c(
      "red",
      "orange",
      "yellow",
      "lightgreen",
      "darkgreen"
    )
  ) +
  labs(y = "Hora", x = "Día de la Semana")
radio.accidents.df.dates %>%
  count(Día.de.la.Semana, Hora, .drop = F) %>%
  spread(key = Día.de.la.Semana, value = n, fill = 0) %>%
  as.data.frame() %>%
  column_to_rownames("Hora") %>%
  as.matrix() %>%
  kable()
```

### Granularidad Espacial

- Distancia Mínima: 22.19 centímetros
- Distancia Máxima: 23.31 kilómetros
- Distancia Media: 733.6 metros (lineal); 130.55 metros (logarítmico)
- Distancia Mediana: 141.1 metros
- Desviación Standard: 2.49 kilómetros (lineal); 6.48 metros (logarítmico)

```{r radio.accidents.df.space, echo=FALSE, message=FALSE, warning=FALSE}
distances <- min.haversine.distances(
  radio.accidents.df$lat,
  radio.accidents.df$lng
)
#distances %>% summary()
ggplot() +
  geom_histogram(aes(x = distances)) +
  scale_x_log10()
```

**Outliers**: Media y desviación standard (logarítmico)

```{r radio.accidents.df.space.ol, echo=FALSE, message=FALSE, warning=FALSE}
is.outlier <- distances %>% is.outlier.m.n.sd(func = log)
ggplot() +
  geom_histogram(aes(x = distances, fill = is.outlier)) +
  scale_x_log10()
```

Hay 6 outliers inferiores y 8 outliers superiores, dando un total de 14 outliers

### Distribución Espacio-Temporal

**Comuna y Día de la Semana**

```{r radio.accidents.df.spacetime.0, echo=FALSE, message=FALSE, warning=FALSE}
radio.accidents.df.points <- radio.accidents.df %>%
  st_as_sf(
    coords = c("lng", "lat"),
    crs = 4326
  )
radio.accidents.df.cities <- st_join(radio.accidents.df.points, cities.map, join = st_intersects)
radio.accidents.df.spacetime <- data.frame(
  Hora = radio.accidents.df$Hora %>% hour(),
  Día = radio.accidents.df$Hora %>% weekdays() %>% factor(levels = weekdays),
  Comuna = radio.accidents.df.cities$nombre_comuna %>% replace.na(r = "Concepción - San Pedro") %>% factor(levels = radio.accidents.df.cities$nombre_comuna %>% replace.na(r = "Concepción - San Pedro") %>% fct_infreq() %>% levels())
)
radio.accidents.df.spacetime %>%
  count(Día, Comuna, .drop = F) %>%
  ggplot() +
  geom_tile(aes(y = Comuna %>% fct_rev(), x = Día, fill = n)) +
  scale_fill_gradientn(
    name = "Cantidad",
    colors = c(
      "red",
      "orange",
      "yellow",
      "lightgreen",
      "darkgreen"
    )
  ) +
  labs(y = "Comuna", x = "Día de la Semana") +
  scale_y_discrete(labels = label_wrap_gen(width = 20))
radio.accidents.df.spacetime %>%
  count(Comuna, Día, .drop = F) %>%
  spread(key = Día, value = n, fill = 0) %>%
  as.data.frame() %>%
  column_to_rownames("Comuna") %>%
  as.matrix() %>%
  kable()
```

**Comuna y Hora**

```{r radio.accidents.df.spacetime.1, echo=FALSE, message=FALSE, warning=FALSE}
radio.accidents.df.spacetime %>%
  count(Hora, Comuna, .drop = F) %>%
  ggplot() +
  geom_tile(aes(y = Comuna %>% fct_rev(), x = Hora, fill = n)) +
  scale_fill_gradientn(
    name = "Cantidad",
    colors = c(
      "red",
      "orange",
      "yellow",
      "lightgreen",
      "darkgreen"
    )
  ) +
  labs(y = "Comuna", x = "Hora") +
  scale_y_discrete(labels = label_wrap_gen(width = 20))
radio.accidents.df.spacetime %>%
  count(Comuna, Hora, .drop = F) %>%
  spread(key = Hora, value = n, fill = 0) %>%
  as.data.frame() %>%
  column_to_rownames("Comuna") %>%
  as.matrix() %>%
  kable()
```


### Clasificación de Incidentes

- **Naturaleza del incidente**:
    - **Incidentes de tráfico**: 263 casos
    - **No incidentes de tráfico**: 1 caso
    - **No especificado**: 48 casos

- **Completitud de reportes**:
    - **Reportes completos**: 257 casos
    - **Reportes incompletos**: 55 casos

```{r radio.accidents.df.complete.report, echo=FALSE, message=FALSE, warning=FALSE}
radio.accidents.df %>% ggplot() +
  geom_bar(aes(y = `Reporte completo? (SI/NO)` %>% fct_infreq() %>% fct_rev(), fill = `es incidente de tráfico? (si/no)` %>% fct_infreq())) +
  labs(y = "Reporte completo? (SI/NO)", fill = "es incidente de tráfico? (si/no)")
```

### Tipología de Incidentes

*Distribución por categoría*:

- Congestión: 157 casos
- Accidentes de tránsito: 43 casos
- Problema Infraestructura de control de tránsito: 38 casos
- Condición de tráfico: 25 casos
- Obstrucciones en la vía: 20 casos
- Intervenciones de emergencia: 5 casos
- Otros: 24 casos

```{r radio.accidents.df.types, echo=FALSE, message=FALSE, warning=FALSE}
radio.accidents.df %>% ggplot() +
  geom_bar(aes(y = `Tipo de incidente` %>% fct_infreq() %>% fct_rev(), fill = dir %>% fct_infreq())) +
  labs(y = "Tipo de incidente", fill = "dir") +
  scale_y_discrete(labels = label_wrap_gen(width = 15))
```


### Direccionalidad del Tráfico Afectado

**Patrones de flujo vehicular impactado**:

- Sur a Norte (S-N): 53 casos
- Norte a Sur (N-S): 51 casos
- Bidireccional (N-S, S-N): 17 casos
- Este a Oeste (E-O): 15 casos
- Oeste a Este (O-E): 10 casos
- Ambos sentidos (a/s): 2 casos
- Bidireccional (S-N, N-S): 1 caso
- No especificado: 163 casos

```{r radio.accidents.df.dir, echo=FALSE, message=FALSE, warning=FALSE}
radio.accidents.df %>% ggplot() +
  geom_bar(aes(fill = `Tipo de incidente` %>% fct_infreq(), y = dir %>% fct_infreq() %>% fct_rev())) +
  labs(fill = "Tipo de incidente", y = "dir") +
  scale_fill_discrete(labels = label_wrap_gen(width = 15))
```

### Procesamiento y Normalización de Datos

**Paso a paso**

- Se lee la hoja
- Se lee el color de la columna "tipo de incidente"
- Se crea la columna "fecha" con el nombre de la hoja
- "#ID" se convierte en numérico
- "Hora" se convierte en POSIXct con formato "%H:%M"
- Se unen los datasets en uno
- Se crea la columna "sheet.name" con el nombre de las hojas
- Se crea la columna "original.row" con el número de la fila original
- Se crea la columna "color" con el código del color de la columna "tipo de incidente"
- Se eliminan las filas en las que "coord" o "Reporte completo? (SI/NO)" es nulo
- Se eliminan las columnas "lat", "tipo de incidente", "...7", "...13", "sheet.name", "original.row"
- "dir" toma el valor de "...12" cuando "...12" no es nulo y "dir" es nulo
- Se elimina la columna "...12"
- En "Reporte completo? (SI/NO)", los valores "is", "si", "SI" y "su" se unifican como "SI", los valores "no" y "NO", como "NO" y "-" se considera nulo
- En "es incidente de tráfico? (si/no)", los valores "si" y "SI" se unifican como "SI" y los valores "no" y "NO", como "NO"
- En "dir", los valores "e-o" y "E-O" se unifican como "E-O", "o-e" y "O-E", como "O-E", "n-s", "n.s" y "N-S", como "N-S", "s-n" y "S-N" como "S-N", "n-s. s-n", "n-s.s-n" y "N-S, S-N", como "N-S, S-N", "s-n.n-s" y "S-N, N-S", como "S-N, N-S" y "-", "n/a" y "n/A" se consideran nulos
- "Reporte completo? (SI/NO)" se convierte en factor
- "es incidente de tráfico? (si/no)" se convierte en factor
- "dir" se convierte en factor
- "color" se convierte en factor
- Se crea la columna "Tipo de incidente" a partir de "color":
  - "Congestión" cuando es nulo
  - "Intervenciones de Emergencia" cuando es <font color="#FF00B0F0">FF00B0F0</font>
  - "Congestión" cuando es <font color="#FF00FFFF">FF00FFFF</font>
  - "Accidente de tránsito" cuando es <font color="#FFFF0000">FFFF0000</font>
  - "Obstrucciones en la vía" cuando es <font color="#FFFF00FF">FFFF00FF</font>
  - "Problema Infraestructura de control de tránsito" cuando es <font color="#FFFF6600">FFFF6600</font>
  - "Condición de tráfico" cuando es <font color="#FFFFC000">FFFFC000</font>
  - "Congestión" cuando es <font color="#FFFFFF00">FFFFFF00</font>
  - "Otros" cuando es <font color="#FF00B050">FF00B050</font>
- Se elimina la columna "color"
- Cuando "Hora" es nulo, toma el valor de la fila anterior
- "coord" se separa en "lat" y "lng", separado por ",\\s*" y se convierten en numéricos
- Se eliminan las filas en las que "lat" es nulo
- "Hora" se convirtió en la concatenación de "fecha" y "hora" y se convierte en POSIXct con el formato "%Y-%m-%d %H:%M"

## Med velo CHIGUAYANTE.xlsx

```{r getData4, eval=FALSE, include=FALSE}
# Med velo CHIGUAYANTE.xlsx
date <- "2024-06-25"
file.path <- "data/Med velo CHIGUAYANTE.xlsx"
directions <- file.path %>% excel_sheets()
chiguayante.speed <- list()
for(sheet in directions) {
  df <- file.path %>% read_excel(sheet = sheet)
  df$dirección <- sheet
  df$`Lugar (dirección)` <- df$`Lugar (dirección)`[!(df$`Lugar (dirección)` %>% is.na())] %>% paste(collapse = ", ")
  chiguayante.speed[[sheet]] <- df
}
chiguayante.speed.df <- chiguayante.speed %>% bind_rows()
chiguayante.speed.df <- chiguayante.speed.df %>% select(-c(...5, ...6, ...7, ...8, ...9, ...10, ...11, ...12, ...13))
chiguayante.speed.df <- chiguayante.speed.df[!(chiguayante.speed.df$`Velocidad [km/hr]` %>% is.na()),]
chiguayante.speed.df <- chiguayante.speed.df %>% fill(Hora, .direction = "down")
chiguayante.speed.df$Hora <- paste(date, chiguayante.speed.df$Hora %>% as.POSIXct() %>% format(., "%H:%M:%S")) %>% as.POSIXct(format = "%Y-%m-%d %H:%M:%S")
chiguayante.speed.df$Comentario[chiguayante.speed.df$Comentario %in% c(
  "auto, doblo a Lo Plaza",
  "Auto, doblo a Lo Plaza",
  "Auto, gira a Lo Plaza"
)] <- "Auto, dobló a Lo Plaza"
chiguayante.speed.df$Comentario[chiguayante.speed.df$Comentario %in% c(
  "camion",
  "Camion"
)] <- "Camión"
chiguayante.speed.df$Comentario[chiguayante.speed.df$Comentario %in% c(
  "micro",
  "Micro"
)] <- "Micro"
chiguayante.speed.df$Comentario <- chiguayante.speed.df$Comentario %>% as.factor()
chiguayante.speed.df$dirección <- chiguayante.speed.df$dirección %>% as.factor()
chiguayante.speed.df$`Lugar (dirección)` <- chiguayante.speed.df$`Lugar (dirección)` %>% as.factor()
chiguayante.speed.df$Vehículo <- "Auto"
chiguayante.speed.df$Vehículo[chiguayante.speed.df$Comentario %in% c("Camión", "Micro", "MOTO", "retroexcavadora")] <- chiguayante.speed.df$Comentario[chiguayante.speed.df$Comentario %in% c("Camión", "Micro", "MOTO", "retroexcavadora")] %>% as.character()
chiguayante.speed.df$Vehículo <- chiguayante.speed.df$Vehículo %>% as.factor()
chiguayante.speed.df %>% summary()
```

El dataset contiene 338 mediciones de velocidad vehicular capturadas en el paradero "Bdo O'Higgins - Arauco" de Chiguayante, monitoreando el flujo entre Concepción y Hualqui.

### Matriz de correlación

```{r chiguayante.speed.df.corr, echo=FALSE, message=FALSE, warning=FALSE}
chiguayante.speed.df.cor <- chiguayante.speed.df %>% mutate(
  Hora = Hora %>% as.numeric(),
  Comentario = Comentario %>% as.numeric() %>% replace.na(),
  `Lugar (dirección)` = `Lugar (dirección)` %>% as.numeric() %>% replace.na(),
  dirección = dirección %>% as.numeric() %>% replace.na(),
  Vehículo = Vehículo %>% as.numeric() %>% replace.na()
) %>%
  cor(use = "pairwise.complete.obs")
chiguayante.speed.df.cor %>%
  ggcorrplot() +
  theme(axis.text.x = element_text(angle = 90, hjust = 1, vjust = 0.5))
chiguayante.speed.df.cor %>% kable()
```


```{r chiguayante.speed.df.corr.export, eval=FALSE, include=FALSE}
chiguayante.speed.df.cor %>% write.csv(file = "corr/chiguayante.speed.df.csv")
```

### Contexto Operacional

- **Ubicación**: Paradero "Bdo O'Higgins - Arauco", Chiguayante
- **Corredor vial**: Concepción - Hualqui
- **Período de medición**: 26 de junio de 2024 entre las 09:06 y las 17:58 horas
- **Duración**: Aproximadamente 9 horas de monitoreo continuo

### Granularidad Temporal

- Diferencia Mínima: 2 minutos
- Diferencia Máxima: 2 horas, 50 minutos
- Diferencia Media: 35 minutos, 55 segundos (lineal); 10 minutos, 43.7 segundos (logarítmico)
- Diferencia Mediana: 6 minutos
- Desviación Standard: 1 hora, 4 minutos, 2.76 segundos (lineal); 4.39 segundos (logarítmico)

```{r chiguayante.speed.df.time, echo=FALSE, message=FALSE, warning=FALSE}
chiguayante.speed.df.sorted <- chiguayante.speed.df[chiguayante.speed.df$Hora %>% order(),]
differences <- chiguayante.speed.df.sorted %>%
  mutate(
    prev.time = Hora %>% lag(),
    same.dir = (dirección == (dirección %>% lag(default = dirección %>% first() - 1)))
  ) %>%
  mutate(
    diff = if_else(same.dir, (Hora - prev.time) %>% as.numeric(), NA_real_)
  ) %>%
  pull(diff)
positive.differences <- differences[differences > 0]
#positive.differences %>% summary()
ggplot() +
  geom_histogram(aes(x = positive.differences)) +
  scale_x_log10()
```

**Outliers**: Cuartiles (logarítmico)

```{r chiguayante.speed.df.time.ol, echo=FALSE, message=FALSE, warning=FALSE}
is.outlier <- positive.differences %>% is.outlier.q(func = log)
ggplot() +
  geom_histogram(aes(x = positive.differences, fill = is.outlier)) +
  scale_x_log10()
```

Hay 2 outliers superiores

### Distribución Temporal

```{r chiguayante.speed.df.month.time, echo=FALSE, message=FALSE, warning=FALSE}
chiguayante.speed.df.dates <- data.frame(
  Hora = chiguayante.speed.df$Hora %>% hour(),
  Dirección = chiguayante.speed.df$dirección
)
chiguayante.speed.df.dates %>%
  count(Hora, Dirección, .drop = F) %>%
  ggplot() +
  geom_tile(aes(y = Hora, x = Dirección, fill = n)) +
  scale_fill_gradientn(
    name = "Cantidad",
    colors = c(
      "red",
      "orange",
      "yellow",
      "lightgreen",
      "darkgreen"
    )
  ) +
  labs(y = "Hora", x = "Dirección")
chiguayante.speed.df.dates %>%
  count(Dirección, Hora, .drop = F) %>%
  spread(key = Dirección, value = n, fill = 0) %>%
  as.data.frame() %>%
  column_to_rownames("Hora") %>%
  as.matrix() %>%
  kable()
```

### Análisis de Velocidades

- **Rango de velocidades**: 3 a 71 km/h
- **Velocidad promedio**: 44.27 km/h
- **Velocidad mediana**: 43 km/h
- **Distribución**: Relativamente simétrica alrededor de la mediana

```{r chiguayante.speed.df.speed, echo=FALSE, message=FALSE, warning=FALSE}
chiguayante.speed.df %>% ggplot() +
  stat_density2d_filled(aes(y = `Velocidad [km/hr]`, x = Hora))
```

### Composición Vehicular

**Tipos de vehículos identificados**:

- **Automóviles**: 273 registros
- **Microbuses**: 52 registros
- **Camiones**: 9 registros
- **Motos**: 3 registros
- **Retroexcavadora**: 1 registro

```{r chiguayante.speed.df.vehicles, echo=FALSE, message=FALSE, warning=FALSE}
chiguayante.speed.df %>% ggplot() +
  geom_bar(aes(y = Vehículo %>% fct_infreq() %>% fct_rev(), fill = dirección %>% fct_infreq())) +
  labs(y = "Vehículo", fill = "dirección")
```

### Patrones de Movimiento

**Distribución direccional**:

- **Hacia Concepción**: 163 mediciones
- **Hacia Hualqui**: 175 mediciones
- **Balance**: Ligero predominio del flujo hacia Hualqui

```{r chiguayante.speed.df.direction, echo=FALSE, message=FALSE, warning=FALSE}
chiguayante.speed.df %>% ggplot() +
  geom_bar(aes(y = dirección %>% fct_infreq() %>% fct_rev())) +
  labs(y = "dirección")
```

### Comportamientos Específicos

**Maniobras documentadas**:

- "Auto, dobló a Lo Plaza": 8 casos
- "Auto, iba a doblar a Lo Plaza": 1 caso
- "auto, se percibe cola": 1 caso

```{r chiguayante.speed.df.comment, echo=FALSE, message=FALSE, warning=FALSE}
chiguayante.speed.df[chiguayante.speed.df$Vehículo == "Auto" & !(chiguayante.speed.df$Comentario %>% is.na()),] %>% ggplot() +
  geom_bar(aes(y = Comentario %>% fct_infreq() %>% fct_rev())) +
  labs(y = "Comentario")
```

### Procesamiento y Normalización de Datos

**Paso a paso**

- Se lee la hoja
- Se crea la columna "dirección" con el nombre de la hoja
- La columna "Lugar (dirección)" se unen en un único valor que se arrastra hacia todas las filas de la hoja
- Se unen los datasets
- Se eliminan las columnas "...5", "...6", "...7", "...8", "...9", "...10", "...11", "...12" y "...13"
- Se eliminan las filas en las que "Velocidad [km/hr]" es nulo
- Las filas donde "Hora" es nulo toman el valor de la fila anterior
- La columna "Hora" se convierte en la concatenación entre "2024-06-25" y "Hora" y se convierte en un POSIXct con formato "%Y-%m-%d %H:%M:%S"
- En la columna "Comentario", los valores "auto, doblo a Lo Plaza", "Auto, doblo a Lo Plaza" y "Auto, gira a Lo Plaza" se unifican como "Auto, dobló a Lo Plaza", los valores "camion" y "Camion", como "Camión" y "micro" y "Micro", como "Micro"
- "Comentario" se convierte en factor
- "dirección" se convierte en factor
- "Lugar (dirección)" se convierte en factor
- Se crea la columna "Vehículo" que toma el valor de la columna "Comentario" si su valor es "Camión", "Micro", "MOTO" o "retroexcavadora" y "Auto" en otro caso
- "Vehículo" se convierte en factor

## Med velo LA VEGA.xlsx

```{r getData5, eval=FALSE, include=FALSE}
#Med velo LA VEGA.xlsx
date <- "2024-06-25"
file.path <- "data/Med velo LA VEGA.xlsx"
sheets <- excel_sheets(file.path)
directions <- sheets[grepl("21", sheets) & grepl("mayo", sheets)]
vega.speed <- list()
for(sheet in directions) {
  df <- file.path %>% openxlsx::read.xlsx(sheet = sheet, colNames = T, fillMergedCells = T, detectDates = T, skipEmptyCols = F, skipEmptyRows = F)
  df <- df[, 2:5]
  df$Hora[!(df$Hora %>% is.na()) & df$Hora %>% as.numeric() > 1 & !((!(df$Hora %>% is.na()) & df$Hora %>% as.numeric() %>% is.numeric() & df$Hora %>% as.numeric() > 1) %>% is.na())] <- ((df$Hora[!(df$Hora %>% is.na()) & df$Hora %>% as.numeric() > 1 & !((!(df$Hora %>% is.na()) & df$Hora %>% as.numeric() %>% is.numeric() & df$Hora %>% as.numeric() > 1) %>% is.na())] %>% as.numeric() %>% round(digits = 2)) / 24) %>% as.character()
  df <- df %>% fill(Hora, .direction = "down")
  hour <- ((df$Hora %>% as.numeric()) * 24) %>% floor()
  minute <- (((df$Hora %>% as.numeric()) * 24 - hour) * 60) %>% floor()
  df$Hora <- sprintf("%02d:%02d:00", hour, minute)
  df$Hora <- paste(date, df$Hora) %>% as.POSIXct(format = "%Y-%m-%d %H:%M:%S")
  df$dirección <- sheet
  df$`Lugar.(dirección)` <- df$`Lugar.(dirección)`[!(df$`Lugar.(dirección)` %>% is.na())] %>% paste(collapse = ", ")
  vega.speed[[sheet]] <- df
}
vega.speed.df <- vega.speed %>% bind_rows()
vega.speed.df <- vega.speed.df %>% fill(Hora, .direction = "down")
vega.speed.df <- vega.speed.df[!(vega.speed.df$`Velocidad.[km/hr]` %>% is.na()),]
vega.speed.df$Comentario[vega.speed.df$Comentario %in% c(
  "cola por funeral",
  "forman cola"
)] <- "Forman cola"
vega.speed.df$Comentario[vega.speed.df$Comentario %in% c(
  "llega a cola",
  "llegan a cola",
  "llegan a cola, aprox 4 vehiculos",
  "llegan a cola formada antes de medir"
)] <- "Llega a cola"
vega.speed.df$Comentario[vega.speed.df$Comentario %in% c(
  "llegan juntos",
  "llegan juntos ",
  "llegan juntos, cola aprox 8 a 10 autos",
  "llegan juntos, generan cola"
)] <- "Llegan juntos"
vega.speed.df$Comentario[vega.speed.df$Comentario %in% c(
  "micro",
  "Micro"
)] <- "Micro"
vega.speed.df$Comentario[vega.speed.df$Comentario %in% c(
  "moto",
  "Moto"
)] <- "Moto"
vega.speed.df$Comentario <- vega.speed.df$Comentario %>% as.factor()
vega.speed.df$`Lugar.(dirección)` <- vega.speed.df$`Lugar.(dirección)` %>% as.factor()
vega.speed.df$dirección <- vega.speed.df$dirección %>% as.factor()
vega.speed.df %>% summary()
```

El dataset contiene 432 mediciones de velocidad vehicular capturadas en el cruce de Briceños con Miraflores, monitoreando el flujo entre 21 de Mayo y Avenida Costanera a través del sector Miraflores.

### Matriz de correlación

```{r vega.speed.df.corr, echo=FALSE, message=FALSE, warning=FALSE}
vega.speed.df.cor <- vega.speed.df %>% mutate(
  Hora = Hora %>% as.numeric(),
  Comentario = Comentario %>% as.numeric() %>% replace.na(),
  `Lugar.(dirección)` = `Lugar.(dirección)` %>% as.numeric() %>% replace.na(),
  dirección = dirección %>% as.numeric() %>% replace.na()
) %>%
  cor(use = "pairwise.complete.obs")
vega.speed.df.cor %>%
  ggcorrplot() +
  theme(axis.text.x = element_text(angle = 90, hjust = 1, vjust = 0.5))
vega.speed.df.cor %>% kable()
```


```{r vega.speed.df.corr.export, eval=FALSE, include=FALSE}
vega.speed.df.cor %>% write.csv(file = "corr/vega.speed.df.csv")
```

### Contexto Operacional

- **Ubicación**: Esquina Briceños con Miraflores, La Vega
- **Corredores viales**:
    - 21 de Mayo -> Briceños -> Miraflores
    - Av. Costanera -> Miraflores -> 21 de Mayo
- **Período de medición**: 25 de junio de 2024 entre las 08:08 y las 17:58 horas
- **Duración**: Aproximadamente 10 horas de monitoreo continuo

### Granularidad Temporal

- Diferencia Mínima: 1 minuto
- Diferencia Máxima: 2 horas, 3 minutos
- Diferencia Media: 3 minutos, 40.5 segundos (lineal); 1 minuto, 56.08 segundos (logarítmico)
- Diferencia Mediana: 2 minutos
- Desviación Standard: 13 minutos, 10.19 segundos (lineal); 2.09 segundos (logarítmico)

```{r vega.speed.df.time, echo=FALSE, message=FALSE, warning=FALSE}
vega.speed.df.sorted <- vega.speed.df[vega.speed.df$Hora %>% order(),]
differences <- vega.speed.df.sorted %>%
  mutate(
    prev.time = Hora %>% lag(),
    same.dir = (dirección == (dirección %>% lag(default = dirección %>% first() - 1)))
  ) %>%
  mutate(
    diff = if_else(same.dir, (Hora - prev.time) %>% as.numeric(), NA_real_)
  ) %>%
  pull(diff)
positive.differences <- differences[differences > 0]
#positive.differences %>% summary()
ggplot() +
  geom_histogram(aes(x = positive.differences)) +
  scale_x_log10()
```

**Outliers**: Cuartiles (logarítmico)

```{r vega.speed.df.time.ol, echo=FALSE, message=FALSE, warning=FALSE}
is.outlier <- positive.differences %>% is.outlier.q(func = log)
ggplot() +
  geom_histogram(aes(x = positive.differences, fill = is.outlier)) +
  scale_x_log10()
```

Hay 2 outliers superiores

### Distribución Temporal

```{r vega.speed.df.month.time, echo=FALSE, message=FALSE, warning=FALSE}
vega.speed.df.dates <- data.frame(
  Hora = vega.speed.df$Hora %>% hour(),
  Dirección = vega.speed.df$dirección
)
vega.speed.df.dates %>%
  count(Hora, Dirección, .drop = F) %>%
  ggplot() +
  geom_tile(aes(y = Hora, x = Dirección, fill = n)) +
  scale_fill_gradientn(
    name = "Cantidad",
    colors = c(
      "red",
      "orange",
      "yellow",
      "lightgreen",
      "darkgreen"
    )
  ) +
  labs(y = "Hora", x = "Dirección")
vega.speed.df.dates %>%
  count(Dirección, Hora, .drop = F) %>%
  spread(key = Dirección, value = n, fill = 0) %>%
  column_to_rownames("Hora") %>%
  as.matrix() %>%
  kable()
```

### Análisis de Velocidades

- **Rango de velocidades**: 5 a 53 km/h
- **Velocidad promedio**: 28.87 km/h
- **Velocidad mediana**: 29 km/h
- **Distribución**: Concentrada en velocidades bajas-medias, típicas de tráfico urbano congestionado

```{r vega.speed.df.speed, echo=FALSE, message=FALSE, warning=FALSE}
vega.speed.df %>% ggplot() +
  stat_density2d_filled(aes(y = `Velocidad.[km/hr]`, x = Hora))
```

### Patrones de Movimiento

**Distribución direccional**:

- **Desde 21 de Mayo**: 250 mediciones
- **Hacia 21 de Mayo**: 182 mediciones
- **Balance**: Predominio del flujo desde 21 de Mayo

```{r vega.speed.df.direction, echo=FALSE, message=FALSE, warning=FALSE}
vega.speed.df %>% ggplot() +
  geom_bar(aes(y = dirección %>% fct_infreq() %>% fct_rev())) +
  labs(y = "dirección")
```

### Fenómenos de Congestión Documentados

**Patrones de formación de colas**:

- "Llegan juntos": 49 casos - agrupamiento vehicular sincronizado
- "Llega a cola": 22 casos - incorporación a colas existentes
- "Forman cola": 14 casos - generación de nuevas colas

**Composición vehicular adicional**:

- **Microbuses**: Registros específicamente identificados
- **Motocicletas**: Registros categorizados separadamente

### Procesamiento y Normalización de Datos

**Paso a paso**

- Se lee la hoja
- En la columna "Hora", se cambian las "," por ":" (ej: "8,15" -> "8:15")
- Las filas donde "Hora" es nulo toman el valor de la fila anterior
- La columna "Hora" se convierte en la concatenación entre "2024-06-25" y "Hora" y se convierte en un POSIXct con formato "%Y-%m-%d %H:%M:%S"
- Se crea la columna "dirección" con el nombre de la hoja
- La columna "Lugar (dirección)" se unen en un único valor que se arrastra hacia todas las filas de la hoja
- Se unen los datasets
- Se eliminan las filas en las que "Velocidad.[km/hr]" es nulo
- En la columna "Comentario", los valores "llega a cola", "llegan a cola", "llegan a cola, aprox 4 vehiculos" y "llegan a cola formada antes de medir" se unifican como "Llega a cola", los valores "llegan juntos", "llegan juntos ", "llegan juntos, cola aprox 8 a 10 autos" y "llegan juntos, generan cola", como "Llegan juntos", los valores "micro" y "Micro", como "Micro" y los valores "moto" y "Moto", como "Moto"
- "Comentario" se convierte en factor
- "Lugar (dirección)" se convierte en factor
- "dirección" se convierte en factor

## tb_gps_historial_eventos_202509161626(1).csv

```{r getData6, eval=FALSE, include=FALSE}
# tb_gps_historial_eventos_202509161626(1).csv
gps.events <- read_file("data/tb_gps_historial_eventos_202509161626(1).csv") %>% str_replace_all(., "\";\"", " ") %>% str_replace_all(., ",", ";") %>% str_replace_all(., "\"", "") %>% read.table(text = ., sep = ";", header = T, stringsAsFactors = F)
gps.events <- gps.events %>% select(-c(ubicacion_, velocidad_))
gps.events$fecha_auto <- gps.events$fecha_auto %>% as.POSIXct(format = "%Y-%m-%d %H:%M:%S")
gps.events$fecha_gps_ <- gps.events$fecha_gps_ %>% as.POSIXct(format = "%Y-%m-%d %H:%M:%S")
gps.events$evento_ <- gps.events$evento_ %>% as.factor()
gps.events$direccion_ <- gps.events$direccion_ %>% as.factor()
gps.events %>% nrow()
gps.events %>% summary()
gps.events.sf <- gps.events %>% st_as_sf(
  coords = c("longitud_", "latitud_"),
  crs = 4326
)
gps.events.sf %>% st_write(.,
  "~/GitHub/data-sets-analysis/shapefiles/gps.events.shp",
  driver = "ESRI Shapefile",
  append = F
)
```

El dataset contiene 1000 eventos registrados por sistemas GPS vehiculares, capturando transiciones de estado en una ventana temporal específica.

### Matriz de correlación

```{r gps.events.corr, echo=FALSE, message=FALSE, warning=FALSE}
gps.events.cor <- gps.events %>% mutate(
  fecha_auto = fecha_auto %>% as.numeric(),
  fecha_gps_ = fecha_gps_ %>% as.numeric(),
  evento_ = evento_ %>% as.numeric() %>% replace.na(),
  direccion_ = direccion_ %>% as.character() %>% as.numeric() %>% replace.na()
) %>%
  cor(use = "pairwise.complete.obs")
gps.events.cor %>%
  ggcorrplot() +
  theme(axis.text.x = element_text(angle = 90, hjust = 1, vjust = 0.5))
gps.events.cor %>%
  round(digits = 3) %>%
  kable() %>%
  kable_styling(full_width = F) %>%
  column_spec(1, bold = T, border_right = T) %>%
  add_header_above(c(" " = 1, "Variables" = ncol(gps.events.cor))) %>%
  pack_rows("Variables", 1, nrow(gps.events.cor)) %>%
  row_spec(0, angle = 90, extra_css = "vertical-align: bottom;") %>%
  column_spec(2:ncol(gps.events.cor), width = "0.5cm")
```


```{r gps.events.corr.export, eval=FALSE, include=FALSE}
gps.events.cor %>% write.csv(file = "corr/gps.events.csv")
```

### Período de Monitoreo

- **Fecha de referencia**: Transición año nuevo 2024-2025
- **Según timestamp del auto**: 1 de enero de 2025, 00:00:06 - 01:06:29 (1 hora, 6 minutos)
- **Según timestamp del GPS**: 31 de diciembre de 2024, 23:59:22 - 1 de enero de 2025, 01:06:49 (1 hora, 7 minutos)
- **Discrepancia temporal**: Diferencia de sincronización entre sistemas de aproximadamente 1 minuto

### Granularidad Temporal

- Diferencia Mínima: 1 segundo
- Diferencia Máxima: 1 minuto, 13 segundos
- Diferencia Media: 15.03 segundos (lineal); 3.91 segundos (logarítmico)
- Diferencia Mediana: 1 segundo
- Desviación Standard: 18.82 segundos (lineal); 5.82 segundos (logarítmico)

```{r gps.events.time, echo=FALSE, message=FALSE, warning=FALSE}
gps.events.odd <- gps.events[1:(gps.events %>% nrow()) %% 2 == 1,]
differences <- (gps.events.odd$fecha_auto - c(NA, gps.events.odd$fecha_auto[1:(gps.events.odd %>% nrow() - 1)])) %>% as.numeric()
positive.differences <- differences[differences > 0]
#positive.differences %>% summary()
ggplot() +
  geom_histogram(aes(x = positive.differences)) +
  labs(x = "differences") +
  scale_x_log10()
```

**Outliers**: Cuartiles (logarítmico)

```{r gps.events.time.ol, echo=FALSE, message=FALSE, warning=FALSE}
is.outlier <- positive.differences %>% is.outlier.q(func = log)
ggplot() +
  geom_histogram(aes(x = positive.differences, fill = is.outlier)) +
  scale_x_log10()
```

No hay outliers

### Granularidad Espacial

- Distancia Mínima: 1.14 metros
- Distancia Máxima: 496.19 kilómetros
- Distancia Media: 65.5 kilómetros (lineal); 14.58 metros (logarítmico)
- Distancia Mediana: 4.59 metros
- Desviación Standard: 168.04 kilómetros (lineal); 63.39 metros (logarítmico)

```{r gps.events.space, echo=FALSE, message=FALSE, warning=FALSE}
distances <- min.haversine.distances(
  gps.events$latitud_,
  gps.events$longitud_
)
#distances %>% summary()
ggplot() +
  geom_histogram(aes(x = distances)) +
  scale_x_log10()
```

**Outliers**: Cuartiles (logarítmico)

```{r gps.events.space.ol, echo=FALSE, message=FALSE, warning=FALSE}
is.outlier <- distances %>% is.outlier.q(func = log)
ggplot() +
  geom_histogram(aes(x = distances, fill = is.outlier)) +
  scale_x_log10()
```

Hay 132 outliers superiores

### Distribución de Estados Vehiculares

**Tipos de eventos registrados**:

- **Apagado**: 552 eventos - vehículo sin operación
- **Detenido**: 264 eventos - vehículo inmovilizado pero encendido
- **Movimiento**: 184 eventos - vehículo en desplazamiento

### Patrones de Direccionalidad

**Valores de dirección registrados**:

- `0`: 316 casos
- `-280`: 184 casos
- `-223`: 184 casos
- `-85`: 184 casos
- `235`: 132 casos

```{r gps.events.event, echo=FALSE, message=FALSE, warning=FALSE}
gps.events %>% ggplot() +
  geom_bar(aes(y = evento_ %>% fct_infreq() %>% fct_rev(), fill = direccion_ %>% fct_infreq())) +
  labs(y = "evento_", fill = "direccion_")
```

**Observación**: Los valores negativos y positivos sugieren un sistema de coordenadas o ángulos específico.

### Aspectos Requieren Investigación

**Variables Críticas por Clarificar**

- `id_evento`: Valor constante `2` en todos los registros
- `direccion_`:
    - Sistema de representación angular (grados) o coordenadas relativas
    - Significado de valores negativos vs. positivos
    - Relación con puntos cardinales o sistema de referencia

### Procesamiento y Normalización de Datos

**Paso a paso**

- Se eliminan las columnas "ubicacion_" y "velocidad_" debido a que todos sus valores son nulos
- "fecha_auto" se convierte en un POSIXct con formato "%Y-%m-%d %H:%M:%S"
- "fecha_gps_" se convierte en un POSIXct con formato "%Y-%m-%d %H:%M:%S"
- "evento_" se convierte en factor
- "direccion_" se convierte en factor

## Inventario CCTV Biobío(1).xlsx

```{r getData7, eval=FALSE, include=FALSE}
# Inventario CCTV Biobío(1).xlsx
biobio.inventary <- read_excel("data/Inventario CCTV Biobío(1).xlsx", 
    range = "A2:Q73", na = "----")
colnames(biobio.inventary) <- ifelse(
  grepl("\\...", biobio.inventary %>% colnames()),
  paste((biobio.inventary %>% colnames() %>% str_split_fixed("\\...", n = 2) %>% as.matrix() %>% {.[. == ""] <- NA; .})[, 1], ifelse((biobio.inventary %>% colnames() %>% str_split_fixed("\\...", n = 2) %>% as.matrix() %>% {.[. == ""] <- NA; .})[, 2] %>% as.numeric() <= 11, "DE LA CÁMARA", "DEL CODIFICADOR DE VIDEO")),
  biobio.inventary %>% colnames()
)
biobio.inventary$COMUNA <- biobio.inventary$COMUNA %>% as.factor()
biobio.inventary$ESTADO <- biobio.inventary$ESTADO %>% as.factor()
biobio.inventary$`TIPO DE ENLACE` <- biobio.inventary$`TIPO DE ENLACE` %>% as.factor()
biobio.inventary$PROVEEDOR <- biobio.inventary$PROVEEDOR %>% as.factor()
biobio.inventary$`MARCA DE LA CÁMARA` <- biobio.inventary$`MARCA DE LA CÁMARA` %>% as.factor()
biobio.inventary$`MODELO DE LA CÁMARA` <- biobio.inventary$`MODELO DE LA CÁMARA` %>% as.factor()
biobio.inventary$`MARCA DEL CODIFICADOR DE VIDEO` <- biobio.inventary$`MARCA DEL CODIFICADOR DE VIDEO` %>% as.factor()
biobio.inventary$`MODELO DEL CODIFICADOR DE VIDEO` <- biobio.inventary$`MODELO DEL CODIFICADOR DE VIDEO` %>% as.factor()
biobio.inventary$REGIÓN <- biobio.inventary$REGIÓN %>% as.factor()
biobio.inventary %>% summary()
biobio.inventary.sf <- biobio.inventary %>% st_as_sf(
  coords = c("LONGITUD", "LATITUD"),
  crs = 4326
)
biobio.inventary.sf %>% st_write(.,
  "~/GitHub/data-sets-analysis/shapefiles/biobio.inventary.shp",
  driver = "ESRI Shapefile",
  append = F
)
```

El inventario documenta 71 ubicaciones de cámaras de vigilancia y sus respectivos sistemas de codificación de video desplegados en la Región del Biobío, representando la infraestructura de monitoreo vial regional.

### Matriz de correlación

```{r biobio.inventary.corr, echo=FALSE, message=FALSE, warning=FALSE}
biobio.inventary.cor <- biobio.inventary %>% mutate(
  COMUNA = COMUNA %>% as.numeric() %>% replace.na(),
  ESTADO = ESTADO %>% as.numeric() %>% replace.na(),
  `FECHA INTEGRACION` = `FECHA INTEGRACION` %>% as.numeric(),
  `TIPO DE ENLACE` = `TIPO DE ENLACE` %>% as.numeric() %>% replace.na(),
  PROVEEDOR = PROVEEDOR %>% as.numeric() %>% replace.na(),
  `MARCA DE LA CÁMARA` = `MARCA DE LA CÁMARA` %>% as.numeric() %>% replace.na(),
  `MODELO DE LA CÁMARA` = `MODELO DE LA CÁMARA` %>% as.numeric() %>% replace.na(),
  `MARCA DEL CODIFICADOR DE VIDEO` = `MARCA DEL CODIFICADOR DE VIDEO` %>% as.numeric() %>% replace.na(),
  `MODELO DEL CODIFICADOR DE VIDEO` = `MODELO DEL CODIFICADOR DE VIDEO` %>% as.numeric() %>% replace.na(),
  REGIÓN = REGIÓN %>% as.numeric() %>% replace.na()
) %>%
  select(-NOMBRE, -`NÚMERO DE SERIE DE LA CÁMARA`, -`NÚMERO DE SERIE DEL CODIFICADOR DE VIDEO`) %>%
  cor(use = "pairwise.complete.obs")
biobio.inventary.cor %>%
  ggcorrplot() +
  theme(axis.text.x = element_text(angle = 90, hjust = 1, vjust = 0.5, size = 8), axis.text.y = element_text(size = 8))
biobio.inventary.cor %>%
  round(digits = 3) %>%
  kable() %>%
  kable_styling(full_width = F) %>%
  column_spec(1, bold = T, border_right = T) %>%
  add_header_above(c(" " = 1, "Variables" = ncol(biobio.inventary.cor))) %>%
  pack_rows("Variables", 1, nrow(biobio.inventary.cor)) %>%
  row_spec(0, angle = 90, extra_css = "vertical-align: bottom;") %>%
  column_spec(2:ncol(biobio.inventary.cor), width = "0.5cm")
```


```{r biobio.inventary.corr.export, eval=FALSE, include=FALSE}
biobio.inventary.cor %>% write.csv(file = "corr/biobio.inventary.csv")
```

### Granularidad Espacial

- Distancia Mínima: 169.3 metros
- Distancia Máxima: 81 kilómetros
- Distancia Media: 1.95 kilómetros (lineal); 613.1 metros (logarítmico)
- Distancia Mediana: 519.8 metros
- Desviación Standard: 9.56 kilómetros (lineal); 2.65 metros (logarítmico)

```{r biobio.inventary.space, echo=FALSE, message=FALSE, warning=FALSE}
distances <- min.haversine.distances(
  biobio.inventary$LATITUD,
  biobio.inventary$LONGITUD
)
#distances %>% summary()
ggplot() +
  geom_histogram(aes(x = distances)) +
  scale_x_log10()
```

**Outliers**: Cuartiles (logarítmico)

```{r biobio.inventary.space.ol, echo=FALSE, message=FALSE, warning=FALSE}
is.outlier <- distances %>% is.outlier.q(func = log)
ggplot() +
  geom_histogram(aes(x = distances, fill = is.outlier)) +
  scale_x_log10()
```

Hay 3 oultiers superiores

### Distribución Geográfica

- **Comunas con mayor cobertura**:
    - **Concepción**: 31 cámaras
    - **San Pedro de la Paz**: 16 cámaras
    - **Los Ángeles**: 10 cámaras
- **Cobertura regional**: Múltiples comunas del Biobío con sistemas CCTV

### Estado Operacional del Sistema

- **Cámaras online**: 32 unidades
- **Cámaras offline**: 39 unidades
- **Disponibilidad general**: Sistema operando con 45% de disponibilidad inmediata

```{r biobio.inventary.cities, echo=FALSE, message=FALSE, warning=FALSE}
biobio.inventary %>% ggplot() +
  geom_bar(aes(y = COMUNA %>% fct_infreq() %>% fct_rev(), fill = ESTADO %>% fct_infreq())) +
  labs(y = "COMUNA", fill = "ESTADO")
```

### Características Técnicas de la Infraestructura

**Conectividad y Proveedores**

- **Tipo de enlace**: 100% digital (71/71 cámaras)
- **Proveedor de servicios**: Exclusivamente "Red Comunicaciones Propia" (71/71)

**Especificaciones de Cámaras**

*Marcas predominantes*:

- Pelco: 38 cámaras
- Avigilon: 10 cámaras
- Axis: 10 cámaras

*Modelos más frecuentes*:

- Pelco Esprit: 27 unidades
- Avigilon 2.0C-H5A-RGDPTZ-DP36: 10 unidades
- Axis AXIS Q8685-E: 10 unidades

```{r biobio.inventary.cameras, echo=FALSE, message=FALSE, warning=FALSE}
biobio.inventary %>% ggplot() +
  geom_bar(aes(y = `MODELO DE LA CÁMARA` %>% fct_infreq() %>% fct_rev(), fill = `MARCA DE LA CÁMARA` %>% fct_infreq())) +
  labs(y = "MODELO DE LA CÁMARA", fill = "MARCA DE LA CÁMARA" %>% str_wrap(width = 10))
```

**Sistema de Codificación de Video**

*Codificadores identificados*:

- Axis AXIS Q7401: 26 unidades
- Sin especificar: 45 unidades - posiblemente integrados en cámaras o no documentados

```{r biobio.inventary.video, echo=FALSE, message=FALSE, warning=FALSE}
biobio.inventary %>% ggplot() +
  geom_bar(aes(y = `MODELO DEL CODIFICADOR DE VIDEO` %>% fct_infreq() %>% fct_rev(), fill = `MARCA DEL CODIFICADOR DE VIDEO` %>% fct_infreq())) +
  labs(y = "MODELO DEL CODIFICADOR DE VIDEO", fill = "MARCA DEL CODIFICADOR DE VIDEO" %>% str_wrap(width = 10))
```

### Evolución Temporal del Sistema

- **Rango de integración**: 1 de noviembre de 2003 - 1 de septiembre de 2024
- **Vida útil del sistema**: Más de 20 años de despliegue progresivo
- **Actualizaciones recientes**: Integraciones hasta septiembre 2024

```{r biobio.inventary.integration, echo=FALSE, message=FALSE, warning=FALSE}
biobio.inventary %>% ggplot() +
  geom_density(aes(x = `FECHA INTEGRACION`, colour = COMUNA))
```

### Procesamiento y Normalización de Datos

**Paso a paso**

- Las columnas "MARCA", "MODELO" y "NÚMERO DE SERIE" estaban duplicadas, por lo que se les agregó "DE LA CÁMARA" y "DEL CODIFICADOR DE VIDEO" para distinguirlos
- "COMUNA" se convierte en factor
- "ESTADO" se convierte en factor
- "TIPO DE ENLACE" se convierte en factor
- "PROVEEDOR" se convierte en factor
- "MARCA DE LA CÁMARA" se convierte en factor
- "MODELO DE LA CÁMARA" se convierte en factor
- "MARCA DEL CODIFICADOR DE VIDEO" se convierte en factor
- "MODELO DEL CODIFICADOR DE VIDEO" se convierte en factor
- "REGIÓN" se convierte en factor

## Alertas de Tráfico.csv

```{r getData8, eval=FALSE, include=FALSE}
# Alertas de Tráfico.csv
trafic.alerts <- read_csv("data/Alertas de Tráfico.csv")
trafic.alerts <- trafic.alerts %>% mutate(
  lng = str_extract(Location, "(?<=Point\\()-?\\d+\\.?\\d*") %>% as.numeric(),
  lat = str_extract(Location, "-?\\d+\\.?\\d*(?=\\)$)") %>% as.numeric()
)
trafic.alerts <- trafic.alerts %>% select(-Location)
trafic.alerts$Date <- trafic.alerts$Date %>% str_replace_all(., setNames(
  months,
  c("ene", "feb", "mar", "abr", "may", "jun", "jul", "ago", "sep", "oct", "nov", "dic")
)) %>% dmy()
trafic.alerts$Country <- trafic.alerts$Country %>% as.factor()
trafic.alerts$City <- trafic.alerts$City %>% as.factor()
trafic.alerts$Type <- trafic.alerts$Type %>% as.factor()
trafic.alerts$Subtype <- trafic.alerts$Subtype %>% as.factor()
trafic.alerts %>% summary()
trafic.alerts.sf <- trafic.alerts %>% st_as_sf(
  coords = c("lng", "lat"),
  crs = 4326
)
trafic.alerts.sf %>% st_write(.,
  "~/GitHub/data-sets-analysis/shapefiles/trafic.alerts.shp",
  driver = "ESRI Shapefile",
  append = F
)
```

El dataset comprende 281759 alertas de tráfico generadas por usuarios de Waze, representando un año completo de reportes ciudadanos sobre condiciones viales en el Gran Concepción.

### Matriz de correlación

```{r trafic.alerts.corr, echo=FALSE, message=FALSE, warning=FALSE}
trafic.alerts.cor <- trafic.alerts %>% mutate(
  Date = Date %>% as.numeric(),
  Country = Country %>% as.numeric() %>% replace.na(),
  City = City %>% as.numeric() %>% replace.na(),
  Street = Street %>% as.factor() %>% as.numeric() %>% replace.na(),
  Type = Type %>% as.numeric() %>% replace.na(),
  Subtype = Subtype %>% as.numeric() %>% replace.na()
) %>%
  cor(use = "pairwise.complete.obs")
trafic.alerts.cor %>%
  ggcorrplot() +
  theme(axis.text.x = element_text(angle = 90, hjust = 1, vjust = 0.5))
trafic.alerts.cor %>% kable()
```


```{r trafic.alerts.corr.export, eval=FALSE, include=FALSE}
trafic.alerts.cor %>% write.csv(file = "corr/trafic.alerts.csv")
```

### Período de Análisis

- **Cobertura temporal**: 23 de junio de 2023 - 15 de mayo de 2024
- **Duración**: 327 de datos continuos
- **Registros diarios promedio**: 861.65 alertas por día

### Distribución Temporal

```{r trafic.alerts.month.time, echo=FALSE, message=FALSE, warning=FALSE}
trafic.alerts.dates <- data.frame(
  Día = trafic.alerts$Date %>% weekdays() %>% factor(levels = weekdays),
  Mes = months[trafic.alerts$Date %>% month()] %>% factor(levels = months)
)
trafic.alerts.dates %>%
  count(Día, Mes, .drop = F) %>%
  ggplot() +
  geom_tile(aes(y = Día %>% fct_rev(), x = Mes, fill = n)) +
  scale_fill_gradientn(
    name = "Cantidad",
    colors = c(
      "red",
      "orange",
      "yellow",
      "lightgreen",
      "darkgreen"
    )
  ) +
  labs(y = "Día de la Semana", x = "Mes")
trafic.alerts.dates %>%
  count(Día, Mes, .drop = F) %>%
  spread(key = Mes, value = n, fill = 0) %>%
  as.data.frame() %>%
  column_to_rownames("Día") %>%
  as.matrix() %>%
  kable()
```

### Distribución Geográfica

- **Distribución por ciudad**:
    - Concepción: 130747 alertas
    - San Pedro de la Paz: 51816 alertas
    - Talcahuano: 35122 alertas
    - Otras comunas: 64074 alertas

```{r trafic.alerts.cities, echo=FALSE, message=FALSE, warning=FALSE}
trafic.alerts %>% ggplot() +
  geom_bar(aes(y = City %>% fct_infreq() %>% fct_rev())) +
  labs(y = "City") +
  scale_x_log10()
```

### Distribución Espacio-Temporal

**Comuna y Mes**

```{r trafic.alerts.spacetime.0, echo=FALSE, message=FALSE, warning=FALSE}
trafic.alerts.spacetime <- data.frame(
  Mes = months[trafic.alerts$Date %>% month()] %>% factor(levels = months),
  Día = trafic.alerts$Date %>% weekdays() %>% factor(levels = weekdays),
  Comuna = trafic.alerts$City %>% factor(levels = trafic.alerts$City %>% fct_infreq() %>% levels())
)
trafic.alerts.spacetime %>%
  count(Mes, Comuna, .drop = F) %>%
  ggplot() +
  geom_tile(aes(y = Comuna %>% fct_rev(), x = Mes, fill = n)) +
  scale_fill_gradientn(
    name = "Cantidad",
    colors = c(
      "red",
      "orange",
      "yellow",
      "lightgreen",
      "darkgreen"
    )
  ) +
  labs(y = "Comuna", x = "Mes") +
  scale_y_discrete(labels = label_wrap_gen(width = 20))
trafic.alerts.spacetime %>%
  count(Comuna, Mes, .drop = F) %>%
  spread(key = Mes, value = n, fill = 0) %>%
  as.data.frame() %>%
  column_to_rownames("Comuna") %>%
  as.matrix() %>%
  kable()
```

**Comuna y Día de la Semana**

```{r trafic.alerts.1, echo=FALSE, message=FALSE, warning=FALSE}
trafic.alerts.spacetime %>%
  count(Día, Comuna, .drop = F) %>%
  ggplot() +
  geom_tile(aes(y = Comuna %>% fct_rev(), x = Día, fill = n)) +
  scale_fill_gradientn(
    name = "Cantidad",
    colors = c(
      "red",
      "orange",
      "yellow",
      "lightgreen",
      "darkgreen"
    )
  ) +
  labs(y = "Comuna", x = "Día de la Semana") +
  scale_y_discrete(labels = label_wrap_gen(width = 20))
trafic.alerts.spacetime %>%
  count(Comuna, Día, .drop = F) %>%
  spread(key = Día, value = n, fill = 0) %>%
  as.data.frame() %>%
  column_to_rownames("Comuna") %>%
  as.matrix() %>%
  kable()
```

### Clasificación de Alertas

**Categorías Principales (Type)**

- **Embottellamiento (JAM)**: 178785 casos
- **Peligro (HAZARD)**: 53457 casos
- **Peligro meteorológico (WEATHERHAZARD)**: 35984 casos
- **Otras categorías**: 13533 casos

**Especificaciones por Subcategoría (Subtype)**

*Embottellamientos (JAM)*:

- Tráfico intenso (JAM_HEAVY_TRAFFIC): 77179 casos
- Tráfico paralizado (JAM_STAND_STILL_TRAFFIC): 52298 casos
- Tráfico moderado (JAM_MODERATE_TRAFFIC): 20947 casos

*Peligros (HAZARD)*:

- Vehículo detenido en franja lateral (HAZARD_ON_SHOULDER_CAR_STOPPED): 15869 casos
- Construcción en la vía (HAZARD_ON_ROAD_CONSTRUCTION): 9458 casos
- Peligro en la vía (HAZARD_ON_ROAD): 7494 casos
- Otros peligros: 20636 casos

*Peligros meteorológicos (WEATHERHAZARD)*:

- Vehículo detenido (HAZARD_ON_ROAD_CAR_STOPPED): 9467 casos
- Construcción en la vía (HAZARD_ON_ROAD_CONSTRUCTION): 6287 casos
- Vehículo detenido en franja lateral (HAZARD_ON_SHOULDER_CAR_STOPPED): 6097 casos
- Otros peligros meteorológicos: 14133 casos

```{r trafic.alerts.types, echo=FALSE, message=FALSE, warning=FALSE}
trafic.alerts[trafic.alerts$Subtype %in% (trafic.alerts %>%
  count(Subtype) %>%
  slice_max(n, n = 10) %>%
  pull(Subtype)),] %>% ggplot() +
  geom_bar(aes(y = Subtype %>% fct_infreq() %>% fct_rev(), fill = Type %>% fct_infreq())) +
  labs(y = "Subtype", fill = "Type")
```

### Procesamiento y Normalización de Datos

**Paso a paso**

- La columna "Location" se separa en "lng" y "lat" mediante los regex `"(?<=Point\\()-?\\d+\\.?\\d*"` y `"-?\\d+\\.?\\d*(?=\\)$)"`, respectivamente
- Se elimina la columna "Location"
- En la columna "Date", se reemplazan los valores "ene", "feb", "mar", "abr", "may", "jun", "jul", "ago", "sep", "oct", "nov" y "dic" por "jan", "feb", "mar", "apr", "may", "jun", "jul", "aug", "sep", "oct", "nov" y "dec", respectivamente
- "Country" se convierte en factor
- "City" se convierte en factor
- "Type" se convierte en factor
- "Subtype" se convierte en factor

## Copia de Accidentes.csv

```{r getData9, eval=FALSE, include=FALSE}
# Copia de Accidentes.csv
accidents <- read_csv("data/Copia de Accidentes.csv")
accidents <- accidents %>% mutate(
  lng = str_extract(Location, "(?<=Point\\()-?\\d+\\.?\\d*") %>% as.numeric(),
  lat = str_extract(Location, "-?\\d+\\.?\\d*(?=\\)$)") %>% as.numeric()
)
accidents <- accidents %>% select(-Location)
accidents$Date <- accidents$Date %>% str_replace_all(., setNames(
  months,
  c("ene", "feb", "mar", "abr", "may", "jun", "jul", "ago", "sep", "oct", "nov", "dic")
)) %>% dmy()
accidents$Country <- accidents$Country %>% as.factor()
accidents$City <- accidents$City %>% as.factor()
accidents %>% summary()
accidents.sf <- accidents %>% st_as_sf(
  coords = c("lng", "lat"),
  crs = 4326
)
accidents.sf %>% st_write(.,
  "~/GitHub/data-sets-analysis/shapefiles/accidents.shp",
  driver = "ESRI Shapefile",
  append = F
)
```

El dataset contiene 281981 registros de accidentes de tránsito, proporcionando una visión detallada de la siniestralidad vial en el Gran Concepción durante un período de 11 meses.

### Matriz de correlación

```{r accidents.corr, echo=FALSE, message=FALSE, warning=FALSE}
accidents.cor <- accidents %>% mutate(
  Date = Date %>% as.numeric(),
  Country = Country %>% as.numeric() %>% replace.na(),
  City = City %>% as.numeric() %>% replace.na(),
  Street = Street %>% as.factor() %>% as.numeric() %>% replace.na()
) %>%
  cor(use = "pairwise.complete.obs")
accidents.cor %>%
  ggcorrplot() +
  theme(axis.text.x = element_text(angle = 90, hjust = 1, vjust = 0.5))
accidents.cor %>% kable()
```


```{r accidents.corr.export, eval=FALSE, include=FALSE}
accidents.cor %>% write.csv(file = "corr/accidents.csv")
```

### Período de Monitoreo

- **Cobertura temporal**: 23 de junio de 2023 - 15 de mayo de 2024
- **Duración**: 327 días de reportes continuos
- **Densidad de datos**: ~862.33 accidentes reportados por día en promedio

```{r accidents.time, echo=FALSE, message=FALSE, warning=FALSE}
accidents %>% ggplot() +
  geom_histogram(aes(x = Date, fill = City)) +
  scale_fill_discrete(labels = label_wrap_gen(width = 15))
```

### Distribución Temporal

```{r accidents.month.time, echo=FALSE, message=FALSE, warning=FALSE}
accidents.dates <- data.frame(
  Mes = months[accidents$Date %>% month()] %>% factor(levels = months),
  `Día de la Semana` = accidents$Date %>% weekdays() %>% factor(levels = weekdays)
)
accidents.dates %>%
  count(Mes, Día.de.la.Semana, .drop = F) %>%
  ggplot() +
  geom_tile(aes(x = Mes, y = Día.de.la.Semana, fill = n)) +
  scale_fill_gradientn(
    name = "Cantidad",
    colors = c(
      "red",
      "orange",
      "yellow",
      "lightgreen",
      "darkgreen"
    )
  ) +
  labs(x = "Mes", y = "Día de la Semana")
accidents.dates %>%
  count(Mes, Día.de.la.Semana, .drop = F) %>%
  spread(key = Mes, value = n, fill = 0) %>%
  as.data.frame() %>%
  column_to_rownames("Día.de.la.Semana") %>%
  as.matrix() %>%
  kable()
```

### Granularidad Espacial

- Distancia Mínima: 9.49 centímetros
- Distancia Máxima: 11.71 kilómetros
- Distancia Media: 3.27 metros (lineal); 67.82 centímetros (logarítmico)
- Distancia Mediana: 55.36 centímetros
- Desviación Standard: 37.17 metros (lineal); 4.35 metros (logarítmico)

```{r accidents.space.0, include=FALSE}
accidents.distances.0.lst <- list()
accidents.distances.0.time <- list()
for(ct in accidents$City[accidents$lng <= -72.75] %>% levels()){
  print(ct)
  start.sys <- Sys.time()
  city.accidents <- accidents[accidents$lng <= -72.75 & accidents$City == ct,]
  accidents.distances.0.lst[[ct]] <- haversine.distances(
    city.accidents$lat,
    city.accidents$lng
  )
  end.sys <- Sys.time()
  dt.sys <- end.sys - start.sys
  accidents.distances.0.time[[ct]] <- dt.sys
  print(dt.sys)
}
accidents.distances.1 <- haversine.distances(
  accidents$lat[accidents$lng > -72.75 & accidents$lng <= -71.5],
  accidents$lng[accidents$lng > -72.75 & accidents$lng <= -71.5]
)
accidents.distances.2 <- haversine.distances(
  accidents$lat[accidents$lng > -71.5],
  accidents$lng[accidents$lng > -71.5]
)
accidents.distances <- c()
for(ad in accidents.distances.0.lst) {
  accidents.distances <- c(accidents.distances, ad)
}
accidents.distances <- c(accidents.distances, accidents.distances.1, accidents.distances.2)
positive.accidents.distances <- accidents.distances[accidents.distances > 0]
```


```{r accidents.space, echo=FALSE, message=FALSE, warning=FALSE}
#positive.accidents.distances %>% summary()
ggplot() +
  geom_histogram(aes(x = positive.accidents.distances)) +
  scale_x_log10()
```

**Outliers**: Cuartiles (logarítmico)

```{r accidents.space.ol, echo=FALSE, message=FALSE, warning=FALSE}
is.outlier <- positive.accidents.distances %>% is.outlier.q(func = log)
ggplot() +
  geom_histogram(aes(x = positive.accidents.distances, fill = is.outlier)) +
  scale_x_log10()
```

Hay 4270 outliers superiores

### Distribución Geográfica

- **Distribución por ciudad**:
    - Concepción: 130516 alertas
    - San Pedro de la Paz: 51704 alertas
    - Talcahuano: 35059 alertas
    - Otras comunas: 64702 alertas

```{r accidents.cities, echo=FALSE, message=FALSE, warning=FALSE}
accidents %>% ggplot() +
  geom_bar(aes(y = City %>% fct_infreq() %>% fct_rev())) +
  labs(y = "City") +
  scale_x_log10()
```

### Distribución Espacio-Temporal

**Comuna y Mes**

```{r accidents.spacetime.0, echo=FALSE, message=FALSE, warning=FALSE}
accidents.spacetime <- data.frame(
  Mes = months[accidents$Date %>% month()] %>% factor(levels = months),
  Día = accidents$Date %>% weekdays() %>% factor(levels = weekdays),
  Comuna = accidents$City %>% factor(levels = accidents$City %>% fct_infreq() %>% levels())
)
accidents.spacetime %>%
  count(Mes, Comuna, .drop = F) %>%
  ggplot() +
  geom_tile(aes(y = Comuna %>% fct_rev(), x = Mes, fill = n)) +
  scale_fill_gradientn(
    name = "Cantidad",
    colors = c(
      "red",
      "orange",
      "yellow",
      "lightgreen",
      "darkgreen"
    )
  ) +
  labs(y = "Comuna", x = "Mes") +
  scale_y_discrete(labels = label_wrap_gen(width = 20))
accidents.spacetime %>%
  count(Mes, Comuna, .drop = F) %>%
  spread(key = Mes, value = n, fill = 0) %>%
  as.data.frame() %>%
  column_to_rownames("Comuna") %>%
  as.matrix() %>%
  kable()
```

**Comuna y Día de la Semana**

```{r accidents.spacetime.1, echo=FALSE, message=FALSE, warning=FALSE}
accidents.spacetime %>%
  count(Día, Comuna, .drop = F) %>%
  ggplot() +
  geom_tile(aes(y = Comuna %>% fct_rev(), x = Día, fill = n)) +
  scale_fill_gradientn(
    name = "Cantidad",
    colors = c(
      "red",
      "orange",
      "yellow",
      "lightgreen",
      "darkgreen"
    )
  ) +
  labs(y = "Comuna", x = "Día de la Semana") +
  scale_y_discrete(labels = label_wrap_gen(width = 20))
accidents.spacetime %>%
  count(Día, Comuna, .drop = F) %>%
  spread(key = Día, value = n, fill = 0) %>%
  as.data.frame() %>%
  column_to_rownames("Comuna") %>%
  as.matrix() %>%
  kable()
```

### Métricas de Confiabilidad

- **Rango de fiabilidad**: 5 a 10 puntos (escala no especificada)
- **Fiabilidad promedio**: 5.82 puntos
- **Fiabilidad mediana**: 5 puntos
- **Distribución**: Sesgada hacia valores bajos-medios de la escala

```{r accidents.reliability, echo=FALSE, message=FALSE, warning=FALSE}
accidents %>% ggplot() +
  geom_histogram(aes(x = `Avg Reliability`, fill = City)) +
  scale_fill_discrete(labels = label_wrap_gen(width = 15))
```

### Procesamiento y Normalización de Datos

**Paso a paso**

- La columna "Location" se separa en "lng" y "lat" mediante los regex `"(?<=Point\\()-?\\d+\\.?\\d*"` y `"-?\\d+\\.?\\d*(?=\\)$)"`, respectivamente
- Se elimina la columna "Location"
- En la columna "Date", se reemplazan los valores "ene", "feb", "mar", "abr", "may", "jun", "jul", "ago", "sep", "oct", "nov" y "dic" por "jan", "feb", "mar", "apr", "may", "jun", "jul", "aug", "sep", "oct", "nov" y "dec", respectivamente
- "Country" se convierte en factor
- "City" se convierte en factor

## Waze for Cities Data Key Alerts Dashboard_Traffic Irregularities_Tabla(1).csv

```{r getData10, eval=FALSE, include=FALSE}
# Waze for Cities Data Key Alerts Dashboard_Traffic Irregularities_Tabla(1).csv
waze.data <- read_csv("data/Waze for Cities Data Key Alerts Dashboard_Traffic Irregularities_Tabla(1).csv", 
    na = "null")
waze.data$Day <- waze.data$Day %>% str_replace_all(., setNames(
  months,
  c("ene", "feb", "mar", "abr", "may", "jun", "jul", "ago", "sep", "oct", "nov", "dic")
)) %>% dmy()
waze.data$Country <- waze.data$Country %>% as.factor()
waze.data$City <- waze.data$City %>% as.factor()
waze.data$Street <- waze.data$Street %>% as.factor()
waze.data$Cause <- waze.data$Cause %>% as.factor()
waze.data %>% summary()
```

El dataset contiene 13502 registros de irregularidades de tráfico documentadas a través de la plataforma Waze for Cities, proporcionando métricas detalladas sobre el impacto de incidentes viales en la Región del Biobío durante un período de 11 meses.

### Matriz de correlación

```{r waze.data.corr, echo=FALSE, message=FALSE, warning=FALSE}
waze.data.cor <- waze.data %>% mutate(
  Day = Day %>% as.numeric(),
  Country = Country %>% as.numeric() %>% replace.na(),
  City = City %>% as.numeric() %>% replace.na(),
  Street = Street %>% as.numeric() %>% replace.na(),
  Cause = Cause %>% as.numeric() %>% replace.na()
) %>%
  cor(use = "pairwise.complete.obs")
waze.data.cor %>%
  ggcorrplot() +
  theme(axis.text.x = element_text(angle = 90, hjust = 1, vjust = 0.5, size = 8), axis.text.y = element_text(size = 8))
waze.data.cor %>% kable()
```


```{r waze.data.corr.export, eval=FALSE, include=FALSE}
waze.data.cor %>% write.csv(file = "corr/waze.data.csv")
```

### Período de Análisis

- **Cobertura temporal**: 23 de junio de 2023 - 15 de mayo de 2024
- **Duración**: 327 días de monitoreo continuo
- **Frecuencia promedio**: 41.29 irregularidades reportadas por día

```{r waze.data.time, echo=FALSE, message=FALSE, warning=FALSE}
waze.data %>% ggplot() +
  geom_histogram(aes(x = Day, fill = City)) +
  scale_fill_discrete(labels = label_wrap_gen(width = 15))
```

### Distribución Temporal

```{r waze.data.month.time, echo=FALSE, message=FALSE, warning=FALSE}
waze.data.dates <- data.frame(
  Mes = months[waze.data$Day %>% month()] %>% factor(levels = months),
  `Día de la Semana` = waze.data$Day %>% weekdays() %>% factor(levels = weekdays)
)
waze.data.dates %>%
  count(Mes, Día.de.la.Semana, .drop = F) %>%
  ggplot() +
  geom_tile(aes(x = Mes, y = Día.de.la.Semana, fill = n)) +
  scale_fill_gradientn(
    name = "Cantidad",
    colors = c(
      "red",
      "orange",
      "yellow",
      "lightgreen",
      "darkgreen"
    )
  ) +
  labs(x = "Mes", y = "Día de la Semana")
waze.data.dates %>%
  count(Mes, Día.de.la.Semana, .drop = F) %>%
  spread(key = Mes, value = n, fill = 0) %>%
  as.data.frame() %>%
  column_to_rownames("Día.de.la.Semana") %>%
  as.matrix() %>%
  kable()
```

### Distribución Geográfica

- **Concentración por ciudad**:
    - Concepción: 4236 registros
    - Los Ángeles: 3484 registros
    - San Pedro de la Paz: 2190 registros
    - Otras localidades: 3592 registros

```{r waze.data.cities, echo=FALSE, message=FALSE, warning=FALSE}
waze.data %>% ggplot() +
  geom_bar(aes(y = City %>% fct_infreq() %>% fct_rev(), fill = Cause %>% fct_infreq())) +
  labs(y = "City", fill = "Cause")
```

### Distribución Espacio-Temporal

**Comuna y Mes**

```{r waze.data.spacetime.0, echo=FALSE, message=FALSE, warning=FALSE}
waze.data.spacetime <- data.frame(
  Mes = months[waze.data$Day %>% month()] %>% factor(levels = months),
  Día = waze.data$Day %>% weekdays() %>% factor(levels = weekdays),
  Comuna = waze.data$City %>% factor(levels = waze.data$City %>% fct_infreq() %>% levels())
)
waze.data.spacetime %>%
  count(Mes, Comuna, .drop = F) %>%
  ggplot() +
  geom_tile(aes(y = Comuna %>% fct_rev(), x = Mes, fill = n)) +
  scale_fill_gradientn(
    name = "Cantidad",
    colors = c(
      "red",
      "orange",
      "yellow",
      "lightgreen",
      "darkgreen"
    )
  ) +
  labs(y = "Comuna", x = "Mes") +
  scale_y_discrete(labels = label_wrap_gen(width = 20))
waze.data.spacetime %>%
  count(Mes, Comuna, .drop = F) %>%
  spread(key = Mes, value = n, fill = 0) %>%
  as.data.frame() %>%
  column_to_rownames("Comuna") %>%
  as.matrix() %>%
  kable()
```

**Comuna y Día de la Semana**

```{r waze.data.spacetime.1, echo=FALSE, message=FALSE, warning=FALSE}
waze.data.spacetime %>%
  count(Día, Comuna, .drop = F) %>%
  ggplot() +
  geom_tile(aes(y = Comuna %>% fct_rev(), x = Día, fill = n)) +
  scale_fill_gradientn(
    name = "Cantidad",
    colors = c(
      "red",
      "orange",
      "yellow",
      "lightgreen",
      "darkgreen"
    )
  ) +
  labs(y = "Comuna", x = "Día de la Semana") +
  scale_y_discrete(labels = label_wrap_gen(width = 20))
waze.data.spacetime %>%
  count(Día, Comuna, .drop = F) %>%
  spread(key = Día, value = n, fill = 0) %>%
  as.data.frame() %>%
  column_to_rownames("Comuna") %>%
  as.matrix() %>%
  kable()
```

### Clasificación por Causas Identificadas

- **Accidentes (ACCIDENT)**: 839 casos
- **Peligros en la vía (HAZARD)**: 826 casos
- **Carreteras cerradas (ROAD_CLOSED)**: 3 casos
- **Causa no especificada**: 11834 casos

```{r waze.data.causes, echo=FALSE, message=FALSE, warning=FALSE}
waze.data[!(waze.data$Cause %>% is.na()),] %>% ggplot() +
  geom_bar(aes(y = Cause %>% fct_infreq() %>% fct_rev(), fill = City %>% fct_infreq())) +
  scale_fill_discrete(labels = label_wrap_gen(width = 15)) +
  labs(y = "Cause", fill = "City")
```

### Métricas de Impacto de Tráfico

**Longitud de Afectación Vial**

- **Rango**: 500 m - 16.61 km
- **Longitud promedio**: 1.34 km
- **Mediana**: 947 m
- **Distribución**: Sesgo hacia afectaciones de mediana extensión

```{r waze.data.length, echo=FALSE, message=FALSE, warning=FALSE}
waze.data %>% ggplot() +
  geom_density(aes(x = `Avg Length (Meters)`, colour = Cause)) +
  scale_x_log10()
```

**Tiempos de Desfase**

- **Rango**: 1 minuto 7.33 segundos - 6 horas 27 minutos 26 segundos
- **Desfase promedio**: 11 minutos 4.97 segundos
- **Mediana**: 9 minutos 18.25 segundos
- **Significado**: Retrasos significativos en la movilidad urbana

```{r waze.data.delay, echo=FALSE, message=FALSE, warning=FALSE}
waze.data %>% ggplot() +
  geom_density(aes(x = `Avg Delay (Seconds)`, colour = Cause)) +
  scale_x_log10()
```

**Impacto en Usuarios**

- **Usuarios afectados (Impacted Wazers)**: 1 - 122563 personas
- **Promedio de afectados**: 2033 usuarios por incidente
- **Mediana**: 465 usuarios
- **Distribución**: Alta variabilidad con eventos masivos ocasionales

```{r waze.data.impacted.wazers, echo=FALSE, message=FALSE, warning=FALSE}
waze.data %>% ggplot() +
  geom_density(aes(x = `Impacted Wazers`, colour = Cause)) +
  scale_x_log10()
```

### Procesamiento y Normalización de Datos

**Paso a paso**

- En la columna "Date", se reemplazan los valores "ene", "feb", "mar", "abr", "may", "jun", "jul", "ago", "sep", "oct", "nov" y "dic" por "jan", "feb", "mar", "apr", "may", "jun", "jul", "aug", "sep", "oct", "nov" y "dec", respectivamente
- "Country" se convierte en factor
- "City" se convierte en factor
- "Street" se convierte en factor
- "Cause" se convierte en factor

## Red de Waze

```{r getData11, eval=FALSE, include=FALSE}
json.route <- "data/json"
folders <- json.route %>% list.dirs(recursive = F) %>% basename()
routes.list <- list()
folder.time.list <- list()
subfolder.time.list <- list()
file.time.list <- list()
#folders <- folders[folders %>% str_replace_all("_", "-") %>% as.POSIXct(format = "%d-%m-%Y") %>% order()]
#folders <- folders[folders %>% str_replace_all("_", "-") %>% as.POSIXct(format = "%d-%m-%Y") > waze.routes.df$date %>% as.POSIXct(format = "%d-%m-%Y") %>% max()]
for(folder in folders){
  folder.start.sys <- Sys.time()
  subfolders <- paste(json.route, folder, sep = "/") %>% list.dirs(recursive = F) %>% basename()
  for(subfolder in subfolders){
    subfolder.start.sys <- Sys.time()
    base.routes <- paste(json.route, folder, subfolder, sep = "/") %>% list.files(full.names = T)
    for(base.route in base.routes){
      file.start.sys <- Sys.time()
      json <- fromJSON(file = base.route)
      routes.data <- json$routes %>% lapply(., function(route) {
        new.row <- route[!names(route) %in% c("line", "bbox", "subRoutes", "leadAlert", "alternateRoute")]
        if(!(route$leadAlert %>% is.null())){
          new.row$leadAlert.numComments <- route$leadAlert$numComments
          new.row$leadAlert.city <- route$leadAlert$city
          new.row$leadAlert.externalImageId <- route$leadAlert$externalImageId
          new.row$leadAlert.numThumbsUp <- route$leadAlert$numThumbsUp
          new.row$leadAlert.street <- route$leadAlert$street
          new.row$leadAlert.subType <- route$leadAlert$subType
          new.row$leadAlert.id <- route$leadAlert$id
          new.row$leadAlert.position <- route$leadAlert$position
          new.row$leadAlert.type <- route$leadAlert$type
          new.row$leadAlert.numNotThereReports <- route$leadAlert$numNotThereReports
        } else {
          new.row$leadAlert.numComments <- NA
          new.row$leadAlert.city <- NA
          new.row$leadAlert.externalImageId <- NA
          new.row$leadAlert.numThumbsUp <- NA
          new.row$leadAlert.street <- NA
          new.row$leadAlert.subType <- NA
          new.row$leadAlert.id <- NA
          new.row$leadAlert.position <- NA
          new.row$leadAlert.type <- NA
          new.row$leadAlert.numNotThereReports <- NA
        }
        if(!(route$bbox %>% is.null())) {
          new.row$minY <- route$bbox$minY
          new.row$minX <- route$bbox$minX
          new.row$maxY <- route$bbox$maxY
          new.row$maxX <- route$bbox$maxX
        } else {
          new.row$minY <- NA
          new.row$minX <- NA
          new.row$maxY <- NA
          new.row$maxX <- NA
        }
        if(!(route$line %>% is.null()) && route$line %>% length() > 0) {
          route$line %>% seq_along() %>% lapply(., function(i) {
            row <- new.row
            row$x <- route$line[[i]]$x
            row$y <- route$line[[i]]$y
            row$point_index <- i
            row$total_points <- route$line %>% length()
            return(row %>% as.data.frame(stringsAsFactors = F))
          })
        } else {
          row <- new.row
          row$x <- NA
          row$y <- NA
          row$point_index <- NA
          row$total_points <- NA
          list(row %>% as.data.frame(stringsAsFactors = F))
        }
      })
      df.routes <- rbind %>% do.call(., routes.data %>% unlist(recursive = F))
      df.routes$speed <- df.routes$length / df.routes$time
      df.routes$broadcasterId <- json$broadcasterId
      df.routes$areaName <- json$areaName
      df.routes$isMetric <- json$isMetric
      df.routes$updateTime <- json$updateTime
      df.routes$date <- gsub("_", "-", folder)
      df.routes$subfolder <- subfolder
      file <- gsub(".json", "", (base.route %>% basename() %>% str_split(pattern = "_"))[[1]][3])
      df.routes$file <- file
      routes.list[[base.route]] <- df.routes
      file.end.sys <- Sys.time()
      file.dt.sys <- file.end.sys - file.start.sys
      file.time.list[[base.route]] <- file.dt.sys
      print("File time:")
      print(base.route %>% basename())
      print(file.dt.sys)
    }
    subfolder.end.sys <- Sys.time()
    subfolder.dt.sys <- subfolder.end.sys - subfolder.start.sys
    subfolder.time.list[[paste(folder, subfolder, sep = "/")]] <- subfolder.dt.sys
    print("Subfolder time:")
    print(subfolder)
    print(subfolder.dt.sys)
  }
  folder.end.sys <- Sys.time()
  folder.dt.sys <- folder.end.sys - folder.start.sys
  folder.time.list[[folder]] <- folder.dt.sys
  print("Folder time:")
  print(folder)
  print(folder.dt.sys)
}
total.dt <- folder.time.list %>% sum.time()
# Reading Time: 1d + 17h + 32m + 45.7s
start.sys <- Sys.time()
waze.routes.df <- routes.list %>% bind_rows()
end.sys <- Sys.time()
binding.time <- end.sys - start.sys
# Binding Time: 26m + 56.11s
start.sys <- Sys.time()
waze.routes.df$toName <- waze.routes.df$toName %>% as.factor()
waze.routes.df$name <- waze.routes.df$name %>% as.factor()
waze.routes.df$fromName <- waze.routes.df$fromName %>% as.factor()
waze.routes.df$type <- waze.routes.df$type %>% as.factor()
waze.routes.df$leadAlert.city <- waze.routes.df$leadAlert.city %>% as.factor()
waze.routes.df$leadAlert.externalImageId <- waze.routes.df$leadAlert.externalImageId %>% as.factor()
waze.routes.df$leadAlert.street <- waze.routes.df$leadAlert.street %>% as.factor()
waze.routes.df$leadAlert.subType <- waze.routes.df$leadAlert.subType %>% as.factor()
waze.routes.df$leadAlert.id <- waze.routes.df$leadAlert.id %>% as.factor()
lat.lng <- function(n = 1){
  waze.routes.df$leadAlert.position %>% sapply(., function(p){
    if(p %>% is.na()) {
      return(NA)
    }
    str_split(p, " ")[[1]][n] %>% as.numeric()
  })
}
waze.routes.df$leadAlert.position.lat <- lat.lng(1)
waze.routes.df$leadAlert.position.lng <- lat.lng(2)
waze.routes.df <- waze.routes.df %>% select(-leadAlert.position)
waze.routes.df$leadAlert.type <- waze.routes.df$leadAlert.type %>% as.factor()
waze.routes.df$broadcasterId <- waze.routes.df$broadcasterId %>% as.factor()
waze.routes.df$areaName <- waze.routes.df$areaName %>% as.factor()
waze.routes.df$date <- waze.routes.df$date %>% as.POSIXct(format = "%d-%m-%Y")
waze.routes.df$subfolder <- waze.routes.df$subfolder %>% as.factor()
waze.routes.df$file <- waze.routes.df$file %>% as.factor()
waze.routes.df$updateTime <- (waze.routes.df$updateTime / 1000) %>% as.POSIXct(origin = "1970-01-01", tz = "UTC")
waze.routes.df$weekday <- waze.routes.df$updateTime %>% weekdays() %>% factor(levels = weekdays)
end.sys <- Sys.time()
modifying.time <- end.sys - start.sys
# Modifying Time: 55m + 31.33s
waze.routes.df %>% summary()
waze.routes <- waze.routes.df %>% distinct(id, date, file, .keep_all = T) %>% select(-x, -y, -point_index)
waze.routes %>% summary()
waze.routes.df.short <- waze.routes.df %>%
  rename(
    alert_lat = leadAlert.position.lat,
    alert_lng = leadAlert.position.lng,
    alert_city = leadAlert.city,
    alert_img = leadAlert.externalImageId,
    alert_strt = leadAlert.street,
    alert_sub = leadAlert.subType,
    alert_id = leadAlert.id,
    alert_type = leadAlert.type,
    alert_com = leadAlert.numComments,
    alert_thumbs = leadAlert.numThumbsUp,
    alert_notthere = leadAlert.numNotThereReports,
    date_str = date
  )
waze.routes.df.short$date_str <- waze.routes.df.short$date_str %>% as.character()
waze.routes.df.clean <- waze.routes.df.short %>%
  filter(!(x %>% is.na()), !(y %>% is.na()))
waze.routes.df.sf <- waze.routes.df.clean %>% st_as_sf(
  coords = c("x", "y"),
  crs = 4326
)
waze.routes.df.sf %>% st_write(.,
  "~/GitHub/data-sets-analysis/shapefiles/waze.routes.df.shp",
  driver = "ESRI Shapefile",
  append = F,
  delete_dsn = T
)
create.bbox.polygons <- function(df){
  polygons.list <- list()
  for (i in df %>% nrow() %>% seq_len()) {
    minX <- df$minX[i]
    minY <- df$minY[i]
    maxX <- df$maxX[i]
    maxY <- df$maxY[i]
    if (c(minX, minY, maxX, maxY) %>% is.na() %>% any()) {
      next
    }
    polygon.coords <- matrix(c(
      minX, minY,
      minX, maxY,
      maxX, maxY,
      maxX, minY,
      minX, minY
    ), ncol = 2, byrow = TRUE)
    polygon <- polygon.coords %>% list() %>% st_polygon()
    polygons.list[[i]] <- polygon
  }
  valid.rows <- !sapply(polygons.list, is.null)
  df.valid <- df[valid.rows, ]
  df.sf <- df.valid %>% st_sf(geometry = polygons.list[valid.rows] %>% st_sfc(crs = 4326)) %>% select(-minX, -minY, -maxX, -maxY)
  return(df.sf)
}
waze.routes.polygons <- waze.routes %>% create.bbox.polygons() %>%
  rename(
    alert_lat = leadAlert.position.lat,
    alert_lng = leadAlert.position.lng,
    alert_city = leadAlert.city,
    alert_img = leadAlert.externalImageId,
    alert_strt = leadAlert.street,
    alert_sub = leadAlert.subType,
    alert_id = leadAlert.id,
    alert_type = leadAlert.type,
    alert_com = leadAlert.numComments,
    alert_thumbs = leadAlert.numThumbsUp,
    alert_notthere = leadAlert.numNotThereReports,
    date_str = date
  )
waze.routes.polygons %>% st_write(
  dsn = "~/GitHub/data-sets-analysis/shapefiles",
  layer = "waze.routes",
  driver = "ESRI Shapefile",
  append = F,
  delete_dsn = T
)

# Mapa de calor (Velocidad, tramo x hora)
## Datos de Carrera y Pedro Aguirre Cerda
## Martes y miércoles, respectivamente
waze.routes.df %>% summary()
waze.routes.heatmap <- waze.routes.df[
  waze.routes.df$weekday %in% c("martes", "miércoles") &
  (
    grepl("Av. Los Carrera", waze.routes.df$name) |
    grepl("Av. Pedro Aguirre Cerda", waze.routes.df$name)
  ),
]
waze.routes.heatmap$hour <- waze.routes.heatmap$updateTime %>% hour()
waze.routes.heatmap$placeName <- NA
for(n in c(waze.routes.heatmap$toName %>% levels(), waze.routes.heatmap$fromName %>% levels())){
  waze.routes.heatmap$placeName[grepl(n, waze.routes.heatmap$name)] <- n
}
waze.routes.heatmap$placeName <- waze.routes.heatmap$placeName %>% as.factor()
waze.routes.heatmap$dirName <- NA
for(n in c("O.P", "P.O")){
  waze.routes.heatmap$dirName[grepl(n, waze.routes.heatmap$name)] <- n
}
waze.routes.heatmap$dirName <- waze.routes.heatmap$dirName %>% as.factor()
waze.routes.heatmap$placeName %>% summary()

waze.routes.heatmap$name[waze.routes.heatmap$placeName == "Av. Los Carrera" & waze.routes.heatmap$dirName == "O.P"] %>% as.character() %>% as.factor() %>% levels()

waze.routes.heatmap$name.number <- waze.routes.heatmap$name %>% sapply(., function(n) str_split(n, "_")[[1]][1]) %>% as.numeric()

waze.routes.heatmap$name.number %>% summary()

display.heat.map = function(placeName = "Av. Los Carrera", dirName = "O.P", filter = T, title = "") {
  filtered.data <- waze.routes.heatmap[waze.routes.heatmap$placeName == placeName & waze.routes.heatmap$dirName == dirName & filter,]
  name.order <- filtered.data %>%
    select(name, name.number) %>%
    distinct() %>%
    arrange(name.number) %>%
    pull(name)
  plot.data <- filtered.data %>%
    group_by(name, hour, name.number) %>%
    summarise(speed = speed %>% mean(na.rm = T)) %>%
    ungroup() %>%
    mutate(name = name %>% factor(levels = name.order))
  plot.data %>% 
    ggplot() +
    geom_tile(aes(
      x = name,
      y = hour,
      fill = speed
    )) +
    scale_fill_gradientn(
      colors = c(
        "red",
        "orange",
        "yellow",
        "lightgreen",
        "darkgreen"
      )
    ) +
    labs(title = paste("Mapa de calor en", placeName, "en dirección", dirName, title), x = "Tramo", y = "Hora", fill = "Velocidad") +
    theme(axis.text.x = element_text(angle = 90, hjust = 0, vjust = 0.5))
}

for(placeName in waze.routes.heatmap$placeName %>% levels()){
  for(dirName in waze.routes.heatmap$dirName %>% levels()){
    for(weekday in waze.routes.heatmap$weekday %>% as.character() %>% as.factor() %>% levels()){
      display.heat.map(placeName, dirName, waze.routes.heatmap$date >= "2025-12-16" & waze.routes.heatmap$weekday == weekday, paste("durante el día", weekday)) %>% print()
    }
  }
}
```

El sistema procesó 766668 registros de datos de rutas provenientes de la API de Waze, consolidando información de navegación y alertas de tráfico durante un período de 21 días.

### Matriz de correlación

```{r waze.routes.df.corr, echo=FALSE, message=FALSE, warning=FALSE}
waze.routes.df.cor <- waze.routes.df %>% mutate(
  toName = toName %>% as.numeric() %>% replace.na(),
  name = name %>% as.numeric() %>% replace.na(),
  fromName = fromName %>% as.numeric() %>% replace.na(),
  id = id %>% as.numeric() %>% replace.na(),
  type = type %>% as.numeric() %>% replace.na(),
  leadAlert.city = leadAlert.city %>% as.numeric() %>% replace.na(),
  leadAlert.externalImageId = leadAlert.externalImageId %>% as.numeric() %>% replace.na(),
  leadAlert.street = leadAlert.street %>% as.numeric() %>% replace.na(),
  leadAlert.subType = leadAlert.subType %>% as.numeric() %>% replace.na(),
  leadAlert.id = leadAlert.id %>% as.numeric() %>% replace.na(),
  leadAlert.type = leadAlert.type %>% as.numeric() %>% replace.na(),
  broadcasterId = broadcasterId %>% as.numeric() %>% replace.na(),
  areaName = areaName %>% as.numeric() %>% replace.na(),
  isMetric = isMetric %>% as.numeric() %>% replace.na(),
  updateTime = updateTime %>% as.numeric(),
  date = date %>% as.numeric(),
  subfolder = subfolder %>% as.numeric(),
  file = file %>% as.numeric() %>% replace.na(),
  weekday = weekday %>% as.numeric() %>% replace.na()
) %>%
  cor(use = "pairwise.complete.obs")
waze.routes.df.cor %>%
  ggcorrplot() +
  theme(axis.text.x = element_text(angle = 90, hjust = 1, vjust = 0.5, size = 8), axis.text.y = element_text(size = 8))
waze.routes.df.cor %>%
  round(digits = 3) %>%
  kable() %>%
  kable_styling(full_width = F) %>%
  column_spec(1, bold = T, border_right = T) %>%
  add_header_above(c(" " = 1, "Variables" = ncol(waze.routes.df.cor))) %>%
  pack_rows("Variables", 1, nrow(waze.routes.df.cor)) %>%
  row_spec(0, angle = 90, extra_css = "vertical-align: bottom;") %>%
  column_spec(2:ncol(waze.routes.df.cor), width = "0.5cm")
```


```{r waze.data.corr.export, eval=FALSE, include=FALSE}
waze.routes.df.cor %>% write.csv(file = "corr/waze.routes.df.csv")
```

### Metadatos de Procesamiento

- **Tiempo de lectura**: 4 horas, 13 minutos, 36.01 segundos
- **Tiempo de unión**: 15.76 segundos
- **Tiempo de transformación**: 4 minutos, 35.99 segundos
- **Total de procesamiento**: 4 horas, 18 minutos, 27.76 segundos

### Período de Monitoreo

- **Fecha inicial**: 24 de noviembre de 2025 a las 15:31:51
- **Fecha final**: 29 de diciembre de 2025 a las 19:46:46
- **Duración**: 35 días, 4 horas, 14 minutos, 55 segundos
- **Estructura temporal**: Datos organizados por fecha en estructura de carpetas

### Granularidad Temporal

- Diferencia Mínima: 1 minuto, 51.2 segundos
- Diferencia máxima: 1 día, 23 horas, 25 minutos, 2.32 segundos
- Diferencia Media: 5 minutos, 24.1 segundos (lineal); 5 minutos, 2.58 segundos (logarítmico)
- Diferencia Mediana: 5 minutos
- Desviación Standard: 24 minutos, 57.95 segundos (lineal); 1.16 segundos (logarítmico)

```{r waze.routes.time, echo=FALSE, message=FALSE, warning=FALSE}
waze.routes.times <- waze.routes[waze.routes$updateTime %>% order(),] %>% distinct(updateTime)
differences <- (waze.routes.times$updateTime - c(NA, waze.routes.times$updateTime[1:(waze.routes.times %>% nrow() - 1)])) %>% as.numeric()
positive.differences <- differences[differences > 0]
#positive.differences %>% summary()
ggplot() +
  geom_histogram(aes(x = positive.differences)) +
  scale_x_log10()
```

**Outliers**: Media y desviación standard (logarítmico)

```{r waze.routes.time.ol, echo=FALSE, message=FALSE, warning=FALSE}
is.outlier <- positive.differences %>% is.outlier.m.n.sd(func = log)
ggplot() +
  geom_histogram(aes(x = positive.differences, fill = is.outlier)) +
  scale_x_log10()
```

Hay 60 outliers inferiores y 176 outliers superiores, dando un total de 235 outliers

### Distribución Temporal

```{r waze.routes.month.time, echo=FALSE, message=FALSE, warning=FALSE}
waze.routes.dates <- data.frame(
  Hora = waze.routes$updateTime %>% hour(),
  `Día de la Semana` = waze.routes$updateTime %>% weekdays() %>% factor(levels = weekdays)
)
waze.routes.dates %>%
  count(Hora, Día.de.la.Semana, .drop = F) %>%
  ggplot() +
  geom_tile(aes(y = Hora, x = Día.de.la.Semana, fill = n)) +
  scale_fill_gradientn(
    name = "Cantidad",
    colors = c(
      "red",
      "orange",
      "yellow",
      "lightgreen",
      "darkgreen"
    )
  ) +
  labs(y = "Hora", x = "Día de la Semana")
waze.routes.dates %>%
  count(Hora, Día.de.la.Semana, .drop = F) %>%
  spread(key = Día.de.la.Semana, value = n, fill = 0) %>%
  as.data.frame() %>%
  column_to_rownames("Hora") %>%
  as.matrix() %>%
  kable()
```

### Granularidad Espacial

- Distancia Mínima: 32 centímetros
- Distancia Máxima: 730.01 metros
- Distancia Media: 53.59 metros (lineal); 29.66 metros (logarítmico)
- Distancia Mediana: 29.31 metros
- Desviación Standard: 76.16 metros (lineal); 3.25 metros (logarítmico)

```{r waze.routes.df.space, echo=FALSE, message=FALSE, warning=FALSE}
waze.routes.dist <- waze.routes.df %>%
  mutate(
    prev.x = x %>% lag(),
    prev.y = y %>% lag(),
    same.id = (id == (id %>% lag(default = id %>% as.factor() %>% first() - 1))),
    same.date = (date == (date %>% lag(default = date %>% first() - 1))),
    same.file = (file == (file %>% lag(default = file %>% first() - 1))),
  ) %>%
  mutate(
    dist = if_else(same.id & same.date & same.file, haversine.dist(y, x, prev.y, prev.x), NA_real_)
  ) %>%
  pull(dist)
waze.routes.positive.dist <- waze.routes.dist[waze.routes.dist > 0]
#waze.routes.positive.dist %>% summary()
ggplot() +
  geom_histogram(aes(x = waze.routes.positive.dist)) +
  scale_x_log10()
```

**Outliers**: Media y desviación standard (logarítmico)

```{r waze.routes.df.space.ol, echo=FALSE, message=FALSE, warning=FALSE}
is.outlier <- waze.routes.positive.dist %>% is.outlier.m.n.sd(func = log)
ggplot() +
  geom_histogram(aes(x = waze.routes.positive.dist, fill = is.outlier)) +
  scale_x_log10()
```

Hay 139900 outliers inferiores y 55960 outliers superiores, dando un total de 195860 outliers

### Distribución Espacio-Temporal

**Comuna y Día de la Semana**

```{r waze.routes.spacetime.0, echo=FALSE, message=FALSE, warning=FALSE}
waze.routes.spacetime <- data.frame(
  Hora = waze.routes$updateTime[!(waze.routes$leadAlert.id %>% is.na())] %>% hour(),
  Día = waze.routes$updateTime[!(waze.routes$leadAlert.id %>% is.na())] %>% weekdays() %>% factor(levels = weekdays),
  Comuna = waze.routes$leadAlert.city[!(waze.routes$leadAlert.id %>% is.na())] %>% factor(levels = waze.routes$leadAlert.city %>% fct_infreq() %>% levels())
)
waze.routes.spacetime %>%
  count(Día, Comuna, .drop = F) %>%
  ggplot() +
  geom_tile(aes(x = Comuna %>% fct_rev(), y = Día %>% fct_rev(), fill = n)) +
  scale_fill_gradientn(
    name = "Cantidad",
    colors = c(
      "red",
      "orange",
      "yellow",
      "lightgreen",
      "darkgreen"
    )
  ) +
  labs(x = "Comuna", y = "Día de la Semana") +
  scale_y_discrete(labels = label_wrap_gen(width = 20))
waze.routes.spacetime %>%
  count(Día, Comuna, .drop = F) %>%
  spread(key = Día, value = n, fill = 0) %>%
  as.data.frame() %>%
  column_to_rownames("Comuna") %>%
  as.matrix() %>%
  kable()
```

**Comuna y Hora**

```{r waze.routes.spacetime.1, echo=FALSE, message=FALSE, warning=FALSE}
waze.routes.spacetime %>%
  count(Hora, Comuna, .drop = F) %>%
  ggplot() +
  geom_tile(aes(x = Comuna %>% fct_rev(), y = Hora, fill = n)) +
  scale_fill_gradientn(
    name = "Cantidad",
    colors = c(
      "red",
      "orange",
      "yellow",
      "lightgreen",
      "darkgreen"
    )
  ) +
  labs(x = "Comuna", y = "Hora") +
  scale_y_discrete(labels = label_wrap_gen(width = 20))
waze.routes.spacetime %>%
  count(Hora, Comuna, .drop = F) %>%
  spread(key = Hora, value = n, fill = 0) %>%
  as.data.frame() %>%
  column_to_rownames("Comuna") %>%
  as.matrix() %>%
  kable()
```

### Características del Dataset Consolidado

**Volumen y Estructura**

- **Registros totales**: 4399211 puntos de ruta
- **Rutas únicas (agrupadas)**: 766668 rutas
- **Nivel de detalle**: Desagregación punto por punto de trayectos

**Análisis de Orígenes y Destinos**

*Principales Destinos* (`toName`)

- "Av. Los Carrera": 492858 referencias
- "Av. Pedro Aguirre Cerda": 109524 referencias
- "Ruta 160": 54762 referencias

```{r waze.routes.toName, echo=FALSE, message=FALSE, warning=FALSE}
waze.routes %>% ggplot() +
  geom_bar(aes(y = toName %>% fct_infreq() %>% fct_rev(), fill = total_points %>% as.factor())) +
  labs(y = "toName", fill = "total_points")
```

*Principales Orígenes* (`fromName`)

- "Av. Los Carrera": 511112 referencias
- "Av. Pedro Aguirre Cerda": 118651 referencias
- "Ruta 160": 45635 referencias

```{r waze.routes.fromName, echo=FALSE, message=FALSE, warning=FALSE}
waze.routes %>% ggplot() +
  geom_bar(aes(y = fromName %>% fct_infreq() %>% fct_rev(), fill = total_points %>% as.factor())) +
  labs(y = "fromName", fill = "total_points")
```

**Métricas de Desempeño de Rutas**

*Tiempos de Viaje*

- **Tiempo histórico** (`historicTime`):
  - Mínimo: 1
  - Máximo: 344
  - Media: 20.74 (lineal); 14.72 (logarítmico)
  - Mediana: 13
  - Desviación Standard: 23.23 (lineal); 2.25 (logarítmico)
- **Tiempo estimado** (`time`):
  - Mínimo: 0
  - Máxmimo: 952
  - Media: 26.96 (lineal); 17.94 (logarítmico)
  - Mediana: 16
  - Desviación Standard: 34.7 (lineal); 2.29 (logarítmico)
- **Unidades por confirmar**: Minutos o segundos (requiere validación)

```{r waze.routes.historicTime, echo=FALSE, message=FALSE, warning=FALSE}
waze.routes %>% ggplot() +
  geom_histogram(aes(x = historicTime)) +
  scale_x_log10()
```

**Outliers**: Media y desviación standard (logarítmico)

```{r waze.routes.historicTime.ol, echo=FALSE, message=FALSE, warning=FALSE}
is.outlier <- waze.routes$historicTime %>% is.outlier.m.n.sd(func = function(n) ifelse(n > 0, n %>% log(), NA))
waze.routes %>% ggplot() +
  geom_histogram(aes(x = historicTime, fill = is.outlier)) +
  scale_x_log10()
```

Hay 25041 outliers inferiores y 25421 outliers superiores, dando un total de 50462 outliers

*Distancias y Velocidades*

- **Longitud de ruta** (`length`):
  - Mínimo: 0
  - Máximo: 1257
  - Media: 175.4 (lineal); 127.73 (logarítmico)
  - Mediana: 126
  - Desviación Standard: 189.09 (lineal); 2.09 (logarítmico)
- **Velocidad calculada** (`speed`):
  - Mínimo: 0.52
  - Máximo: 24
  - Media: 8.06 (lineal)
  - Mediana: 7.89
  - Desviación Standard: 3.74 (lineal)
- **Relación distancia/tiempo**: Consistente con tráfico urbano congestionado

```{r waze.routes.speed, echo=FALSE, message=FALSE, warning=FALSE}
waze.routes %>% ggplot() +
  geom_histogram(aes(x = speed))
```

**Outliers**: Media y desviación standard (lineal)

```{r waze.routes.speed.ol, echo=FALSE, message=FALSE, warning=FALSE}
is.outlier <- waze.routes$speed %>% is.outlier.m.n.sd()
waze.routes %>% ggplot() +
  geom_histogram(aes(x = speed, fill = is.outlier))
```

Hay 11 outliers inferiores y 33636 outliers superiores, dando un total de 33647 outliers

**Sistema de Alertas Waze**

*Distribución de Alertas*

- **Total de alertas registradas**: 301

```{r waze.routes.alerts, echo=FALSE, message=FALSE, warning=FALSE}
waze.routes.alerts <- waze.routes[!(waze.routes$leadAlert.id %>% is.na()),]
```

*Tipología de Alertas* (`leadAlert.type`)

**Accidentes (ACCIDENT) - 159 casos**:

- `NO_SUBTYPE`: 146 casos
- `ACCIDENT_MAJOR`: 13 casos

**Peligros (HAZARD) - 134 casos**:

- `HAZARD_ON_ROAD`: 60 casos
- `HAZARD_ON_ROAD_OBJECT`: 32 casos
- `HAZARD_ON_ROAD_TRAFFIC_LIGHT_FAULT`: 22 casos
- `HAZARD_ON_ROAD_CAR_STOPPED`: 10 casos
- `HAZARD_ON_ROAD_CONSTRUCTION`: 6 casos
- `HAZARD_WEATHER_FLOOD`: 4 casos

**Carreteras cerradas (ROAD_CLOSED) - 8 casos**

- `NO_SUBTYPE`: 8 casos

```{r waze.routes.alerts.types, echo=FALSE, message=FALSE, warning=FALSE}
waze.routes.alerts %>% ggplot() +
  geom_bar(aes(y = leadAlert.subType %>% fct_infreq() %>% fct_rev(), fill = leadAlert.type %>% fct_infreq())) +
  labs(y = "leadAlert.subType", fill = "leadAlert.type")
```

*Interacción de Usuarios con Alertas*

- **Comentarios** (`numComments`): 0-89 (media: 9.2, mediana: 4)
- **Me gusta** (`numThumbsUp`): 0-46 (media: 7.5, mediana: 3)
- **Reportes de inexistencia** (`numNotThereReports`): 0 (120 casos)  y 1 (89 casos)

```{r waze.routes.alerts.users, echo=FALSE, message=FALSE, warning=FALSE}
waze.routes.alerts %>% ggplot() +
  geom_point(aes(x = leadAlert.numComments, y = leadAlert.numThumbsUp, colour = leadAlert.numNotThereReports %>% as.factor())) +
  labs(colour = "leadAlert.numNotThereReports")
```

*Contexto Geográfico de Alertas*

- **Calles más reportadas**:
  - "Ruta 160": 176 alertas
  - "Av. Pedro Aguirre Cerda": 108 alertas
  - "Av. Los Carrera Poniente": 9 alertas
  - "Av. Los Carrera": 8 alertas
- **Ciudades involucradas**:
  - "San Pedro de la Paz": 108 alertas
  - "Concepción": 17 alertas
  - Sin especificar: 176 alertas

```{r waze.routes.alerts.cities, echo=FALSE, message=FALSE, warning=FALSE}
waze.routes.alerts %>% ggplot() +
  geom_bar(aes(y = leadAlert.street %>% fct_infreq() %>% fct_rev(), fill = leadAlert.city %>% fct_infreq())) +
  labs(y = "leadAlert.street", fill = "leadAlert.city")
```

### Procesamiento y Normalización de Datos

**Paso a paso**

- Se leen las carpetas
- En cada carpeta, se leen las sub-carpetas
- En cada sub-capreta, se leen los archivos .json
- En cada archivo, se leen las rutas
- Por cada ruta, se crea la fila con todos sus valores, excepto "line", "bbox", "subRoutes", "leadAlert" y "alternateRoute"
- Si "leadAlert" no es nulo, las columnas "leadAlert.numComments", "leadAlert.city", "leadAlert.externalImageId", "leadAlert.numThumbsUp", "leadAlert.street", "leadAlert.subType", "leadAlert.id", "leadAlert.position", "leadAlert.type" y "leadAlert.numNotThereReports" toman los valores de "numComments", "city", "externalImageId", "numThumbsUp", "street", "subType", "id", "position", "type" y "numNotThereReports", respectivamente de "leadAlert"
- Si "bbox" no es nulo, las columnas "minY", "minX", "maxY" y "maxX" toman los valores de "minY", "minX", "maxY" y "maxX" de "bbox", respectivamente
- Si "line" no es nulo, se clona la fila una vez por cada elemento en "line", por cada punto, "x" e "y" toman el valor de "x" e "y", respectivamente del elemento de "line", "point_index", la posición del punto en "line" y "total_points", la cantidad de puntos en "line"
- Se unen las filas en un data.frame
- Se crea la columna "speed" con el valor de "lenght" / "time"
- Se crea la columna "broadcasterId" con el valor de "broadcasterId" del archivo
- Se crea la columna "areaName" con el valor de "areaName" del archivo
- Se crea la columna "isMetric" con el valor de "isMetric" del archivo
- Se crea la columna "updateTime" con el valor de "updateTime" del archivo
- Se crea la columna "date" con el nombre de la carpeta
- Se crea la columna "subfolder" con el nombre de la sub-carpeta
- Se crea la columna "file" con el nombre del archivo quitando la cadena ".json", separándolo en una lista de cadenas con el caracter "_" y tomando en último elemento (ej: "1763409379301_2025-12-01_000004.267298.json" -> "000004.267298")
- Se unen las filas en un solo data.frame
- "toName" se convierte en factor
- "name" se convierte en factor
- "fromName" se convierte en factor
- "type" se convierte en factor
- "leadAlert.city" se convierte en factor
- "leadAlert.externalImageId" se convierte en factor
- "leadAlert.street" se convierte en factor
- "leadAlert.subType" se convierte en factor
- "leadAlert.position" se divide en "leadAlert.position.lat" y "leadAlert.position.lng" separándolo por el caracter " "
- Se elimina la columna "leadAlert.position"
- "leadAlert.type" se convierte en factor
- "broadcasterId" se convierte en factor
- "areaName" se convierte en factor
- "date" se convierte en POSIXct con formato "%d-%m-%Y"
- "subfolder" se convierte en factor
- "file" se convierte en factor
- "updateTime" se divide por 1000 y se convierte en POSIXct con origen en "1970-01-01" y zona horaria "UTC"
- Se crea la columna "weekday" siendo el día de la semana de "updateTime" y se convierte en factor

# Discretización de datos

```{r quantum.data, include=FALSE}
meters.per.degree.lat <- 111320

meters.per.degree.lng <- function(lat.d) {
  meters.per.degree.lat * cos(lat.d * pi / 180)
}

calculate.street.heading <- function(lng.data, lat.data, buffer.meters = 100) {
  if(lat.data %>% length() == 0) return(0 %>% numeric())
  points.df <- data.frame(lng = lng.data, lat = lat.data)
  points.sf <- points.df %>% st_as_sf(
    coords = c("lng", "lat"),
    crs = 4326
  )
  bbox <- points.sf %>% st_bbox()
  osm.roads <- opq(bbox = bbox + c(-1, -1, 1, 1) * 0.002) %>%
    add_osm_feature(key = "highway") %>%
    osmdata_sf()
  if(osm.roads$osm_lines %>% is.null() | osm.roads$osm_lines %>% nrow() == 0) {
    message("No streets found")
    return(rep(NA, lat.data %>% length()))
  }
  roads.proj <- osm.roads$osm_lines %>% st_transform(crs = 3857)
  points.proj <- points.sf %>% st_transform(crs = 3857)
  coords <- roads.proj %>% st_coordinates() %>% as.data.frame()
  p1 <- coords[-(coords %>% nrow()),]
  p2 <- coords[-1,]
  valid.segments <- p1$L1 == p2$L1
  p1 <- p1[valid.segments,]
  p2 <- p2[valid.segments,]
  seg.headings <- atan2(p2$Y - p1$Y, p2$X - p1$X)
  mid.points.sf <- data.frame(heading = seg.headings) %>% st_as_sf(
    geometry = mapply(
      function(x1, y1, x2, y2) (c(x1 + x2, y1 + y2) / 2) %>% st_point(),
      p1$X, p1$Y, p2$X, p2$Y,
      SIMPLIFY = F
    ) %>% st_sfc(),
    crs = 3857
  )
  nearest.indices <- st_nearest_feature(points.proj, mid.points.sf)
  return(seg.headings[nearest.indices])
}

stat.mode <- function(x){
  ux <- x %>% unique()
  ux[match(x, ux) %>% tabulate() %>% which.max()]
}

middle.value <- function(X) X %>% range(na.rm = T) %>% mean(na.rm = T)

quantum.data <- function(
  time.data = NA,
  lng.data = NA,
  lat.data = NA,
  field.data = NA,
  names.data = NA,
  speed.data = NA,
  length.data = NA,
  minX = NA,
  maxX = NA,
  minY = NA,
  maxY = NA,
  time.gap = 5,
  space.gap = 50,
  street.aligned = T,
  street.angle.tolerance = 30,
  compile.function = function(X, W) X %>% weighted.mean(w = W)
) {
  dt <- data.table(
    time = time.data,
    lng = lng.data,
    lat = lat.data,
    id = field.data,
    name = names.data,
    speed = speed.data,
    mX = minX,
    MX = maxX,
    mY = minY,
    MY = maxY
  )
  first.date <- time.data %>% min()
  if (street.aligned) dt[, heading := calculate.street.heading(lng, lat)]
  else dt[, heading := 0]
  rad.tolerance <- street.angle.tolerance * pi / 180
  y.gap.meters <- rad.tolerance %>% sin() * space.gap
  dt[, time.bin := time %>% cut(breaks = seq(time %>% min(), time %>% max() + time.gap, by = time.gap), include.lowest = T, labels = F) %>% as.integer()]
  dt.expanded <- dt[, {
    cxm <- lat %>% meters.per.degree.lng() * lng
    cym <- lat * meters.per.degree.lat
    x.along <- heading %>% cos() * cxm + heading %>% sin() * cym
    y.across <- -heading %>% sin() * cxm + heading %>% cos() * cym
    dist.m <- ((lat %>% meters.per.degree.lng() * (MX - mX)) ^ 2 + (meters.per.degree.lat * (MY - mY)) ^ 2) %>% sqrt()
    start.m <- x.along - dist.m / 2
    end.m <- x.along + dist.m / 2
    bins.idx <- ((start.m / space.gap) %>% floor()):((end.m / space.gap) %>% floor())
    by <- (y.across / y.gap.meters) %>% floor()
    bins.idx %>% lapply(., function(bx){
      m.along.start <- bx * space.gap
      m.along.end <- (bx + 1) * space.gap
      m.across.min <- by * y.gap.meters
      m.across.max <- (by + 1) * y.gap.meters
      len <- max(0, min(end.m, m.along.end) - max(start.m, m.along.start))
      inv.rot <- function(a, q){
        x.glob <- heading %>% cos() * a - heading %>% sin() * q
        y.glob <- heading %>% sin() * a + heading %>% cos() * q
        return(
          list(
            x = x.glob,
            y = y.glob
          )
        )
      }
      p1 <- inv.rot(m.along.start, m.across.min)
      p2 <- inv.rot(m.along.end, m.across.min)
      p3 <- inv.rot(m.along.end, m.across.max)
      p4 <- inv.rot(m.along.start, m.across.max)
      list(
        time.bin = time.bin,
        x.bin = bx,
        y.bin = by,
        minX = min(p1$x, p2$x, p3$x, p4$x) / lat %>% meters.per.degree.lng(),
        maxX = max(p1$x, p2$x, p3$x, p4$x) / lat %>% meters.per.degree.lng(),
        minY = min(p1$y, p2$y, p3$y, p4$y) / meters.per.degree.lat,
        maxY = max(p1$y, p2$y, p3$y, p4$y) / meters.per.degree.lat,
        speed = speed,
        len = len,
        name = name,
        heading = heading,
        lng = (heading %>% cos() * (m.along.start + m.along.end) / 2 - heading %>% sin() * (m.across.min + m.across.max) / 2) / lat %>% meters.per.degree.lng(),
        lat = (heading %>% sin() * (m.along.start + m.along.end) / 2 + heading %>% cos() * (m.across.min + m.across.max) / 2) / meters.per.degree.lat
      )
    }) %>% rbindlist()
  }, by = 1:(dt %>% nrow())]
  result <- dt.expanded[, {
    list(
      time = time.bin[1] * time.gap + first.date,
      lng = (minX[1] + maxX[1]) / 2,
      lat = (minY[1] + maxY[1]) / 2,
      minX = minX[1],
      maxX = maxX[1],
      minY = minY[1],
      maxY = maxY[1],
      field = speed %>% compile.function(W = len),
      summarised = name[1],
      n.points = .N,
      street.heading = heading %>% first(),
      street.heading.from.north = 90 - heading %>% first() * 180 / pi + ifelse(heading %>% first() > pi / 2, 360, 0)
    )
  }, by = .(time.bin, x.bin, y.bin)]
  return(result[order(time.bin, x.bin)])
}
```

[Ver Diagrama de Flujo](https://mermaid.live/edit#pako:eNqFVV1PIzcU_SuWpdWCFAYICYRRSMVCd1upuyCSvuyEB8_4ZmLqsae2ByWL-DF97EOf-hP4Y722Z5JAt-o8gD-uz7k-9_jmiRaaA01paVi9JLPruSL4TR0zbi_7WYlC6JT83jDlmirhzLH7fXJwMCG45bIrA8wQv5o4lksghVZ-qi3hQEA5wzi7j5Dx77t35BocmEooVoiXv5UPvDECY-M8hnn0SGMvpSgV8CfrDIBLWJySiwsy--G5je6C8AiZvvwVTn4C9xMwLlSZ_SJZhXkWTBaNZA6SFmsZ98e5OZyMxeRXy8hNDWoadj-zmtTMMIKMyl_T300yjyJhfCgm998h_6ID91cwuiOfgiMtEbkgR2_VuNJqIcrGbNX4IJSN29srBNQYml3FaxiC4iZOSzBMFUDWZJ2UrE4qL69taXYS2YGIe3EclmeiAqRt6-lwluRCkZxZxjXWMS4h-tvsf1zVTNmQ-ZrMMBG70KZq77J39fKHT1WTWnv1OSM6t2Ae4_5-RGm5Qx4tnFbZnI7zyQ466nIdfLXHXQJ-nQPfHx_mkzl9lZRt8mjlOb01ugDLKm-umMNtg6M5jZH-48JA4ZCQzD5sVzdphKQQ5iEGZThc4zCYQRsOCu9kyafbKWEEdTe6091_23MB5k47FkD8IAiQkk0pV-hrjTXyRWQF4tjOlJet--ABbGfBkPXGL9_xpP86vkDuPZVtHp4hWF1LwNaYCJMInK96JF8HzqLJBRgvtVcMJNbsAZzeQfZgbQ94RJbsY6NiMkI9Jka7nXs9vvxpnMAqkPr4oB4EArTTrnql1LnPYYcg4gaKm0cwktVb03uZhGs4eS9Bvcf7S2KhrHyJAzr3XUd7XYLh8KItMCj-xryXpYFyt-u0ZLF9GN3U_v1iVIN9IKjRvYweFiz8Wydbgn_5Dx-Y1VLw7jncgW2k2_9__3Xc7ZOtaq9wdllLUQTrVbWQkCxw0R_tnIJ-q4AL73R8HMa_XJ9z0OmNNzrMSICKgfECb1UugoqC-7aS60aFBpLrVStx8BzITW8PmBuYgPpFG7fseuAG93XjTRaYcqJ85H8Wacq8gnG6ixlIPqKZ5RRXs5vgp9dVwtxXO_XZBMdWo_hehkspuUN3G_X6d8xgqSrkvd-nPfxpFJymzjTQoxW-IOan9MmjzqlbQgVzmuKQM_ObL-4znsEG8lXrqjuGBS2XNF0waXHW1EgF14KhU7Yh4Kt2hWI7mo5G_YBB0ye6ounx6DQZ9s_Pz4_OhoPT0_PBqEfXND04Oz5Ozkf94eDspN8_weXnHv0WaE-S0Wg0OOofnw2PhoP-ybD__A-oeqIJ)

```{mermaid}
graph TD
    Start([Inicio: quantum.data]) --> Init[Crear data.table con datos de entrada]
    
    %% Determinación de Orientación
    Init --> IsAligned{street.aligned == T?}
    IsAligned -- Sí --> GetHeading[Llamar calculate.street.heading<br/><i>Usa OpenStreetMap para alinear con la calle</i>]
    IsAligned -- No --> ZeroHeading[Set heading = 0]
    
    %% Configuración de Bins
    GetHeading --> Config[Calcular rad.tolerance y y.gap.meters]
    ZeroHeading --> Config
    Config --> TimeBin[Crear time.bin basado en time.gap]
    
    %% Expansión y Transformación (Cálculo por cada observación)
    TimeBin --> Expansion["<b>Expansión de Datos (dt.expanded)</b>"]
    
    subgraph "Procesamiento por Punto"
        direction TB
        Expansion --> Projection[Proyectar coordenadas GPS a metros]
        Projection --> Rotation[Rotación: Calcular x.along y y.across<br/><i>Alinear ejes con la dirección de la calle</i>]
        Rotation --> Bins[Determinar bins espaciales bx, by<br/>cubiertos por el objeto]
        Bins --> InvRot[Función inv.rot: Calcular vértices p1-p4<br/>en coordenadas globales]
        InvRot --> Overlap[Calcular longitud 'len' del segmento<br/>dentro de cada bin]
    end
    
    %% Agregación
    Overlap --> Grouping[Agrupar por time.bin, x.bin, y.bin]
    
    subgraph "Consolidación (Result)"
        direction TB
        Grouping --> CompFunc[Aplicar compile.function<br/><i>Promedio ponderado por 'len'</i>]
        CompFunc --> CenterCalc[Calcular centroide y bounding box<br/>de la celda]
        CenterCalc --> NorthHeading[Calcular street.heading.from.north]
    end
    
    %% Salida
    NorthHeading --> FinalSort[Ordenar por time.bin y x.bin]
    FinalSort --> End([Fin: Retornar data.table resumida])
```

El proceso de discretización busca transformar un conjunto de observaciones heterogéneas y continuas en una estructura de rejilla regular (teselado) espaciotemporal. Esto permite homogeneizar la información de tráfico para su análisis estadístico.

## Descripción Matemática

Sea una observación $i$ definida por la tupla $(t_i, \lambda_i, \phi_i, v_i, \mathbf{B}_i)$, donde $t$ es el tiempo, $(\lambda, \phi)$ las coordenadas geográficas, $v$ la variable escalar de interés (ej. velocidad) y $\mathbf{B}$ el recuadro delimitador (bounding box) del evento.

### 1. Transformación de Coordenadas

Primero, se proyectan las coordenadas esféricas $(\lambda, \phi)$ a un plano euclidiano local $(x, y)$ en metros, utilizando el radio de curvatura terrestre según la latitud:

$$
x = \lambda \cdot R \cdot \cos(\phi), \quad y = \phi \cdot R
$$

Donde $R$ es la constante de conversión de grados a metros en el ecuador.

### 2. Rotación al Eje de la Vía (Alineación)

Para cada observación, se identifica el ángulo de orientación de la calle más cercana $\theta$. Se aplica una transformación lineal de rotación para obtener un sistema de coordenadas $(u, v)$ donde el eje $u$ es paralelo a la dirección de la vía y el eje $v$ es perpendicular a ella:

$$
\begin{pmatrix} u \\ v \end{pmatrix} = \begin{pmatrix} \cos\theta & \sin\theta \\ -\sin\theta & \cos\theta \end{pmatrix} \begin{pmatrix} x \\ y \end{pmatrix}
$$

### 3. Función de Discretización (Binning)

El espacio-tiempo se particiona en celdas uniformes. Una observación pertenece a una celda $C_{j,k,l}$ si:

- **Temporalmente**: $j = \lfloor \frac{t}{\Delta t} \rfloor$
- **Longitudinalmente (en la vía)**: $k = \lfloor \frac{u}{\Delta s} \rfloor$
- **Transversalmente**: $l = \lfloor \frac{v}{\Delta y} \rfloor$, donde $\Delta y$ es una tolerancia lateral derivada del ángulo de la vía.

## Parámetros de Entrada

El algoritmo requiere la definición de los siguientes parámetros físicos y geométricos:

- $\Delta t$ **(Time Gap)**: Resolución temporal del análisis (ej. 5 segundos). Determina el tamaño del intervalo en el que se agrupan los eventos cronológicamente.
- $\Delta s$ **(Space Gap)**: Resolución espacial longitudinal (ej. 50 metros). Define la longitud de los segmentos en los que se divide la vía.
- $\theta_{tol}$ **(Angle Tolerance)**: Tolerancia angular para la alineación. Define el margen de error aceptable para considerar que una observación pertenece al flujo de la calle analizada.
- **Función de Agregación** ($f$): Operador matemático para consolidar múltiples valores en una celda. Por defecto, se utiliza la media ponderada por longitud:

$$
\bar{V}_{celda} = \frac{\sum (v_i \cdot L_i)}{\sum L_i}
$$

donde $L_i$ es la fracción del objeto que intersecta la celda espacial.

## Proceso de Discretización

El flujo lógico para la transformación de los datos sigue estos pasos:

1. **Enriquecimiento Geográfico**: Para cada punto, se consulta una base de datos cartográfica (OpenStreetMap) para obtener el vector director de la infraestructura vial más cercana.
2. **Expansión de Objetos**: Si la observación representa un objeto con extensión física (no un punto puntual), el algoritmo proyecta su longitud sobre el eje de la vía. Si un objeto es más largo que el parámetro $\Delta s$, este se fragmenta matemáticamente para repartir su contribución entre múltiples celdas espaciales adyacentes.
3. **Cálculo de Intersecciones**: Se calcula el peso $L$ (longitud de ocupación) para cada celda afectada. Esto garantiza que objetos grandes o que cruzan fronteras de celdas no sesguen el promedio.
4. **Colapso Estadístico**: Se agrupan todas las contribuciones que caen en la misma terna de índices $(j, k, l)$ y se calcula la media ponderada de la variable objetivo.
5. **Georeferenciación Inversa**: Los centroides de las celdas discretas en el plano $(u, v)$ se transforman de vuelta a coordenadas $(\lambda, \phi)$ para permitir su visualización en mapas y sistemas de información geográfica (SIG).

## Ejemplo

```{r discretization.example, eval=FALSE}
degrees.format <- function(deg, sec.decimals = 3) {
  pos <- deg %>% abs()
  degrees <- (pos %>% floor() * deg %>% sign()) %>% as.integer()
  minutes <- ((pos * 60) %% 60) %>% floor()
  seconds <- ((pos * 3600) %% 60) %>% round(sec.decimals)
  return(paste0(degrees, "°", sprintf("%02d", minutes), "'", sprintf(paste0("%0", 2 + sec.decimals + ifelse(sec.decimals > 0, 1, 0), ifelse(sec.decimals > 0, paste0(".", sec.decimals, "f"), "d")), seconds), "''"))
}
filtered.waze.routes <- waze.routes[waze.routes$updateTime >= "2026-01-16" %>% as.POSIXct(tz = "UTC") & waze.routes$updateTime <= "2026-01-18" %>% as.POSIXct(tz = "UTC"),]
filtered.waze.routes.polygons <- filtered.waze.routes %>% create.bbox.polygons()
sg <- 100
tg <- 1800
start.sys <- Sys.time()
discretization.example <- quantum.data(
  time.data = filtered.waze.routes$updateTime,
  lng.data = (filtered.waze.routes$minX + filtered.waze.routes$maxX) / 2,
  lat.data = (filtered.waze.routes$minY + filtered.waze.routes$maxY) / 2,
  field.data = filtered.waze.routes$id,
  #names.data = filtered.waze.routes$name,
  speed.data = filtered.waze.routes$speed,
  minX = filtered.waze.routes$minX,
  maxX = filtered.waze.routes$maxX,
  minY = filtered.waze.routes$minY,
  maxY = filtered.waze.routes$maxY,
  space.gap = sg,
  time.gap = tg,
  street.aligned = T,
  street.angle.tolerance = 10
)
end.sys <- Sys.time()
dt.sys <- end.sys - start.sys

plot.data <- discretization.example %>%
  filter(
    !(time %>% is.na()),
    !(lng %>% is.na()),
    !(lat %>% is.na()),
    !(field %>% is.na())
  ) %>%
  arrange(time) %>%
  mutate(
    time = time %>% as.POSIXct(tz = "UTC")
  )

ui <- fluidPage(
  titlePanel("Mapa con Filtro de Tiempo"),
  sidebarLayout(
    fluidRow(
      column(
        width = 12,
        wellPanel(
          sliderInput(
            "time_range",
            "Selecciona el rango de tiempo:",
            min = plot.data$time %>% min(),
            max = plot.data$time %>% max(),
            value = plot.data$time %>% range(),
            step = tg,
            animate = T,
            width = "100%",
            timezone = "+0000"
          )
        )
      )
    ),
    fluidRow(
      column(
        width = 12,
        leafletOutput("map", height = "600px")
      )
    )
  )
)

server <- function(input, output, options){
  rectangle <- function(lng, lat, angle, dx, dy){
    corners.x <- c(-1, -1, 1, 1, -1) * dx / 2
    corners.y <- c(1, -1, -1, 1, 1) * dy / 2
    rot.x <- angle %>% cos() * corners.x - angle %>% sin() * corners.y
    rot.y <- angle %>% sin() * corners.x + angle %>% cos() * corners.y
    final.lng <- lng + rot.x / lat %>% meters.per.degree.lng()
    final.lat <- lat + rot.y / meters.per.degree.lat
    return(cbind(final.lng, final.lat))
  }
  abs.rectangle <- function(minX, minY, maxX, maxY, angle, center.lat) {
    corners.x <- c(minX, maxX, maxX, minX, minX)
    corners.y <- c(minY, minY, maxY, maxY, minY)
    final.lng.m <- angle %>% cos() * corners.x - angle %>% sin() * corners.y
    final.lat.m <- angle %>% sin() * corners.x + angle %>% cos() * corners.y
    final.lng <- final.lng.m / center.lat %>% meters.per.degree.lng()
    final.lat <- final.lat.m / meters.per.degree.lat
    return(cbind(corners.x, corners.y))
  }
  pal <- colorNumeric(
    palette = c("blue", "green", "yellow", "red"),
    domain = plot.data$field
  )
  pal.dir <- colorNumeric(
    palette = c("#F00", "#FF0", "#0F0", "#0FF", "#00F", "#F0F"),
    domain = c(0, 360)
  )
  sd <- plot.data %>% SharedData$new()
  rect.polys <- 1:(plot.data %>% nrow()) %>% lapply(., function(i){
    d <- plot.data[i,]
    if(d$street.heading %>% is.na() || d$lng %>% is.na()) return(st_polygon())
    coords <- rectangle(d$lng, d$lat, d$street.heading, sg, 5)
    coords %>% list() %>% st_polygon() %>% return()
  })
  abs.rect.polys <- 1:(plot.data %>% nrow()) %>% lapply(., function(i){
    d <- plot.data[i,]
    if(d$lng %>% is.na()) return(st_polygon())
    abs.coords <- abs.rectangle(d$minX, d$minY, d$maxX, d$maxY, d$street.heading, d$lat)
    abs.coords %>% list() %>% st_polygon() %>% return()
  })
  plot.data.sf <- plot.data %>% st_sf(geometry = rect.polys %>% st_sfc(crs = 4326))
  abs.plot.data.sf <- plot.data %>% st_sf(geometry = abs.rect.polys %>% st_sfc(crs = 4326))
  f.data <- reactive({
    input$time_range %>% req()
    plot.data.sf %>%
      filter(time >= input$time_range[1] & time <= input$time_range[2]) %>%
      group_by(geometry) %>%
      summarise(
        field = field %>% weighted.mean(w = n.points),
        lng = lng %>% first(),
        lat = lat %>% first(),
        street.heading = street.heading %>% mean(na.rm = T),
        n.points = n.points %>% sum(),
        time.info = paste(time %>% min() %>% format(., "%H:%M"), "-", time %>% max() %>% format(., "%H:%M")),
        date.info =  ifelse(time %>% min() %>% format(., "%Y-%m-%d") == time %>% max() %>% format(., "%Y-%m-%d"), time %>% min() %>% format(., "%Y-%m-%d"), paste(time %>% min() %>% format(., "%Y-%m-%d"), "-", time %>% max() %>% format(., "%Y-%m-%d"))),
        street.heading.from.north = street.heading.from.north %>% first(),
        .groups = 'drop'
      )
  })
  abs.f.data <- reactive({
    input$time_range %>% req()
    abs.plot.data.sf %>%
      filter(time >= input$time_range[1] & time <= input$time_range[2])
  })
  output$map <- renderLeaflet({
    leaflet() %>%
      addTiles() %>%
      addScaleBar(position = "bottomleft") %>%
      setView(
        lng = plot.data$lng %>% median(na.rm = T),
        lat = plot.data$lat %>% median(na.rm = T),
        zoom = 12
      )
  })
  observe({
    data.to.plot <- f.data()
    abs.data.to.plot <- abs.f.data()
    proxy <- leafletProxy("map") %>% clearShapes()
    if(data.to.plot %>% nrow() == 0){
      proxy
      return()
    }
    proxy %>%
      addPolygons(
        data = data.to.plot,
        fillColor = ~field %>% pal(),
        color = "black",
        fillOpacity = 0.8,
        weight = 0.5,
        popup = ~paste0(
          "Velocidad: ", field %>% round(4),
          " km/h<br>Fecha: ", date.info,
          "<br>Hora: ", time.info,
          "<br>Longitud: ", lng %>% degrees.format(),
          "<br>Latitud: ", lat %>% degrees.format(),
          "<br>Dirección: ", street.heading.from.north %>% round(), "°")
      )
  })
}

shinyApp(ui, server)
```

# Base de Datos

## Creación de tablas

[Ver Modelo Entidad Relación](https://mermaid.live/edit#pako:eNq9Wd1T4zYQ_1cyfrqbgRsSJyH4LdzlWubo0aFMHzqZyQhbCbrYkivLlBzkf6-sD0eWZYOD27yQSKvVfmn3t8uzF5IIeoEH6RcENhQkSzzgH0a2EA-e5Y_ic_X9bvHL4naAosHS-_3bYH619A67l9c3lx-G04_ynFzfL9WXjOQ0hG9n9uf89vOv89sPo8nk4wCDBFr8UkgTlGWI4P54CrlXXSXVu2yLV4Li6zfXdkZDe9u6-BiV3nh5SpPGyzMG2DGOOXPaMERs915mFbMV0jXLDkNGaG_CZ4xCyN4dUObBwh7NfqfoPscg7i-EQQwpW7FdCvvmmeX3vbCtRC1n2GgceW2EKPfxUc98eNaiTgjyrEcbUZLzMC02-uZ5nNEbdP8H_IQrwbd7inEksOLzZX63uLv6bTGI-EM9LH-9vpnfDR5Qxt8nClcMufy_piRpS1uFBm37jLh25dUxxBv2YK-65fgBklUMH2HcMUSlh1KCMOtuT3m4WX7AEMujmkljgjfWRnkfjuCTK9r_a2e3JbsKV5lD2kjEu2y2yjaxV9YIu8qGKAytsaNyr4vm8ubmejH_PghJksaQe4nClFBWJ2AUrNc8vBEOUQQxe4cT5QaFMQL3KOaGfFtARzAGu7p2PG22KX_IA42xjfCPnO7kszgi__CUZrwom2sag2PAIGcqTjqZdg_yv3OAWcXSekfWiBYDCt1aEVch5yu1rSvceLN0knEL7ADhFuHNak3iCNLeqkvHwmJ41Q0PpHiNajzCBxTGR1w4FWFkJrBXcOE7QEgT0kwhjP6fGtw5BwnZ6mn2yV5KuVFQ0a50LwSNtU8TKN-2kZROqaVEkjaALJ7Pk0qWbkmXpavuKcBRb45PeKd9FN5veiRCvEbhY4S3_ULIlJJHdFTW8Bs6Rr5EQW9vocwqZ11assor4nAObiioxpYu-QTHTsQhLN3agku7tclcxIw0B6dyb0NczGpoZV9fIWKrTQZ9uJGwU8awYvrl5fT05Vm7MyilaaOxBarMihTxAasEyudmCt0XRC9y7BBo15qDDX2lJNDjBGNYoQhUMbZ4GP20oqt2w4FuEFytsnmiuLtEv_VG1CLVKNjdCVvEMnn9UVep5FaxihyZ2LJpvGwNJiwyAzS7XCXILC9Js1aNp01d4hQXrdGrBrpTfJVOdIQOjKXCROuhEZTZIyl2CkzaNBU4bJNqNOjAuDapxoW1sYFLG9X_1sYBTs3N0DIbU6V6hVjX39pUwPJ3pU-opOuWd2fDS8WzdKVGdSZo1I9QvGlbPg30LKIDRrBRmkUoH4gja8jorQasLPeKg8xaQVlk7aJq5zNVBKxKaVMZpcBlU5dUchSvGJlz6kCNfh0T7NfYmQNnRSvWqywNosr1h_VAjZe9E29D-Z-A0RyeeFylBBQ_PVHalx57gLwcewH_GgG6LerOnp9JAf6LkEQf467fPHjBGsQZ_5WnBaRV_5UoSSDm1vtMcsy8YHgxmwgmXvDsPXnB6Wg4_jS9GA2nI394MZ7MTrwdXx3y1dn5ZOyP_enYP7sY-_sT76e4d_Rp6I_PZ5Ph-cQf-ePZ1N__CyklP5o)

```{mermaid}
erDiagram
    token {
        INTEGER id "PK AI"
        BLOB(16) token
    }

    source {
        INTEGER id "PK AI"
        VARCHAR(255) name
    }

    permission {
        INTEGER id "PK AI"
        VARCHAR(255) name
    }

    token_source {
        INTEGER id "PK AI"
        INTEGER tkn_id "FK"
        INTEGER src_id "FK"
    }

    token_permission {
        INTEGER id "PK AI"
        INTEGER tkn_id "FK"
        INTEGER prm_id "FK"
    }

    state {
        INTEGER id "PK AI"
        VARCHAR(20) name
    }

    city {
        INTEGER id "PK AI"
        VARCHAR(20) name
        INTEGER state_id "FK"
    }

    sector {
        INTEGER id "PK AI"
        VARCHAR(20) name
    }

    street {
        INTEGER id "PK AI"
        VARCHAR(255) name
        INTEGER city_id "FK"
    }

    tribunal {
        INTEGER id "PK AI"
        VARCHAR(255) name
    }

    alert_type {
        INTEGER id "PK AI"
        VARCHAR(255) name
    }

    alert_subtype {
        INTEGER id "PK AI"
        VARCHAR(255) name
        INTEGER type_id "FK"
    }

    alert_direction {
        INTEGER id "PK AI"
        VARCHAR(10) name
    }

    alert_cause {
        INTEGER id "PK AI"
        VARCHAR(255) name
    }

    route_name {
        INTEGER id "PK AI"
        VARCHAR(255) name
    }

    route_type {
        INTEGER id "PK AI"
        VARCHAR(10) name
    }

    waze_route {
        INTEGER id "PK AI"
        INTEGER src_id "FK"
        DATETIME date
        FLOAT historic_time
        INTEGER from_id "FK"
        INTEGER name_id "FK"
        INTEGER to_id "FK"
        FLOAT length
        FLOAT time
        INTEGER jam_level
        INTEGER type_id "FK"
    }

    route_point {
        INTEGER id "PK AI"
        INTEGER route_id "FK"
        FLOAT latitude
        FLOAT longitude
        INTEGER index
    }

    alert {
        INTEGER id "PK AI"
        INTEGER src_id "FK"
        DATETIME date
        INTEGER city_id "FK"
        INTEGER subtype_id "FK"
        INTEGER cause_id "FK"
        FLOAT km
        FLOAT fine
        INTEGER sector_id "FK"
        INTEGER tribunal_id "FK"
        BOOLEAN complete_report
        BOOLEAN traffic_incident
        FLOAT latitude
        FLOAT longitude
        FLOAT reliability
        FLOAT length
        FLOAT delay
        INTEGER dir_id "FK"
        INTEGER waze_route_id "FK"
    }

    injury_level {
        INTEGER id "PK AI"
        VARCHAR(15) level
    }

    injury_place {
        INTEGER id "PK AI"
        VARCHAR(5) place
    }

    injury {
        INTEGER id "PK AI"
        INTEGER quantity
        INTEGER alert_id "FK"
        INTEGER level_id "FK"
        INTEGER place_id "FK"
    }

    alert_street {
        INTEGER id "PK AI"
        INTEGER alert_id "FK"
        INTEGER street_id "FK"
    }

    tracking_folder {
        INTEGER id "PK AI"
        VARCHAR(10) name
    }

    route {
        INTEGER id "PK AI"
        VARCHAR(5) name
        INTEGER folder_id "FK"
    }

    vehicle {
        INTEGER id "PK AI"
        VARCHAR(6) plate
        VARCHAR(20) name
    }

    direction {
        INTEGER id "PK AI"
        VARCHAR(20) name
    }

    speed {
        INTEGER id "PK AI"
        INTEGER src_id "FK"
        DATETIME date
        FLOAT latitude
        FLOAT longitude
        FLOAT speed
        FLOAT fix
        FLOAT precision
        INTEGER city_id "FK"
        INTEGER route_id "FK"
        INTEGER vehicle_id "FK"
        INTEGER direction
        FLOAT dop
        VARCHAR(255) comment
        INTEGER dir_id "FK"
    }

    brand {
        INTEGER id "PK AI"
        VARCHAR(20) name
    }

    model {
        INTEGER id "PK AI"
        VARCHAR(25) name
        INTEGER brand_id "FK"
    }

    link_type {
        INTEGER id "PK AI"
        VARCHAR(10) name
    }

    provider {
        INTEGER id "PK AI"
        VARCHAR(30) name
    }

    camera {
        INTEGER id "PK AI"
        INTEGER src_id "FK"
        VARCHAR(50) name
        INTEGER city_id "FK"
        DATETIME integration
        BOOLEAN online
        INTEGER link_id "FK"
        INTEGER provider_id "FK"
        VARCHAR(20) camera_id
        VARCHAR(20) encoder_id
        INTEGER model_id "FK"
        INTEGER encoder_model_id "FK"
        FLOAT latitude
        FLOAT longitude
    }

    model ||--|{ camera : model_id
    model ||--|{ camera : encoder_model_id
    source ||--|{ waze_route: src_id
    speed }|--|| city : city_id
    state ||--|{ city : state_id
    city ||--|{ street : city_id
    alert_type ||--|{ alert_subtype : type_id
    alert_subtype ||--|{ alert : subtype_id
    alert_cause ||--|{ alert : cause_id
    alert_direction ||--|{ alert : dir_idS
    city ||--|{ alert : city_id
    sector ||--|{ alert : sector_id
    tribunal ||--|{ alert : tribunal_id
    source ||--|{ alert: src_id
    street ||--|{ alert_street : street_id
    street ||--|{ waze_route : from_id
    street ||--|{ waze_route : to_id
    alert_street }|--|| alert : alert_id
    alert ||--|{ injury : alert_id
    injury_level ||--|{ injury : level_id
    injury_place ||--|{ injury : place_id
    route_name ||--|{ waze_route : name_id
    route_type ||--|{ waze_route : type_id
    route_point }|--|| waze_route : route_id
    waze_route ||--|{ alert : waze_route_id
    camera }|--|| city : city_id
    tracking_folder ||--|{ route : folder_id
    route ||--|{ speed : route_id
    vehicle ||--|{ speed : vehicle_id
    direction ||--|{ speed : dir_id
    speed }|--|| source: src_id
    brand ||--|{ model : brand_id
    link_type ||--|{ camera : link_id
    provider ||--|{ camera : provider_id
    camera }|--|| source: src_id
    token ||--|{ token_source: tkn_id
    token_source }|--|| source: src_id
    token_permission }|--|| token: tkn_id
    permission ||--|{ token_permission: prm_id
```


```{sql creation, eval=FALSE}
CREATE TABLE IF NOT EXISTS token (
  id INTEGER PRIMARY KEY AUTOINCREMENT,
  token BINARY(16) UNIQUE DEFAULT UUID()
)

CREATE TABLE IF NOT EXISTS source (
  id INTEGER PRIMARY KEY AUTOINCREMENT,
  name VARCHAR(255)
)

CREATE TABLE IF NOT EXISTS permission (
  id INTEGER PRIMARY KEY AUTOINCREMENT,
  name VARCHAR(255)
)

CREATE TABLE IF NOT EXISTS token_source (
  id INTEGER PRIMARY KEY AUTOINCREMENT,
  tkn_id INTEGER REFERENCES token(id),
  src_id INTEGER REFERENCES source(id)
)

CREATE TABLE IF NOT EXISTS token_permission (
  id INTEGER PRIMARY KEY AUTOINCREMENT,
  tkn_id INTEGER REFERENCES token(id),
  prm_id INTEGER REFERENCES permission(id)
)

CREATE TABLE IF NOT EXISTS state (
  id INTEGER PRIMARY KEY AUTOINCREMENT,
  name VARCHAR(20)
)

CREATE TABLE IF NOT EXISTS city (
  id INTEGER PRIMARY KEY AUTOINCREMENT,
  name VARCHAR(20),
  state_id INTEGER REFERENCES state(id)
)

CREATE TABLE IF NOT EXISTS sector (
  id INTEGER PRIMARY KEY AUTOINCREMENT,
  name VARCHAR(20)
)

CREATE TABLE IF NOT EXISTS street (
  id INTEGER PRIMARY KEY AUTOINCREMENT,
  name VARCHAR(255),
  city_id INTEGER REFERENCES city(id)
)

CREATE TABLE IF NOT EXISTS tribunal (
  id INTEGER PRIMARY KEY AUTOINCREMENT,
  name VARCHAR(255)
)

CREATE TABLE IF NOT EXISTS alert_type (
  id INTEGER PRIMARY KEY AUTOINCREMENT,
  name VARCHAR(255)
)

CREATE TABLE IF NOT EXISTS alert_subtype (
  id INTEGER PRIMARY KEY AUTOINCREMENT,
  name VARCHAR(255),
  type_id INTEGER REFERENCES alert_type(id)
)

CREATE TABLE IF NOT EXISTS alert_direction (
  id INTEGER PRIMARY KEY AUTOINCREMENT,
  name VARCHAR(10)
)

CREATE TABLE IF NOT EXISTS alert_cause (
  id INTEGER PRIMARY KEY AUTOINCREMENT,
  name VARCHAR(255)
)

CREATE TABLE IF NOT EXISTS route_name (
  id INTEGER PRIMARY KEY AUTOINCREMENT,
  name VARCHAR(255)
)

CREATE TABLE IF NOT EXISTS route_type (
  id INTEGER PRIMARY KEY AUTOINCREMENT,
  name VARCHAR(10)
)

CREATE TABLE IF NOT EXISTS waze_route (
  id INTEGER PRIMARY KEY AUTOINCREMENT,
  src_id INTEGER REFERENCES source(id),
  date DATETIME,
  historic_time FLOAT,
  from_id INTEGER REFERENCES street(id),
  name_id INTEGER REFERENCES route_name(id),
  to_id INTEGER REFERENCES street(id),
  length FLOAT,
  time FLOAT,
  jam_level INTEGER,
  type_id INTEGER REFERENCES route_type(id)
)

CREATE TABLE IF NOT EXISTS route_point (
  id INTEGER PRIMARY KEY AUTOINCREMENT,
  route_id INTEGER REFERENCES waze_route(id),
  latitude FLOAT,
  longitude FLOAT,
  index INTEGER
)

CREATE TABLE IF NOT EXISTS alert (
  id INTEGER PRIMARY KEY AUTOINCREMENT,
  src_id INTEGER REFERENCES source(id),
  date DATETIME,
  city_id INTEGER REFERENCES city(id),
  subtype_id INTEGER REFERENCES alert_subtype(id),
  cause_id INTEGER REFERENCES alert_cause(id),
  km FLOAT,
  fine FLOAT,
  sector_id INTEGER REFERENCES sector(id),
  tribunal_id INTEGER REFERENCES tribunal(id),
  complete_report TINYINT(1),
  traffic_incident TINYINT(1),
  latitude FLOAT,
  longitude FLOAT,
  reliability FLOAT,
  length FLOAT,
  delay FLOAT,
  dir_id INTEGER REFERENCES alert_direction(id),
  waze_route_id INTEGER REFERENCES waze_route(id)
)

CREATE TABLE IF NOT EXISTS injury_level (
  id INTEGER PRIMARY KEY AUTOINCREMENT,
  name VARCHAR(15)
)

CREATE TABLE IF NOT EXISTS injury_place (
  id INTEGER PRIMARY KEY AUTOINCREMENT,
  name VARCHAR(5)
)

CREATE TABLE IF NOT EXISTS injury (
  id INTEGER PRIMARY KEY AUTOINCREMENT,
  quantity INTEGER,
  alert_id INTEGER REFERENCES alert(id),
  level_id INTEGER REFERENCES injury_level(id),
  place_id INTEGER REFERENCES injury_place(id)
)

CREATE TABLE IF NOT EXISTS alert_street (
  id INTEGER PRIMARY KEY AUTOINCREMENT,
  alert_id INTEGER REFERENCES alert(id),
  street_id INTEGER REFERENCES street(id)
)

CREATE TABLE IF NOT EXISTS tracking_folder (
  id INTEGER PRIMARY KEY AUTOINCREMENT,
  name VARCHAR(10)
)

CREATE TABLE IF NOT EXISTS route (
  id INTEGER PRIMARY KEY AUTOINCREMENT,
  name VARCHAR(5),
  folder_id INTEGER REFERENCES tracking_folder(id)
)

CREATE TABLE IF NOT EXISTS vehicle (
  id INTEGER PRIMARY KEY AUTOINCREMENT,
  plate VARCHAR(6),
  name VARCHAR(20)
)

CREATE TABLE IF NOT EXISTS direction (
  id INTEGER PRIMARY KEY AUTOINCREMENT,
  name VARCHAR(20)
)

CREATE TABLE IF NOT EXISTS speed (
  id INTEGER PRIMARY KEY AUTOINCREMENT,
  src_id INTEGER REFERENCES source(id),
  date DATETIME,
  latitude FLOAT,
  longitude FLOAT,
  speed FLOAT,
  fix FLOAT,
  precision FLOAT,
  city_id INTEGER REFERENCES city(id),
  route_id INTEGER REFERENCES route(id),
  vehicle_id INTEGER REFERENCES vehicle(id),
  direction INTEGER,
  dop FLOAT,
  comment VARCHAR(255),
  dir_id INTEGER REFERENCES alert_direction(id)
)

CREATE TABLE IF NOT EXISTS brand (
  id INTEGER PRIMARY KEY AUTOINCREMENT,
  name VARCHAR(20)
)

CREATE TABLE IF NOT EXISTS model (
  id INTEGER PRIMARY KEY AUTOINCREMENT,
  name VARCHAR(25),
  brand_id INTEGER REFERENCES brand(id)
)

CREATE TABLE IF NOT EXISTS link_type (
  id INTEGER PRIMARY KEY AUTOINCREMENT,
  name VARCHAR(10)
)

CREATE TABLE IF NOT EXISTS provider (
  id INTEGER PRIMARY KEY AUTOINCREMENT,
  name VARCHAR(30)
)

CREATE TABLE IF NOT EXISTS speed (
  id INTEGER PRIMARY KEY AUTOINCREMENT,
  src_id INTEGER REFERENCES source(id),
  name VARCHAR(50),
  city_id INTEGER REFERENCES city(id),
  integration DATETIME,
  online BOOLEAN,
  link_id INTEGER REFERENCES link_type(id),
  provider_id INTEGER REFERENCES provider(id),
  camera_id VARCHAR(20),
  encoder_id VARCHAR(20),
  model_id INTEGER REFERENCES model(id),
  encoder_model_id INTEGER REFERENCES model(id),
  latitude FLOAT,
  longitude FLOAT
)
```

## Insertar registros

### Siniestros buses interurbanos(1).xlsx

```{sql inserts0, eval=FALSE}

```

### GH026929.xlsx

```{sql inserts1, eval=FALSE}

```

### DTPR

```{sql inserts1.5, eval=FALSE}

```

### Data accidentes de carabineros.xlsx

```{sql inserts2, eval=FALSE}

```

### Incidentes de tráfico radio.xlsx

```{sql inserts3, eval=FALSE}

```

### Med velo CHIGUAYANTE.xlsx

```{sql inserts4, eval=FALSE}

```

### Med velo LA VEGA.xlsx

```{sql inserts5, eval=FALSE}

```

### Inventario CCTV Biobío(1).xlsx

```{sql inserts7, eval=FALSE}

```

### Alertas de Tráfico.csv

```{sql inserts8, eval=FALSE}

```

### Copia de Accidentes.csv

```{sql inserts9, eval=FALSE}

```

### Waze for Cities Data Key Alerts Dashboard_Traffic Irregularities_Tabla(1).csv

```{sql inserts10, eval=FALSE}

```

### Red de Waze

```{sql inserts11, eval=FALSE}

```

